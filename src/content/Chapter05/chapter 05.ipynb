{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                     线性回归模型----------------建立和培训 \n",
    "  根据我们在前面第二章中对线性回归模型的解释，数据建模的实际运用——泰坦尼克号模型我们将通过这一定义去建立一个简单的线性回归模型。让我们从导入实现这一需求所必须的包开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：pyplot不默认支持显示中文，需要Rcparams修改字体来实现。\n",
    "plt中的figure函数,绘图     \n",
    "参数名：figure 备注：返回的Figure实例会被传递给后端的新图像管理器new_figure_manager，这将允许定制的Figure类到pylab接口，额外的参数会被传递给图形初始化函数\n",
    "参数名：figsize 类型： tuple of integers 整数元组, optional可选, default: None，默认没有 备注：宽度，高度英寸。如果没有提供，默认为rc figure.figsize。\n",
    "\n",
    "如果你正在创建很多图形，确保在不适的图形上调用关闭函数，因为这将是pylab正确清理内存。rcParams定义默认值，可以在matplotlibrc文件中修改\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "我们定义一个独立变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Values...\n",
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7\n",
      " 1.8 1.9 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5\n",
      " 3.6 3.7 3.8 3.9 4.  4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9]\n",
      "defining the linear regression equation...\n",
      "Plotting the output...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementing the linear regression model in TensorFlow...\n"
     ]
    }
   ],
   "source": [
    "input_values = np.arange(0.0, 5.0, 0.1)\n",
    "\n",
    "print('Input Values...')\n",
    "print(input_values)\n",
    "\n",
    "print('defining the linear regression equation...')\n",
    "weight=1\n",
    "bias=0\n",
    "\n",
    "\n",
    "output = weight*input_values + bias\n",
    "\n",
    "print('Plotting the output...')\n",
    "plt.plot(input_values,output)\n",
    "plt.ylabel('Dependent Variable')\n",
    "plt.xlabel('Indepdendent Variable')\n",
    "plt.show()\n",
    "print('Implementing the linear regression model in TensorFlow...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cnblogs.com/TensorSense/p/6802280.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们在tensorflow代码中去理解。\n",
    "\n",
    "<font color=#FF0000> Tensorflow中的线性回归 </font> \n",
    "\n",
    "对于第一部分，我们将生成随机数据点并定义一个线性关系，我们将使用tensorflow来调整并获得正确的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = np.random.rand(100).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42033228 0.5963097  0.4023396  0.717908   0.53151834 0.25332552\n",
      " 0.97751486 0.7205613  0.27657962 0.07477889 0.11128575 0.82746655\n",
      " 0.16186203 0.18979247 0.40814823 0.5533579  0.70759684 0.71830815\n",
      " 0.3413415  0.1304997  0.5681144  0.04668642 0.96550435 0.22972603\n",
      " 0.46595147 0.53121257 0.3642674  0.96821743 0.9551877  0.5944036\n",
      " 0.90094113 0.6417873  0.30401826 0.4932522  0.6866288  0.77156883\n",
      " 0.92808425 0.79278886 0.78724545 0.72384894 0.63069445 0.77906936\n",
      " 0.6914404  0.98756516 0.3353803  0.27006382 0.01009431 0.30786645\n",
      " 0.04711584 0.46536386 0.41362128 0.32260433 0.6487513  0.9792802\n",
      " 0.8799003  0.49077898 0.10275687 0.23788983 0.7916724  0.67415637\n",
      " 0.01382603 0.76243323 0.14029425 0.78096765 0.3797123  0.40258673\n",
      " 0.8562378  0.3332955  0.40058127 0.31077176 0.703207   0.7997768\n",
      " 0.2129223  0.31148523 0.5325596  0.74074703 0.8542488  0.93233675\n",
      " 0.9165258  0.8053432  0.05164476 0.70947915 0.9524554  0.7945742\n",
      " 0.90978897 0.07795006 0.6640318  0.26881677 0.55826664 0.33018446\n",
      " 0.7495403  0.05882033 0.34269485 0.5359591  0.32958946 0.40701923\n",
      " 0.6318902  0.86169076 0.24877408 0.2774912 ]\n"
     ]
    }
   ],
   "source": [
    "input_values = np.random.rand(100).astype(np.float32)\n",
    "print(input_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：创建100个浮点数32的[0，1]的之间的随机数https://blog.csdn.net/wave_xiao/article/details/79141294"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本例中模型的方程为:\n",
    "                            Y=2x+3\n",
    "这个等式本身并没有什么特别的地方，它只是我们用来生成数据点的模型。实际上，你可以根据自己的偏好任意的去调节参数，正如你们之后会这样做。我们在这些点中加入一些高斯噪声使其变得更生动。\n",
    "以下是一个样本中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from the input and output values of the linear regression model...\n",
      "[(0.817965, 4.635703381443361), (0.35672733, 3.5591916644268577), (0.939491, 4.815186982860583), (0.25160825, 3.4349347953916154), (0.5616466, 4.048211808676295)]\n"
     ]
    }
   ],
   "source": [
    "output_values = input_values * 2 + 3\n",
    "output_values = np.vectorize(lambda y: y + np.random.normal(loc=0.0, scale=0.1))(output_values)\n",
    "print('Sample from the input and output values of the linear regression model...')\n",
    "print(list(zip(input_values,output_values))[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：vectorize 向量化      \n",
    "两个小括号\n",
    "zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。\n",
    "http://www.runoob.com/python/python-func-zip.html\n",
    "lambda x，y：x+y                  https://blog.csdn.net/zjuxsl/article/details/79437563\n",
    "\n",
    "np.random.normal(loc=0.0, scale=0.1)    https://blog.csdn.net/doufuxixi/article/details/80356752\n",
    "loc：float\n",
    "    此概率分布的均值（对应着整个分布的中心centre）\n",
    "scale：float\n",
    "    此概率分布的标准差（对应于分布的宽度，scale越大越矮胖，scale越小，越瘦高）\n",
    "size：int or tuple of ints\n",
    "    输出的shape，默认为None，只输出一个值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们用任意的随机猜测初始化变量权重和偏差，然后我们定义线性函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining the model loss and optimizer...\n"
     ]
    }
   ],
   "source": [
    "weight = tf.Variable(1.0)\n",
    "bias = tf.Variable(0.2)\n",
    "\n",
    "predicted_vals = weight * input_values + bias\n",
    "\n",
    "print('Defining the model loss and optimizer...')\n",
    "model_loss = tf.reduce_mean(tf.square(predicted_vals - output_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一个典型的线性回归模型中，我们将需要调整的方程的平方误差最小化减去目标值（我们有的数据），因此我们将这个方程定义为损失最小化。\n",
    "为了寻找损失的数值，我们利用tf.reduce_mean()。这一函数找出了多维张量的均值，结果可以有不同的维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：tf.reduce_mean就是求均值\n",
    "x = np.array([[1.,2.,3.],[4.,5.,6.]])\n",
    "sess = tf.Session()\n",
    "mean_none = sess.run(tf.reduce_mean(x))\n",
    "mean_0 = sess.run(tf.reduce_mean(x, 0))\n",
    "mean_1 = sess.run(tf.reduce_mean(x, 1))\n",
    "print (mean_none)\n",
    "print (mean_0)\n",
    "print (mean_1)\n",
    "mean_none=3.5\n",
    "mean_0=[ 2.5  3.5  4.5]\n",
    "mean_1=[ 2.  5.]\n",
    "tf.square就是求每个元素的平方\n",
    "损失函数在机器学习中的模型非常重要的一部分，它代表了评价模型的好坏程度的标准，最终的优化目标就是通过调整参数去使得损失函数尽可能的小，如果损失函数定义错误或者不符合实际意义的话，训练模型只是在浪费时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们定义优化器方法。在这里，我们将使用一个学习率为0.5的简单梯度下降法。\n",
    "\n",
    "现在，我们将定义我们的图的训练方法，但是我们将使用什么方法来最小化损失？tf.train.GradientDescentOptimizer。\n",
    "\n",
    "这个.minimize()功能最小化优化器的错误函数，带来更好的模型:\n",
    "在执行图形之前，不要忘记初始化变量。\n",
    "现在，我们准备开始优化并运行图表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the global variables...\n",
      "0 [2.6770933, 3.4762764]\n",
      "5 [2.224094, 2.8737326]\n",
      "10 [2.1501904, 2.9132109]\n",
      "15 [2.0994017, 2.9397433]\n",
      "20 [2.0646665, 2.95789]\n",
      "25 [2.0409105, 2.970301]\n",
      "30 [2.024663, 2.978789]\n",
      "35 [2.0135512, 2.984594]\n",
      "40 [2.0059516, 2.9885643]\n",
      "45 [2.000754, 2.9912796]\n",
      "50 [1.9971993, 2.9931366]\n",
      "55 [1.9947683, 2.9944067]\n",
      "60 [1.9931055, 2.9952755]\n",
      "65 [1.9919683, 2.9958696]\n",
      "70 [1.9911904, 2.996276]\n",
      "75 [1.9906585, 2.996554]\n",
      "80 [1.9902947, 2.996744]\n",
      "85 [1.9900459, 2.9968739]\n",
      "90 [1.9898758, 2.9969628]\n",
      "95 [1.9897594, 2.9970236]\n"
     ]
    }
   ],
   "source": [
    "model_optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "\n",
    "\n",
    "train = model_optimizer.minimize(model_loss)\n",
    "\n",
    "\n",
    "print('Initializing the global variables...')\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for step in range(100):\n",
    "\n",
    "    evals = sess.run([train,weight,bias])[1:]\n",
    "\n",
    "    if step % 5 == 0:\n",
    "\n",
    "       print(step, evals)\n",
    "\n",
    "       train_data.append(evals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：函数training()通过梯度下降法为最小化损失函数增加了相关的优化操作  https://blog.csdn.net/shenxiaoming77/article/details/77169756\n",
    "比如 tf.train.GradientDescentOptimizer，并基于一定的学习率进行梯度优化训练，然后，可以设置 一个用于记录全局训练步骤的单值。以及使用minimize()操作，该操作不仅可以优化更新训练的模型参数，也可以为全局步骤(global step)计数。与其他tensorflow操作类似，这些训练操作都需要在tf.session会话中进行\n",
    "tf.global_variables_initializer()添加节点用于初始化所有的变量(GraphKeys.VARIABLES)。返回一个初始化所有全局变量的操作（Op）。在你构建完整个模型并在会话中加载模型后，运行这个节点。能够将所有的变量一步到位的初始化，非常的方便。通过feed_dict, 你也可以将指定的列表传递给它，只初始化列表中的变量。                                        https://blog.csdn.net/yyhhlancelot/article/details/81415137\n",
    "tf.Session()创建一个会话，当上下文管理器退出时会话关闭和资源释放自动完成。\n",
    "tf.Session().as_default()创建一个默认会话，当上下文管理器退出时会话没有关闭，还可以通过调用会话进行run()和eval()操作\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程可视化，使其符合数据点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the data points with their corresponding fitted line...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plotting the data points with their corresponding fitted line...')\n",
    "converter = plt.colors\n",
    "cr, cg, cb = (1.0, 1.0, 0.0)\n",
    "\n",
    "for f in train_data:\n",
    "\n",
    "    cb += 1.0 / len(train_data)\n",
    "    cg -= 1.0 / len(train_data)\n",
    "\n",
    "    if cb > 1.0: cb = 1.0\n",
    "\n",
    "    if cg < 0.0: cg = 0.0\n",
    "\n",
    "    [a, b] = f\n",
    "    f_y = np.vectorize(lambda x: a*x + b)(input_values)\n",
    "    line = plt.plot(input_values, f_y)\n",
    "    plt.setp(line, color=(cr,cg,cb))\n",
    "    plt.plot(input_values, output_values, 'ro')\n",
    "green_line = mpatches.Patch(color='red', label='Data Points')\n",
    "plt.legend(handles=[green_line])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：Python len() 方法返回对象（字符、列表、元组等）长度或项目个数。\n",
    "设置legend图例                      https://blog.csdn.net/Quincuntial/article/details/70947363\n",
    "get_legend_handles_labels()方法返回 存在于图像中的 handles/artists 列表，这些图像可以用来生成结果图例中的入口。值得注意的是并不是所有的 artists 都可以被添加到图例中。为了全部控制添加到图例中的内容，通常直接传递适量的 handles 给legend()函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000> 逻辑回归模型的建立和培训</font>\n",
    "\n",
    "同样的，基于我们在第二章中对逻辑回归模型的解释，数据建模运用在实际中---泰坦尼克号模型，我们将在tensorflow中实现逻辑回归算法。所以，简洁的说，逻辑回归通过逻辑函数/激活函数传递输入，然后将结果视为概率。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在tensorflow中应用逻辑回归\n",
    "\n",
    "在tensorflow中应用逻辑回归之前，我们需要将要用到的库导入其中。你可以这么做实现这个目的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：Sklearn的train_test_split用法           https://blog.csdn.net/fxlou/article/details/79189106\n",
    "在机器学习中，我们通常将原始数据按照比例分割为“测试集”和“训练集”，通常使用sklearn.cross_validation里的train_test_split模块用来分割数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将加载将要使用的数据集。在本例中，我们使用的是内置的iris数据集，因此，不需要做任何预处理，我们可以直接操作它。我们把数据集分成x和y，然后再分成训练x和y和y随机检验(伪）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们将加载将要使用的数据集。在本例中，我们使用的是内置的iris数据集，因此，不需要做任何预处理，我们可以直接操作它。\n",
    "#我们把数据集分成x和y，然后再分成训练集和测试集。\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "iris_input_values, iris_output_values = iris_dataset.data[:-1,:], iris_dataset.target[:-1]\n",
    "iris_output_values= pd.get_dummies(iris_output_values).values\n",
    "train_input_values, test_input_values, train_target_values, test_target_values = train_test_split(iris_input_values, iris_output_values, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：pandas.get_dummies 的用法                   https://blog.csdn.net/maymay_/article/details/80198468"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么使用占位符？\n",
    "TensorFlow的这个特性允许我们创建一个算法，它可以接受数据并知道数据的形状，而不需要知道输入的数据量。当我们在训练中插入一批数据时，我们可以很容易地调整我们在一个步骤中训练的几个例子而不改变整个算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numFeatures is the number of features in our input data.\n",
    "# In the iris dataset, this number is '4'.\n",
    "#这些占位符将保存我们的iris数据(包括特性和标签矩阵)，并帮助将它们传递到算法的不同部分。你可以将占位符看作是插入数据的空区域。\n",
    "#我们还需要为它们提供与数据模型相对应的模型。之后，我们将通过feed_dict向占位符提供数据来向占位符插入数据\n",
    "num_explanatory_features = train_input_values.shape[1]\n",
    "\n",
    "# numLabels is the number of classes our data points can be in.\n",
    "# In the iris dataset, this number is '3'.\n",
    "num_target_values = train_target_values.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "# 'None' means TensorFlow shouldn't expect a fixed number in that dimension\n",
    "input_values = tf.placeholder(tf.float32, [None, num_explanatory_features]) # Iris has 4 features, so X is a tensor to hold our data.\n",
    "output_values = tf.placeholder(tf.float32, [None, num_target_values]) # This will be our correct answers matrix for 3 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意： shape函数是numpy.core.fromnumeric中的函数，它的功能是查看矩阵或者数组的维数   https://blog.csdn.net/u010758410/article/details/71554224    tf.placeholder(dtype, shape=None, name=None)此函数可以理解为形参，用于定义过程，在执行的时候再赋具体的值,用于得到传递进来的真实的训练样本\n",
    "参数：dtype：数据类型。常用的是tf.float32,tf.float64等数值类型  shape：数据形状。默认是None，就是一维值，也可以是多维，比如[2,3], [None, 3]表示列是3，行不定  name：名称                                https://blog.csdn.net/zj360202/article/details/70243127\n",
    "TensorFlow 辨异 —— tf.placeholder 与 tf.Variable                 https://blog.csdn.net/lanchunhui/article/details/61712830       \n",
    "为什么使用占位符？\n",
    "TensorFlow的这个特性允许我们创建一个算法，它可以接受数据并知道数据的形状，而不需要知道输入的数据量。当我们在训练中插入一批数据时，我们可以很容易地调整我们在一个步骤中训练的几个例子而不改变整个算法。                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设立模型的权重和偏差\n",
    "\n",
    "与线性回归非常相似，我们需要一个用于逻辑回归的共享可变加权矩阵。我们将W和b初始化为满是0的张量。既然我们要研究W和b，它们的初始值并不重要。这些变量是定义回归模型结构的对象，我们可以在它们经过训练之后保存它们以便以后可以重用它们。\n",
    "\n",
    "我们将两个TensorFlow变量定义为参数。这些变量将会控制我们的逻辑回归的权重和偏差，并且使它们在训练过程中不断更新。注意到W的形状是[4,3]因为我们想用它乘以4维的输入向量来产生3维的向量，b的形状是[3]，所以我们可以把它添加到输出中。此外，与我们的占位符不同(占位符本质上是等待输入数据的空shell)。TensorFlow变量必须初始化为数值,通常,0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly sample from a normal distribution with standard deviation .01\n",
    "#设立模型的权重和偏差\n",
    "#与线性回归非常相似，我们需要一个用于逻辑回归的共享可变加权矩阵。我们将W和b初始化为满是0的张量。既然我们要研究W和b，它们的初始值并不重要。\n",
    "#我们将两个TensorFlow变量定义为参数。这些变量将会控制我们的逻辑回归的权重和偏差，并且使它们在训练过程中不断更新。\n",
    "weights = tf.Variable(tf.random_normal([num_explanatory_features,num_target_values],\n",
    "                                      mean=0,\n",
    "                                      stddev=0.01,\n",
    "                                      name=\"weights\"))\n",
    "\n",
    "biases = tf.Variable(tf.random_normal([1,num_target_values],\n",
    "                                   mean=0,\n",
    "                                   stddev=0.01,\n",
    "                                   name=\"biases\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：tf.random_normal()函数用于从服从指定正太分布的数值中取出指定个数的值。   https://blog.csdn.net/dcrmg/article/details/79028043 \n",
    "tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "shape: 输出张量的形状，必选\n",
    "mean: 正态分布的均值，默认为0\n",
    "stddev: 正态分布的标准差，默认为1.0\n",
    "dtype: 输出的类型，默认为tf.float32\n",
    "seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样name: 操作的名称\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归模型\n",
    "\n",
    "我们现在定义了我们的操作以便正确地运行逻辑回归，逻辑回归通常被认为是一个单一的方程：\n",
    "      w=sigmod(wx+b)\n",
    "不过，为了清晰起见，我们可以将其分为三个主要部分：\n",
    "      权重乘以特征是矩阵乘法运算\n",
    "      加权特征和偏置项的总和\n",
    "      最后，激活函数的应用\n",
    "因此,你会发现这些组件定义为三个独立的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three-component breakdown of the Logistic Regression equation.         \n",
    "# 逻辑回归，权重乘以特征是矩阵乘法运算\n",
    "    #  加权特征和偏置项的总和\n",
    "     # 最后，激活函数的应用\n",
    "# Note that these feed into each other.\n",
    "apply_weights = tf.matmul(input_values, weights, name=\"apply_weights\")\n",
    "add_bias = tf.add(apply_weights, biases, name=\"add_bias\")\n",
    "activation_output = tf.nn.sigmoid(add_bias, name=\"activation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：tf.matmul矩阵相乘                                https://www.jianshu.com/p/19ea2d15eb14 \n",
    "tf.add 相加                                https://blog.csdn.net/Hollake/article/details/79704129\n",
    "tf.nn.sigmoid                                 https://www.w3cschool.cn/tensorflow_python/tensorflow_python-d46p2k47.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如我们之前看到的，我们要用到的函数是逻辑函数，通过偏差和权重判断哪个是输入数据。在Tensorflow中，这个函数通过nn.sigmoid实现，有效地，它将加权输入与偏置成0 - 100%曲线拟合，这是我们想要的概率函数。\n",
    "<font color=#FF0000> \n",
    "训练\n",
    "</font>\n",
    "学习算法就是寻找最优权向量的方法（w），这种搜索是寻找优化误差/成本测量的假设的优化问题。\n",
    "因此,模型的成本或损失函数会告诉我们我们的模型是不好的,我们需要这个函数最小化。您可以遵循不同的损失或成本标准。在这个实现中，我们将使用均方误差(MSE)作为一个损失函数。\n",
    "为了完成最小化损失函数的任务，我们将使用梯度下降算法。\n",
    "<font color=#FF0000> \n",
    "损失函数\n",
    "</font>\n",
    "在定义成本函数之前，我们需要确定训练需要多长时间以及如何定义学习速率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of training epochs                            \n",
    "#定义时间长度和学习速率，损失函数和优化器\n",
    "num_epochs = 700\n",
    "# Defining our learning rate iterations (decay)\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.0008,\n",
    "                                          global_step=1,\n",
    "                                          decay_steps=train_input_values.shape[0],\n",
    "                                          decay_rate=0.95,\n",
    "                                          staircase=True)\n",
    "\n",
    "# Defining our cost function - Squared Mean Error\n",
    "model_cost = tf.nn.l2_loss(activation_output - output_values, name=\"squared_error_cost\")\n",
    "# Defining our Gradient Descent\n",
    "model_train = tf.train.GradientDescentOptimizer(learningRate).minimize(model_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：tf.train.exponential_decay                              https://blog.csdn.net/uestc_c2_403/article/details/72213286\n",
    "初始的学习速率是0.0008，总的迭代次数是1次，如果staircase=True，那就表明每decay_steps次计算学习速率变化，更新原始学习速率，如果是False，那就是每一步都更新学习速率。红色表示False，绿色表示True。\n",
    "l2_loss()这个函数的作用是利用L2范数来计算张量的误差值，但是没有开发并且只取L2范数的值的一半简单的可以理解成张量中的每一个元素进行平方，然后求和，最后乘一个1/2。l2_loss一般用于优化目标函数中的正则项，防止参数太多复杂容易过拟合(所谓的过拟合问题是指当一个模型很复杂时，它可以很好的“记忆”每一个训练数据中的随机噪声的部分而忘记了要去“学习”训练数据中通用的趋势)\n",
    "https://blog.csdn.net/yangfengling1023/article/details/82910536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，是时候将我们的计算图表执行到会话变量中了\n",
    "首先，我们需要用tf.initialize_all_variables()初始化权重和偏差，使其为0或随机值。这个初始化步骤将会成为我们计算图中的一个节点，当我们将图表放入一个会话中，操作会运行并创建变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step 0, accuracy 0.333333, cost 34.8673, cost change 34.8673\n",
      "Training step 10, accuracy 0.494949, cost 30.2579, cost change 30.2579\n",
      "Training step 20, accuracy 0.646465, cost 28.3077, cost change 28.3077\n",
      "Training step 30, accuracy 0.646465, cost 26.6538, cost change 26.6538\n",
      "Training step 40, accuracy 0.646465, cost 25.2748, cost change 25.2748\n",
      "Training step 50, accuracy 0.646465, cost 24.1331, cost change 24.1331\n",
      "Training step 60, accuracy 0.646465, cost 23.1868, cost change 23.1868\n",
      "Training step 70, accuracy 0.646465, cost 22.398, cost change 22.398\n",
      "Training step 80, accuracy 0.646465, cost 21.735, cost change 21.735\n",
      "Training step 90, accuracy 0.646465, cost 21.1722, cost change 21.1722\n",
      "Training step 100, accuracy 0.656566, cost 20.6899, cost change 20.6899\n",
      "Training step 110, accuracy 0.666667, cost 20.2723, cost change 20.2723\n",
      "Training step 120, accuracy 0.666667, cost 19.9074, cost change 19.9074\n",
      "Training step 130, accuracy 0.666667, cost 19.5858, cost change 19.5858\n",
      "Training step 140, accuracy 0.666667, cost 19.2999, cost change 19.2999\n",
      "Training step 150, accuracy 0.666667, cost 19.0438, cost change 19.0438\n",
      "Training step 160, accuracy 0.676768, cost 18.8128, cost change 18.8128\n",
      "Training step 170, accuracy 0.686869, cost 18.6031, cost change 18.6031\n",
      "Training step 180, accuracy 0.686869, cost 18.4114, cost change 18.4114\n",
      "Training step 190, accuracy 0.707071, cost 18.2354, cost change 18.2354\n",
      "Training step 200, accuracy 0.717172, cost 18.0729, cost change 18.0729\n",
      "Training step 210, accuracy 0.737374, cost 17.9222, cost change 17.9222\n",
      "Training step 220, accuracy 0.737374, cost 17.7818, cost change 17.7818\n",
      "Training step 230, accuracy 0.747475, cost 17.6505, cost change 17.6505\n",
      "Training step 240, accuracy 0.757576, cost 17.5272, cost change 17.5272\n",
      "Training step 250, accuracy 0.767677, cost 17.411, cost change 17.411\n",
      "Training step 260, accuracy 0.787879, cost 17.3013, cost change 17.3013\n",
      "Training step 270, accuracy 0.787879, cost 17.1973, cost change 17.1973\n",
      "Training step 280, accuracy 0.787879, cost 17.0985, cost change 17.0985\n",
      "Training step 290, accuracy 0.787879, cost 17.0045, cost change 17.0045\n",
      "Training step 300, accuracy 0.79798, cost 16.9146, cost change 16.9146\n",
      "Training step 310, accuracy 0.79798, cost 16.8287, cost change 16.8287\n",
      "Training step 320, accuracy 0.79798, cost 16.7464, cost change 16.7464\n",
      "Training step 330, accuracy 0.79798, cost 16.6673, cost change 16.6673\n",
      "Training step 340, accuracy 0.79798, cost 16.5912, cost change 16.5912\n",
      "Training step 350, accuracy 0.828283, cost 16.518, cost change 16.518\n",
      "Training step 360, accuracy 0.828283, cost 16.4473, cost change 16.4473\n",
      "Training step 370, accuracy 0.838384, cost 16.379, cost change 16.379\n",
      "Training step 380, accuracy 0.838384, cost 16.313, cost change 16.313\n",
      "Training step 390, accuracy 0.838384, cost 16.249, cost change 16.249\n",
      "Training step 400, accuracy 0.848485, cost 16.187, cost change 16.187\n",
      "Training step 410, accuracy 0.848485, cost 16.1268, cost change 16.1268\n",
      "Training step 420, accuracy 0.848485, cost 16.0683, cost change 16.0683\n",
      "Training step 430, accuracy 0.848485, cost 16.0115, cost change 16.0115\n",
      "Training step 440, accuracy 0.868687, cost 15.9562, cost change 15.9562\n",
      "Training step 450, accuracy 0.868687, cost 15.9023, cost change 15.9023\n",
      "Training step 460, accuracy 0.868687, cost 15.8498, cost change 15.8498\n",
      "Training step 470, accuracy 0.878788, cost 15.7986, cost change 15.7986\n",
      "Training step 480, accuracy 0.878788, cost 15.7487, cost change 15.7487\n",
      "Training step 490, accuracy 0.878788, cost 15.6999, cost change 15.6999\n",
      "Training step 500, accuracy 0.878788, cost 15.6522, cost change 15.6522\n",
      "Training step 510, accuracy 0.878788, cost 15.6055, cost change 15.6055\n",
      "Training step 520, accuracy 0.878788, cost 15.5599, cost change 15.5599\n",
      "Training step 530, accuracy 0.878788, cost 15.5153, cost change 15.5153\n",
      "Training step 540, accuracy 0.888889, cost 15.4716, cost change 15.4716\n",
      "Training step 550, accuracy 0.89899, cost 15.4288, cost change 15.4288\n",
      "Training step 560, accuracy 0.89899, cost 15.3868, cost change 15.3868\n",
      "Training step 570, accuracy 0.89899, cost 15.3457, cost change 15.3457\n",
      "Training step 580, accuracy 0.89899, cost 15.3053, cost change 15.3053\n",
      "Training step 590, accuracy 0.89899, cost 15.2658, cost change 15.2658\n",
      "Training step 600, accuracy 0.909091, cost 15.2269, cost change 15.2269\n",
      "Training step 610, accuracy 0.909091, cost 15.1888, cost change 15.1888\n",
      "Training step 620, accuracy 0.909091, cost 15.1513, cost change 15.1513\n",
      "Training step 630, accuracy 0.909091, cost 15.1145, cost change 15.1145\n",
      "Training step 640, accuracy 0.909091, cost 15.0783, cost change 15.0783\n",
      "Training step 650, accuracy 0.909091, cost 15.0428, cost change 15.0428\n",
      "Training step 660, accuracy 0.909091, cost 15.0078, cost change 15.0078\n",
      "Training step 670, accuracy 0.909091, cost 14.9734, cost change 14.9734\n",
      "Training step 680, accuracy 0.909091, cost 14.9396, cost change 14.9396\n",
      "Training step 690, accuracy 0.909091, cost 14.9063, cost change 14.9063\n"
     ]
    }
   ],
   "source": [
    "# tensorflow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize our variables.\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "#We also want some additional operations to keep track of our model's efficiency over time. We can do this like so:\n",
    "# argmax(activation_output, 1) returns the label with the most probability\n",
    "# argmax(output_values, 1) is the correct label\n",
    "correct_predictions = tf.equal(tf.argmax(activation_output,1),tf.argmax(output_values,1))\n",
    "\n",
    "# If every false prediction is 0 and every true prediction is 1, the average returns us the accuracy\n",
    "model_accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "\n",
    "# Summary op for regression output\n",
    "activation_summary =  tf.summary.histogram(\"output\", activation_output)\n",
    "\n",
    "# Summary op for accuracy····\n",
    "accuracy_summary = tf.summary.scalar(\"accuracy\", model_accuracy)\n",
    "\n",
    "# Summary op for cost\n",
    "cost_summary = tf.summary.scalar(\"cost\", model_cost)\n",
    "\n",
    "# Summary ops to check how variables weights and biases are updating after each iteration to be visualized in tenorboard\n",
    "weight_summary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "bias_summary = tf.summary.histogram(\"biases\", biases.eval(session=sess))\n",
    "\n",
    "merged = tf.summary.merge([activation_summary, accuracy_summary, cost_summary, weight_summary, bias_summary])\n",
    "writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)\n",
    "\n",
    "#Now we can define and run the actual training loop, like this:\n",
    "# Initialize reporting variables\n",
    "\n",
    "inital_cost = 0\n",
    "diff = 1\n",
    "epoch_vals = []\n",
    "accuracy_vals = []\n",
    "costs = []\n",
    "\n",
    "# Training epochs\n",
    "for i in range(num_epochs):\n",
    "    if i > 1 and diff < .0001:\n",
    "       print(\"change in cost %g; convergence.\"%diff)\n",
    "       break\n",
    "\n",
    "    else:\n",
    "       # Run training step\n",
    "       step = sess.run(model_train, feed_dict={input_values: train_input_values, output_values: train_target_values})\n",
    "\n",
    "       # Report some stats evert 10 epochs\n",
    "       if i % 10 == 0:\n",
    "           # Add epoch to epoch_values\n",
    "           epoch_vals.append(i)\n",
    "\n",
    "           # 生成模型的精度统计数据\n",
    "           train_accuracy, new_cost = sess.run([model_accuracy, model_cost], feed_dict={input_values: train_input_values, output_values: train_target_values})\n",
    "\n",
    "           # 增加实时图形变量的准确性\n",
    "           accuracy_vals.append(train_accuracy)\n",
    "\n",
    "           # 添加动态绘图变量的损失\n",
    "           costs.append(new_cost)\n",
    "\n",
    "           # 为变量重新赋值\n",
    "           diff = abs(new_cost - inital_cost)\n",
    "           cost = new_cost\n",
    "\n",
    "\n",
    "           print(\"Training step %d, accuracy %g, cost %g, cost change %g\"%(i, train_accuracy, new_cost, diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看看经过训练的模型如何在iris数据集中执行，因此让我们根据测试集测试经过训练的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：tf.equal(A, B)是对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，反正返回False，返回的值的矩阵维度和A是一样的\n",
    "https://blog.csdn.net/uestc_c2_403/article/details/72232924\n",
    "tf.reduce.mean 求平均值           https://blog.csdn.net/qq_32166627/article/details/52734387\n",
    "TensorBoard读取TensorFlow的events文件，这些文件在运行TensorFlow时可以保存下来。\n",
    "如果想要记录learning rate和目标函数。可以将tf.summary.scalar放在相应的节点上。\n",
    "如果想要可视化激活函数的分布，或者是梯度或权重的分布，可以将tf.summary.histogram放在相应的节点。\n",
    "这些summary节点并不在之前创建的图中，所以，需要用tf.summary.merge_all将它们结合成一个操作。\n",
    "最后，由tf.summary.FileWriter来存储数据。log_path为存储路径\n",
    "https://blog.csdn.net/ls617386/article/details/62049834\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy on test set: 0.9\n"
     ]
    }
   ],
   "source": [
    "# test the model against the test set\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(model_accuracy,\n",
    "                                                    feed_dict={input_values: test_input_values,\n",
    "                                                               output_values: test_target_values})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在测试集上获得0.9精度是很好的，您可以通过改变次数来获得更好的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000> 总结</font>\n",
    "\n",
    "在这一章中，我们对神经网络和多层神经网络的需求进行了基本的解释，我们还用一些基本的例子介绍了tensorflow计算图模型，如线性回归和逻辑回归。\n",
    "接下来，我们将介绍更高级的示例，并演示如何使用TensorFlow构建类似于手写字符识别的东西。我们还将处理在传统机器学习中取代特征工程的架构工程的核心思想。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
