{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第07章 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据科学领域，卷积神经网络（Convolutional Neural Network）是一种特别的深度学习架构，它利用卷积运算来提取输入图像的相关解释特征。卷积神经网络是前向反馈的神经网络，尤其是当它在模仿人类识别物品时进行的卷积操作。人类的脑皮层会对特定接收域的刺激进行反应。在特殊情况下，生物医学成像问题有时很具有挑战性，但在这一章，我们将会看到怎么使用卷积神经网络来识别图片中的图案。\n",
    "\n",
    "在本章节中将包含以下几个主题：\n",
    "- 卷积操作\n",
    "- 诱因\n",
    "- 卷积神经网络的不同层\n",
    "- 卷积神经网络的基本案例：MNIST数字分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络在计算机视觉领域已经被广泛的应用，它的性能优于我们所使用的大多数传统的计算机视觉技术。卷积神经网络将著名的卷积运算和神经网络相结合，因此被称为卷积神经网络。因此，在深入研究卷积神经网络的神经网络层之前，我们将介绍卷积运算，看看它是如何发挥作用的。\n",
    "\n",
    "卷积运算的主要目的是从图像中提取信息或特征。任何图像都可以被认为是一个矩阵，并且这个矩阵中的一组特定值将形成一个特征。卷积运算就是扫描这个矩阵，并试图提取该图像的相关解释性特征。例如，考虑下面这幅5乘5的图像，图片中相应的强度或像素值显示为0和1：\n",
    "\n",
    "<img src='./images/2018/10/9.1.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "并考虑以下这个3 \\* 3的矩阵：\n",
    "\n",
    "<img src='./images/2018/10/9.2.png' style='float:center; width:150px;height:150px'/>\n",
    "\n",
    "我们可以使用3\\*3的矩阵将5\\*5矩阵表示的图像转换为下图所示：\n",
    "\n",
    "<img src='./images/2018/10/9.3.1.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.2.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.3.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.4.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.5.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.6.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.7.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.8.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.9.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "\n",
    "上述过程可归纳如下。为了使用这个3\\*3的卷积核将原始的5\\*5的图片进行卷积，我们需要做以下工作：\n",
    "\n",
    "- 用橙色矩阵扫描原始绿色图像，每次仅移动1个像素(步幅)\n",
    "- 对于橙色图像的每个位置，我们在橙色矩阵和绿色矩阵中相应的像素值之间进行元素相乘（点乘）\n",
    "- 将这些按元素进行的乘法运算的结果相加到一起，它将在粉红色矩阵中输出。\n",
    "\n",
    "<img src='./images/2018/10/0001.gif' style='float:center; width:350px;height:300px'/>\n",
    "\n",
    "*从上面的图中可以看到，橙色3乘3的矩阵每次移动时只对原始绿色图像的一部分进行操作(步幅)，或者说一次只能看到一部分图像。*\n",
    "\n",
    "那么，我们就可以在卷积神经网络的背景之下,来看先前的解释：\n",
    "\n",
    "- 橙色的3\\*3的矩阵称为内核、特征检测器、滤镜\n",
    "- 包含元素乘法的结果输出的粉红矩阵称为特征映射。\n",
    "\n",
    "因为特征映射是通过内核与原始图片中相应的像素进行点乘并加和得到的，因此每次更改内核的值将产生不同的特征映射。\n",
    "\n",
    "所以，我们可以认为，在卷积神经网络的训练过程中，需要自己计算出特征检测器的值，但这里不是这样的。卷积神经网络在学习过程中会计算出这些数值。所以，如果我们有更多的滤波器，那就意味着我们能从图片上提取更多的特征。\n",
    "\n",
    "在进入下一个小节之前，我们先来介绍一些在卷积神经网络中使用到的术语：\n",
    "- 步幅（Stride）：之前我们有提到过。一般来说，步幅是指每次在输入的原始图像的像素矩阵上移动特征检测器的像素数。例如，步幅为1是指在进行卷积操作时每次将滤镜移动一个像素，而步幅为2是指进行卷积操作时每次将滤镜移动两个像素。步幅越大，生成的特征映射维数就越小。\n",
    "- 零填充（Zero-padding）：如果我们想要包含输入图像的边框像素，那么部分过滤器将在输入图像之外。而零填充就是在输入图片的边界周围填充零来解决这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 诱因"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大多数计算机视觉任务使用传统的计算机视觉技术来完成，如目标检测和分割。这些技术也一直表现得很好，但是却没有被实时使用，例如在自动驾驶汽车方面。2012年，Alex Krizhevsky介绍了卷积神经网络，并在ImageNet比赛中将目标分类误差从26%提高到15%。从此以后，卷积神经网络被广泛使用，并且已经有不同的变化。卷积神经网络在ImageNet竞争中甚至超越了人类的分类错误，下图是不同识别方法的错误率：\n",
    "\n",
    "<img src='./images/2018/10/9.4.png' style='float:center; width:400px;height:250px'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积神经网络的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自从卷积神经网络在计算机视觉、甚至是自然语言识别等不同的领域取得重大突破之后，大多数公司已经在他们的计算机视觉回波系统中使用深度学习。例如，Google将此架构用于图像搜索引擎，而Facebook将其用于自动标记等等：\n",
    "\n",
    "<img src='./images/2018/10/9.5.png' style='float:center; width:700px;height:270px'/>\n",
    "\n",
    "卷积神经网络能够实现这种突破性进展，是因为这种结构能直观地使用卷积运算从图像中提取特征。在接下来的内容中，你会发现它和人类大脑的工作方式非常相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络的不同层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个典型的卷积神经网络体系结构由多个执行不同任务的层组成，如上面的图所示。在这一节，我们将会详细的了解卷积神经网络，也可以体会它以特殊方式将所有这些连接在计算机视觉中并取得突破的好处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是卷积神经网络架构中的第一层。后续所有的卷积层和池化层期望输入采用特定的格式。输入的变量将成为张量，其形式如下：\n",
    "\n",
    "```python\n",
    "[batch_size,image_width,image_height,channels]\n",
    "```\n",
    "\n",
    "在这里：\n",
    "- batch_size是在随机梯度下降过程中使用的原始训练集中的随机样本。\n",
    "- image_width是输入图片的宽度\n",
    "- image_height是输入图片的长度\n",
    "- channels是输入图片的颜色通道数，对于RGB来说是3，对于二进制图像来说是1\n",
    "\n",
    "例如，考虑我们著名的MNIST数据集。假设我们对这个数据集使用卷积神经网络执行数字分类。\n",
    "\n",
    "就像MNIST那样，如果数据集是由单色28\\*28像素的图片组成，那么我们的输入层所需的形式如下：\n",
    "\n",
    "```python\n",
    "[batch_size,28,28,1]\n",
    "```\n",
    "\n",
    "如果需要更改输入层的形式，可以执行以下操作：\n",
    "\n",
    "```python\n",
    "input_layer = tf.reshape(features['x'],[-1,28,28,1])\n",
    "```\n",
    "\n",
    "*把batch_size定义为-1，那也就意味着这个数字由输入的样本数量动态决定。通过这样做，我们能够通过控制batch_size来微调卷积神经网络*\n",
    "\n",
    "作为进行变化形状的例子，我们把输入的样本分成5个批次，而'x'将包含3920个跟输入的图片相应像素相关联的的值。对于这个MNIST，我们的输入层将是如下这种形状：\n",
    "\n",
    "```python\n",
    "[5,28,28,1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如前所述，卷积步骤是从卷积运算中得到的。卷积步骤的主要目的就是从输入的图片中提取特征，然后将他们提供给线性分类器。\n",
    "\n",
    "在自然图像中，特征可以在图像中的任何地方出现。例如说，边际可能在图片的中间，也可能在角落，所以在卷积步骤中，堆叠一堆卷积步骤的目的就是为了能够从图片的任何地方去探测特征。\n",
    "\n",
    "在TensorFlow中，是很容易去定义一个卷积步骤的。例如，如果我们想用relu激活函数将大小为5\\*5的20个过滤器应用于输入层，那么我们可以使用下面的代码行来实现这一点：\n",
    "\n",
    "```python\n",
    "conv_layer1 = tf.layers.conv2d(inputs=input_layer,filters=20,kernel_size=[5,5],padding='same',activation=tf.nn.relu)\n",
    "```\n",
    "\n",
    "这个conv2d函数的第一个参数是我们在前面的代码中定义的输入层，它具有适当的形状，第二个参数是过滤器参数，它指要有多少个过滤器将被用来处理图片，其中，滤波器数目越多，从输入图像中提取的特征就越多。第三个参数是kernel_size，它表示滤波器或特征检测器的大小。至于我们在这里使用的填充参数'same'是给图片的边缘像素以0来进行填充。而最后一个参数就是在卷积操作最后输出时使用的激活函数。\n",
    "\n",
    "所以，在MNIST中，输入的张量是下面的这种格式：\n",
    "\n",
    "```python\n",
    "[batch_size,28,28,1]\n",
    "```\n",
    "\n",
    "然后，卷积操作之后输出的张量就是下面这种格式：\n",
    "\n",
    "```python\n",
    "[batch_size,28,28,20]\n",
    "```\n",
    "\n",
    "输出的张量跟输入的图片有相同的维度，但是因为我们用了20个滤镜来处理输入的图片，所以我们现在有了20个经过处理的图像。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入非线性的激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在卷积步骤中，我们之前讨论到将卷积步骤的输出提供给ReLU激活函数，所以我们接下来介绍非线性的激活函数。\n",
    "\n",
    "<img src='./images/2018/10/9.6.png' style='float:center; width:600px;height:220px'/>\n",
    "\n",
    "ReLU激活函数将会把像素值是负数的像素直接转换成0，将卷积输出结果提供给这个激活函数的目的就是在输出的图片中应用非线性激活函数，而这个非线性激活函数的所处理的数据对训练过程都是有好处的。为了能够清晰的显示ReLU激活函数的好处，我们可以看下面的图片，右侧的图片就是在左侧的基础上在行上进行卷积操作修复之后的版本：\n",
    "\n",
    "<img src='./images/2018/10/9.7.png' style='float:center; width:700px;height:300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 池化步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习过程的重要步骤之一是池化步骤，而池化步骤有时也被称为缩减像素采样步骤。这一步主要是为了降低特征映射输出的维数。池化步骤的优点就是在保留原始图像重要信息的前提下对输出的特征图像降低尺寸。\n",
    "\n",
    "在下面的图片中就是使用一个尺寸为2\\*2的滤镜并应用最大操作来筛选出来四个值中最大的那个，然后再移动两个像素。跟这个类似的池化操作叫做最大化池化：\n",
    "\n",
    "<img src='./images/2018/10/9.8.png' style='float:center; width:350px;height:350px'/>\n",
    "\n",
    "通过使用下面代码，我们可以将卷积步骤的输出连接到池化层：\n",
    "\n",
    "```python\n",
    "pool_layer1 = tf.layers.max_pooling2d(inputs=conv_layer1,pool_size=[2,2],strides=2)\n",
    "```\n",
    "\n",
    "池化层接收来自卷积步骤的输入，其形式如下：\n",
    "\n",
    "```python\n",
    "[batch_size ,image_width,image_height,channels]\n",
    "```\n",
    "\n",
    "例如说，在我们的数字识别任务中，池化层的输入将会是下面这种格式：\n",
    "\n",
    "```python\n",
    "[batch_size,28,28,20]\n",
    "```\n",
    "\n",
    "池化层输出的结果将会有下面这种结构：\n",
    "\n",
    "```python\n",
    "[batch_size,14,14,20]\n",
    "```\n",
    "\n",
    "在这个例子中，卷积操作输出结果的尺寸将被减少到原来的一半。这个步骤非常有用，因为它在减少模型复杂度的同时还保留了重要的信息，从而避免了过度拟合。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连通层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一系列的卷积和池化步骤之后，接下来的是一个完全连接的神经网络，我们从输入的图片中提取高标准的特征，然后将结果提供给完全连接的神经网络，然后在这个特征基础上做一些实际分类：\n",
    "\n",
    "<img src='./images/2018/10/9.9.png' style='float:center; width:500px;height:200px'/>\n",
    "\n",
    "例如，数字识别分类任务中，我们可以把完全连接的神经网络放在卷积、池化步骤之后，而完全连接的神经网络包含了1024个神经元以及ReLU激活函数来执行实际分类。这个神经网络接受的输入需要具有下面这种格式：\n",
    "\n",
    "```python\n",
    "[batch_size,features]\n",
    "```\n",
    "\n",
    "所以，我们需要重塑（展平）从池化层获取的特征图像来符合我们所需要的格式。我们可以使用下面的这行代码来重新修改池化层的结果：\n",
    "\n",
    "```python\n",
    "pool1_flat = tf.reshape(pool_layer1,[-1,14,14,20])\n",
    "```\n",
    "\n",
    "在这个重塑函数中，我们用-1来显示每一批次的样本数量将会动态决定，而且从池化层输出的每个样本都是14\\*14\\*20的尺寸。\n",
    "\n",
    "所以最后重塑之后的格式将会是下面这种\n",
    "\n",
    "```python\n",
    "[batch_size,3136]\n",
    "```\n",
    "\n",
    "最后，我们可以使用TensorFlow中的Dense函数定义我们的完全连接的神经网络，其中Dense包括所需的神经元数量(单位)和最终的激活函数：\n",
    "\n",
    "```python\n",
    "dense_layer = tf.layers.dense(inputs=pool1_flat,units=1024,activation = tf.nn.relu)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们需要逻辑层，这一层将使用完全连接层输出的结果生成原始的预测值。\n",
    "例如，在数字分类中，输出将是长度为10个的张量，其中每个值代表一个从0-9类的数。所以，我们为这个数字识别分类任务定义逻辑层，在这个层我们只需要10个结果，同时在Dense函数中使用TensorFlow默认的线性激活函数：\n",
    "\n",
    "\n",
    "```python\n",
    "logits_layer = tf.layers.dense(inputs = dense_layer,units=10)\n",
    "```\n",
    "\n",
    "<img src='./images/2018/10/9.10.png' style='float:center; width:600px;height:200px'/>\n",
    "\n",
    "逻辑层最后输出的结构将会是一个具有下面结构的张量矩阵：\n",
    "\n",
    "```python\n",
    "[batch_size,10]\n",
    "```\n",
    "\n",
    "在之前提到的，模型中的逻辑层将会返回一个原始的预测值。但是我们需要将这些值转换成可解释的格式：\n",
    "\n",
    "- 输入样本0-9的预测类\n",
    "- 每个可能类的分数或概率。例如，样本为0的概率是1，以此类推\n",
    "\n",
    "<img src='./images/2018/10/9.11.png' style='float:center; width:700px;height:350px'/>\n",
    "\n",
    "所以，我们预测的类将会是10个结果中具有最高概率值的那个类。我们可以使用argmax函数来得到这个具体的值：\n",
    "\n",
    "```python\n",
    "tf.argmax(input=logits_layer,axis=1)\n",
    "```\n",
    "\n",
    "logits_layer层具有下面这种结构：\n",
    "\n",
    "```python\n",
    "[batch_size,10]\n",
    "```\n",
    "\n",
    "所以，我们需要在预测的结果中找到最大值，而这是索引为1的维度。\n",
    "\n",
    "最后我们可以得到下一个值，它代表着目标类的最大概率，通过将sotfmax激活函数应用到logits_layer层得到的结果，这将把每一个值压缩在0或者1：\n",
    "\n",
    "```python\n",
    "tf.nn.softmax(logits_layer,name=\"softmax_tensor\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络的基本例子--MNIST数字识别分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一节，我们借助MNIST数据集并使用卷积神经网络来做一个完整的数字分类识别。我们将会创建一个具有两层卷积层和完全连接的神经网络层的模型。\n",
    "\n",
    "我们先导入在这个实例中使用到的库：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将会使用TensorFlow辅助函数来下载MNIST数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/MNIST/',one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个数据集将会被分成三个互不相关的数据集：训练集，验证集，测试集。所以，我们打印下各个数据集中图片的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of images in the training set:\t\t55000\n",
      "- Number of images in the test set:\t\t10000\n",
      "- Number of images in the validation set:\t5000\n"
     ]
    }
   ],
   "source": [
    "print('- Number of images in the training set:\\t\\t{}'.format(len(mnist.train.labels)))\n",
    "print('- Number of images in the test set:\\t\\t{}'.format(len(mnist.test.labels)))\n",
    "print('- Number of images in the validation set:\\t{}'.format(len(mnist.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集中图片的真是标签都是被存储为one-hot格式的，所以我们有一个含有10个值的数组，而其中类的索引就是对应图片上的数字。为了之后的使用，我们需要将数据集中的类转换成整型数字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist.test.cls_integer = np.argmax(mnist.test.labels,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再定义一些等下在实例中使用的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST数据集中图片的默认尺寸\n",
    "image_size = 28\n",
    "\n",
    "# 每个图片都被存为跟这个尺寸一样的向量\n",
    "image_size_flat = image_size*image_size\n",
    "\n",
    "# 每个图片的形状\n",
    "image_shape = (image_size,image_size)\n",
    "\n",
    "# 在MNIST数据集中的所有图片的色度都是1，也就是只有黑白两种颜色\n",
    "num_channels = 1\n",
    "\n",
    "# 在MNIST数据集中的数据类是从0到9的10个数据类\n",
    "num_classes = 10\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的滤镜尺寸\n",
    "filter_size_1 = 5\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的滤镜数量\n",
    "filters_1 = 16\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的滤镜尺寸\n",
    "filter_size_2 = 5\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的滤镜数量\n",
    "filters_2 = 36\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的输出神经元个数\n",
    "fc_num_neurons = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要定义一个辅助函数来显示MNIST数据集中的图片。这个辅助函数将会把图片绘画在有9个子图的网格中：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_imgs(imgs,cls_actual,cls_predicted = None):\n",
    "    assert len(imgs) == len(cls_actual) == 9\n",
    "    \n",
    "    # 创建有9个子图的图像来绘画图片\n",
    "    fig,axes = plt.subplots(3,3)\n",
    "    fig.subplots_adjust(hspace = 0.3,wspace = 0.3)\n",
    "\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        \n",
    "        # 在第i个位置绘画图片\n",
    "        ax.imshow(imgs[i].reshape(image_shape),cmap = 'binary')\n",
    "        \n",
    "        # 用图片的真实值和预测的类来对图片进行贴标签\n",
    "        if cls_predicted is None:\n",
    "            xlabel = 'True:{0}'.format(cls_actual[i])\n",
    "        else:\n",
    "            xlabel = 'True:{0},Pred:{1}'.format(cls_actual[i],cls_predicted[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        # 移除图像上的刻度\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        # 将类显示为x轴的标签\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们从测试集中取出图片来进行绘画，然后看一下它是什么样子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKn2wxAEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23b6e226eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 从测试集中取出9个图片进行可视化\n",
    "imgs = mnist.test.images[0:9]\n",
    "\n",
    "# 得到测试集中的9个图片所对应的真实类\n",
    "cls_actual = mnist.test.cls_integer[0:9]\n",
    "\n",
    "# 绘画\n",
    "plot_imgs(imgs = imgs,cls_actual = cls_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "结果正如上面所显示的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在是时候来建立模型的核心部分了，这个计算图包含了所有在这一章提到的层。我们将以定义函数为开始，而这些函数将会被用于定义特定形状的变量，并且会随机初始化它们：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev = 0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05,shape = [length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们将会定义一个函数，这个函数将会基于输入的层、图像通道、滤镜大小、滤镜的数量、是否使用池化参数等来创建卷积层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input是之前层的输出\n",
    "def conv_layer(inputs,input_channels,filter_size,filters,use_pooling=True):\n",
    "    # 在这里使用了2*2的最大池化\n",
    "\n",
    "    #准备输入张量能接受的结构\n",
    "    shape = [filter_size,filter_size,input_channels,filters]\n",
    "\n",
    "    # 创建权重，而这就意味着滤镜要具有给定的结构\n",
    "    filter_weights = new_weights(shape = shape)\n",
    "\n",
    "    # 为每一个滤镜都创建偏差值\n",
    "    filters_biases = new_biases(length = filters)\n",
    "\n",
    "    # 正如我们上面所解释的那牙膏，在这里我们调用conv2d函数\n",
    "    # 同时里面的步长（strides）参数中有四个值，\n",
    "    # 第一个是指图片的数量，最后一个是指的图像的通道数，中间两个代表着滤镜移动的像素数\n",
    "    conv_layer = tf.nn.conv2d(input = inputs,\n",
    "                              filter = filter_weights,\n",
    "                              strides = [1,1,1,1],\n",
    "                              padding = 'SAME')\n",
    "\n",
    "    # 对conv_layer的输出结果增加偏差\n",
    "    conv_layer += filters_biases\n",
    "\n",
    "    # 用池化操作来降低图片的分辨率\n",
    "    if use_pooling:\n",
    "        # 用最大池化层来减小特征地图的输出结果\n",
    "        pool_layer = tf.nn.max_pool(value = conv_layer,\n",
    "                                    ksize = [1,2,2,1],\n",
    "                                    strides = [1,2,2,1],\n",
    "                                    padding = 'SAME')\n",
    "\n",
    "    # 将输出的结果提供给ReLU激活函数\n",
    "    relu_layer = tf.nn.relu(pool_layer)\n",
    "\n",
    "    # 在应用过relu和滤镜权重后，返回最终结果\n",
    "    return relu_layer,filter_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如我们先前提到的，池化层会生成一个四维的张量。我们需要把这个四维张量压平层一个两维的，然后将结果提供给完全连接的神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layers(layer):\n",
    "    # 获取图层的形状\n",
    "    shape = layer.get_shape()\n",
    "\n",
    "    # 我们需要将具有跟[num_images,image_height,image_width,num_channels]\n",
    "    #具有相同形状的图层进行压平处理，然后我们就会有跟[batch_size,num_features]相同尺寸的数据，\n",
    "    # 而其中的num_features的尺寸是image_height*image_width*num_channels\n",
    "    num_features = shape[1:4].num_elements()\n",
    "\n",
    "    # 重塑图片，然后将其提供给完全连接的神经网络\n",
    "    flatten_layer = tf.reshape(layer,[-1,num_features])\n",
    "\n",
    "    # 将压平的图层和要素数量返回\n",
    "    return flatten_layer,num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来的函数创建了一个完全连接神经网络，同时也假设输入的数据是一个两维的张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input 压平之后的输出结果\n",
    "# num_inputs 来自上一层的输入数量\n",
    "# num_outputs 输出的数量\n",
    "# use_relu 在结果中使用ReLU激活函数来移除其中的负值\n",
    "def fc_layer(inputs,num_inputs,num_outputs,use_relu = True):\n",
    "    # 为这一层的神经元创建权重\n",
    "    fc_weights = new_weights(shape = [num_inputs,num_outputs])\n",
    "    fc_biases = new_biases(length = num_outputs)\n",
    "\n",
    "    # 通过对输入的值和权重进行矩阵相乘然后再加上偏差，来计算这一层的值\n",
    "    fc_layer = tf.matmul(inputs,fc_weights) + fc_biases\n",
    "\n",
    "    # 如果使用ReLU激活函数的话\n",
    "    if use_relu:\n",
    "        relu_layer = tf.nn.relu(fc_layer)\n",
    "        return relu_layer\n",
    "    return fc_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在建立模型前，先为输入的图像定义一个占位符，其中第一个参数是None，也就意味着可能是任意数量的图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_values = tf.placeholder(tf.float32,shape = [None,image_size_flat],\\\n",
    "                              name='input_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如我们之前提到的，我们需要输入到卷积步骤中的图片是需要一个四维的张量，所以我们需要把输入的图片重塑为下列的结构：\n",
    "\n",
    "[num_images,image_height,image_width,num_channels]\n",
    "\n",
    "所以，我们把输入的值进行重塑以满足下面的格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = tf.reshape(input_values,[-1,image_size,image_size,num_channels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要另外再定义一个占位符来存储事实类，而这个类值是一个one-hot编码格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_actual = tf.placeholder(tf.float32,shape = [None,num_classes],name = 'y_actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时，我们也需要定义一个变量来存储真实类的真实值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_actual_cls_integer = tf.argmax(y_actual,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "那么，接下来就是开始建立第一个卷积层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer_1,conv1_weights = conv_layer(inputs = input_image,\n",
    "                            input_channels = num_channels,\n",
    "                            filter_size = filter_size_1,\n",
    "                            filters = filters_1,\n",
    "                            use_pooling = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来检查下第一个卷积层输出结果的具体形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将创建第二个卷积网络，然后将第一个结果提交给它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer_2,conv2_weights = conv_layer(inputs = conv_layer_1,\n",
    "                            input_channels = filters_1,\n",
    "                            filter_size = filter_size_2,\n",
    "                            filters = filters_2,\n",
    "                            use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们需要第二次检查第二个的卷积层的输出结果，而其输出加过应该是(?,7,7,36),问号所代表的可以是任何数量的图像。\n",
    "\n",
    "接下来，我们需要把卷积层结果的四维张量处理成二维的，以便将结果提供给完全连接的神经网络：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten_layer,number_features = flatten_layers(conv_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要再次检查一下平坦层输出结果的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将创建一个完全连接层，并且将平坦层的结果提供给它。同时，我们也将完全连接层的结果用ReLU激活函数来处理，然后再提交给随后的完全连接层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_layer_1 = fc_layer(inputs = flatten_layer,\n",
    "                      num_inputs = number_features,\n",
    "                      num_outputs = fc_num_neurons,\n",
    "                      use_relu = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还需要再次检查第一个完全连接层的输出结果的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(fc_layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要添加另一个完全连接层，这个完全连接层将会把第一个完全连接层的结果当作输入，而且为每个图像生成一个大小为10的数组，表示每个目标类的分数是正确的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_layer_2 = fc_layer(inputs = fc_layer_1,\n",
    "                      num_inputs = fc_num_neurons,\n",
    "                      num_outputs = num_classes,\n",
    "                      use_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_3:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(fc_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将从第二个完全连接的层中对这些分数进行归一化，并将其提供给softmax激活函数，该函数将校准值压缩到介于0和1之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = tf.nn.softmax(fc_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们需要用TensorFlow的argmax函数，来提取概率最大的那个目标类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_cls_integer = tf.argmax(y_predicted,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要定义绩效指标，也就是交叉熵。如果预测是正确的话，那么交叉熵的值则为0："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-95a4299d59ab>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = fc_layer_2,\n",
    "                                                        labels = y_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们需要平均从上一步得到的所有交叉熵值，以便能够在测试集上获得单一的性能指标："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们有了一个需要被优化（最小化）的损失函数，所以我们将会用AdamOptimizer函数，这个函数是跟梯度下降类似，但是更加先进："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_optimizer = tf.train.AdamOptimizer(learning_rate = 1e-4).minimize(model_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了展示输出的结果，我们会定义一个变量来检查预测的类和真实类是否相等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_correct_prediction = tf.equal(y_predicted_cls_integer,y_actual_cls_integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过转换布尔值来计算模型精度，然后对它们求平均值以对正确分类的值求和："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_accuracy = tf.reduce_mean(tf.cast(model_correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过创建session变量来开始训练过程，而这个变量也将负责执行我们之前定义的计算图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时，我们也需要初始化我们之前定义的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们会批次提供图片数量来避免内存溢出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们开始训练过程前，我们将会先定义一个辅助函数，通过迭代训练批来执行优化过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 迭代优化的次数\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    \n",
    "    # 将迭代次数变量进行全局更新\n",
    "\tglobal total_iterations\n",
    "\tfor i in range(total_iterations,total_iterations + num_iterations):\n",
    "\t\t\n",
    "\t\t# 为训练过程随机生成批次\n",
    "\t\t# input_batch包含从训练集中获取的图片，而y_actual_batch是所对应的图片的事实标签\n",
    "\t\tinput_batch,y_actual_batch = mnist.train.next_batch(train_batch_size)\n",
    "        \n",
    "\t\t# 将先前的值放在TensorFlow的dict格式中\n",
    "        # 以自动将它们分配给我们在上面定义的输入占位符。\n",
    "\t\tfeed_dict = {input_values:input_batch,y_actual:y_actual_batch}\n",
    "        \n",
    "\t\t# 接下来，我们将会在这个批次的图片上进行模型优化：\n",
    "\t\tsession.run(model_optimizer,feed_dict = feed_dict)\n",
    "        \n",
    "\t\t# 每进行100次迭代之后，打印训练状态：\n",
    "\t\tif i%100 == 0:\n",
    "            \n",
    "\t\t\t# 测量训练集的准确度\n",
    "\t\t\tacc_training_set = session.run(model_accuracy,feed_dict = feed_dict)\n",
    "\t\t\t# 打印训练集的准确度\n",
    "\t\t\tprint('Iteration:',\\\n",
    "                  '{0:> 6},Accuracy Over the training set:{1:>6.1%}'.format(i + 1,\\\n",
    "                                                                    acc_training_set))\n",
    "\t\t# 更新到目前执行迭代的次数 \n",
    "\ttotal_iterations += num_iterations\n",
    "\tprint(total_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们将定义一些辅助函数来帮助我们进行模型结果的可视化，然后来看下哪些图片被模型错误的分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_errors(cls_predicted, correct):\n",
    "\t# cls_predicted是测试集中每个图像的预测类号的数组。\n",
    "    \n",
    "\t# 提取错误的图片\n",
    "\tincorrect = (correct == False)\n",
    "    \n",
    "\t# 从测试集中得到被模型错误分类的图片\n",
    "\timages = mnist.test.images[incorrect]\n",
    "    \n",
    "\t# 获取那些不正确图像的预测类\n",
    "\tcls_pred = cls_predicted[incorrect]\n",
    "    \n",
    "\t# 获取那些不正确图像的真实类\n",
    "\tcls_true = mnist.test.cls_integer[incorrect]\n",
    "    \n",
    "\t# 绘画9个图片\n",
    "\tplot_imgs(imgs = images[0:9],cls_actual = cls_true[0:9],\n",
    "              cls_predicted = cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以绘制预测结果与实际真实类别的混淆矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusionMatrix(cls_predicted):\n",
    "    \n",
    "\t# cls_predicted是测试集中每个图像的预测类号的数组。\n",
    "\t# 从测试集中获取真实类\n",
    "\tcls_actual = mnist.test.cls_integer\n",
    "    \n",
    "\t# 用sklearn来生成混淆矩阵\n",
    "\tconf_matrix = confusion_matrix(y_true = cls_actual,y_pred = cls_predicted)\n",
    "    \n",
    "\t# 打印矩阵\n",
    "\tprint(conf_matrix)\n",
    "    \n",
    "\t# 可视化混淆矩阵\n",
    "\tplt.matshow(conf_matrix)\n",
    "\tplt.colorbar()\n",
    "\ttick_marks = np.arange(num_classes)\n",
    "\tplt.xticks(tick_marks,range(num_classes))\n",
    "\tplt.yticks(tick_marks,range(num_classes))\n",
    "\tplt.xlabel('Predicted class')\n",
    "\tplt.ylabel('True class')\n",
    "    \n",
    "\t# 展示绘画\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们将会定义一个辅助函数来帮助我们测量训练模型在测试集上的准确性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "def test_accuracy(show_errors = False,show_confusionMatrix = False):\n",
    "    \n",
    "\t# 图片的数量\n",
    "\tnumber_test = len(mnist.test.images)\n",
    "    \n",
    "\t#为测试集的预测类定义一个零数组，将以小批量数据来测量并存储它\n",
    "\tcls_predicted = np.zeros(shape = number_test,dtype = np.int)\n",
    "    \n",
    "\t# 用测试集中的批次来测量预测类，以索引0的批次为开始\n",
    "\ti = 0\n",
    "\twhile i < number_test:\n",
    "        \n",
    "\t\t#要处理的下一批的结束索引是j\n",
    "\t\tj = min(i + test_batch_size,number_test)\n",
    "        \n",
    "\t\t#从开始和结束索引之间获取测试集中的所有图像\n",
    "\t\tinput_images = mnist.test.images[i:j,:]\n",
    "        \n",
    "\t\t# 得到这些图片的真实标签值\n",
    "\t\tactual_labels = mnist.test.labels[i:j,:]\n",
    "        \n",
    "\t\t#使用输入占位符值的相应值创建feed-dict\n",
    "\t\tfeed_dict = {input_values:input_images,y_actual:actual_labels}\n",
    "\t\tcls_predicted[i:j] = session.run(y_predicted_cls_integer,feed_dict = feed_dict)\n",
    "        \n",
    "\t\t# 将下一批的开始设置为我们刚刚处理的j的结束\n",
    "\t\ti = j\n",
    "        \n",
    "\t#获取测试图像的实际类号\n",
    "\tcls_actual = mnist.test.cls_integer\n",
    "    \n",
    "\t# 检查模型的预测是否正确\n",
    "\tcorrect = (cls_actual == cls_predicted)\n",
    "    \n",
    "\t# 对正确样例进行求和\n",
    "\tcorrect_number_images = correct.sum()\n",
    "    \n",
    "\t#通过将正确的分类与测试集中的图像总数相除来测量精度\n",
    "\ttestset_accuracy = float(correct_number_images)/number_test\n",
    "    \n",
    "\t# 展示准确性\n",
    "\tprint('Accuracy on Test-Set:{0:.1%} ({1}/{2})'.format(testset_accuracy,\n",
    "                                              correct_number_images,number_test))\n",
    "    \n",
    "\t# 显示一些不正确的例子\n",
    "\tif show_errors:\n",
    "\t\tprint('Example errors:')\n",
    "\t\tplot_errors(cls_predicted = cls_predicted,correct = correct)\n",
    "        \n",
    "\t#显示测试集预测的混淆矩阵\n",
    "\tif show_confusionMatrix:\n",
    "\t\tprint('Confusion Matrix:')\n",
    "\t\tplot_confusionMatrix(cls_predicted = cls_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在测试集上打印创建的模型的准确性，而不进行任何优化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set:7.1% (713/10000)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们通过运行一次迭代的优化过程，了解优化过程实际上增强了模型功能，以将图像分类到正确的类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,Accuracy Over the training set: 12.5%\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们迭代10000次的来进行优化过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    101,Accuracy Over the training set: 45.3%\n",
      "Iteration:    201,Accuracy Over the training set: 75.0%\n",
      "Iteration:    301,Accuracy Over the training set: 84.4%\n",
      "Iteration:    401,Accuracy Over the training set: 85.9%\n",
      "Iteration:    501,Accuracy Over the training set: 92.2%\n",
      "Iteration:    601,Accuracy Over the training set: 90.6%\n",
      "Iteration:    701,Accuracy Over the training set: 93.8%\n",
      "Iteration:    801,Accuracy Over the training set: 89.1%\n",
      "Iteration:    901,Accuracy Over the training set: 87.5%\n",
      "Iteration:   1001,Accuracy Over the training set: 96.9%\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们来检测模型将如何概括测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set:92.5% (9250/10000)\n",
      "Example errors:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23b708dbac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 955    0    1    5    0    4   10    2    3    0]\n",
      " [   0 1106    2    7    0    2    5    0   13    0]\n",
      " [  12    2  928   28   15    1   13   17   16    0]\n",
      " [   2    2    6  971    0    5    0   12   11    1]\n",
      " [   1    2    3    2  926    1   17    3    3   24]\n",
      " [   8    1    2   65    5  781   20    2    7    1]\n",
      " [  10    3    2    3    8   17  913    0    2    0]\n",
      " [   0    9   21   14    5    1    0  956    1   21]\n",
      " [  11    4    5   68    9   19   10   12  829    7]\n",
      " [  10    5    8   22   35    7    0   34    3  885]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD3CAYAAAA+C7CYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23b708db278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_accuracy(show_errors = True,show_confusionMatrix = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有趣的是，在使用基本卷积网络时，我们实际上在测试中获得了近93％的准确率。这个实现和结果向您展示了一个简单的卷积网络可以做什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一章中，我们已经涵盖了TensorFlow中CNN直觉和技术细节。我们还看了一下如何在TensorFlow中实现CNN的基本架构。\n",
    "在下一章节，我们将会演示更高级的架构，可用于检测数据科学家广泛使用的图像数据集中的对象。我们还将看到CNN的美丽以及它们如果像人类那样在首次认识到物体的基本特征，然后在这之上构建更高级的语义特征来对它们进行分类。尽管，这些步骤在我们大脑中进行的很快，而这的确是我们在辨认物体时所发生的。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
