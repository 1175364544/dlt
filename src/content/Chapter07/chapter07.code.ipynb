{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/MNIST',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of images in the training set:\t\t55000\n",
      "- Number of images in the test sets:\t\t10000\n",
      "- Number of images in the validation set:\t\t5000\n"
     ]
    }
   ],
   "source": [
    "print('- Number of images in the training set:\\t\\t{}'.format(len(mnist.train.labels)))\n",
    "print('- Number of images in the test sets:\\t\\t{}'.format(len(mnist.test.labels)))\n",
    "print('- Number of images in the validation set:\\t\\t{}'.format(len(mnist.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist.test.cls_integer = np.argmax(mnist.test.labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "image_size_flat = image_size*image_size\n",
    "image_shape = (image_size,image_size)\n",
    "num_channel = 1\n",
    "num_classes = 10\n",
    "filter_size_1 = 5\n",
    "filters_1 = 16\n",
    "filter_size_2 = 5\n",
    "filters_2 = 36\n",
    "fc_num_neurons = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_imgs(imgs,cls_actual,cls_predicted=None):\n",
    "    assert len(imgs) == len(cls_actual) == 9\n",
    "    fig,axes = plt.subplots(3,3)\n",
    "    fig.subplots_adjust(hspace=0.3,wspace=0.3)\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        ax.imshow(imgs[i].reshape(image_shape),cmap='binary')\n",
    "    if cls_predicted is None:\n",
    "        xlabel = 'True:{0}'.format(cls_actual[i])\n",
    "    else:\n",
    "        xlabel = 'True:{0},Pred:{1}'.format(cls_actual[i],cls_predicted[i])\n",
    "    ax.set_xticks([]);ax.set_yticks([])\n",
    "    ax.set_xlabel(xlabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAD8CAYAAADKdkf7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a81a296b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = mnist.test.images[0:9]\n",
    "cls_actual = mnist.test.cls_integer[0:9]\n",
    "plot_imgs(imgs=imgs,cls_actual=cls_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05,shape=[length]))\n",
    "\n",
    "def conv_layer(input,input_channels,filter_size,filters,use_pooling=True):\n",
    "    shape = [filter_size,filter_size,input_channels,filters]\n",
    "    filters_weights = new_weights(shape=shape)\n",
    "    filters_biases = new_biases(length=filters)\n",
    "    \n",
    "    conv_layer = tf.nn.conv2d(input=input,\n",
    "                              filter=filters_weights,\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              padding='SAME')\n",
    "    conv_layer += filters_biases\n",
    "    if use_pooling:\n",
    "        pool_layer = tf.nn.max_pool(value=conv_layer,\n",
    "                                    ksize=[1,2,2,1],\n",
    "                                    strides=[1,2,2,1],\n",
    "                                    padding='SAME')\n",
    "    relu_layer = tf.nn.relu(pool_layer)\n",
    "    return relu_layer,filters_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    shape = layer.get_shape()\n",
    "    number_features = shape[1:4].num_elements()\n",
    "    flatten_layer = tf.reshape(layer,[-1,number_features])\n",
    "    return flatten_layer,number_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(input,num_inputs,num_outputs,use_relu=True):\n",
    "    fc_weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "    fc_biases = new_biases(length=num_outputs)\n",
    "    fc_layer = tf.matmul(input,fc_weights) + fc_biases\n",
    "    if use_relu:\n",
    "        relu_layer = tf.nn.relu(fc_layer)\n",
    "        return relu_layer\n",
    "    return fc_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_values = tf.placeholder(tf.float32,shape=[None,image_size_flat])\n",
    "input_image = tf.reshape(input_values,[-1,image_size,image_size,num_channel])\n",
    "y_actual = tf.placeholder(tf.float32,shape=[None,num_classes],name='y_actual')\n",
    "y_actual_cls_integer = tf.argmax(y_actual,axis=1)\n",
    "conv_layer_1,conv1_weights = conv_layer(input=input_image,\n",
    "                                        input_channels=num_channel,\n",
    "                                        filter_size = filter_size_1,\n",
    "                                        filters=filters_1,\n",
    "                                        use_pooling=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer_2,conv2_weights = conv_layer(input =conv_layer_1,\n",
    "                                        input_channels=filters_1,\n",
    "                                        filter_size=filter_size_2,\n",
    "                                        filters = filters_2,\n",
    "                                        use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten_layer,number_features = flatten_layer(conv_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_layer_1 = fc_layer(input = flatten_layer,\n",
    "                      num_inputs = number_features,\n",
    "                      num_outputs=fc_num_neurons,\n",
    "                      use_relu =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_layer_2 = fc_layer(input=fc_layer_1,\n",
    "                      num_inputs = fc_num_neurons,\n",
    "                      num_outputs=num_classes,\n",
    "                      use_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = tf.nn.softmax(fc_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_cls_integer = tf.argmax(y_predicted,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-f17636ccc1c4>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=fc_layer_2,\n",
    "                                                        labels=y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(model_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_correct_prediction = tf.equal(y_predicted_cls_integer,y_actual_cls_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_accuracy = tf.reduce_mean(tf.cast(model_correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    for i in range(total_iterations,total_iterations+num_iterations):\n",
    "        input_batch,y_actual_batch = mnist.train.next_batch(train_batch_size)\n",
    "        feed_dict = {input_values:input_batch,\n",
    "                     y_actual : y_actual_batch}\n",
    "        session.run(model_optimizer,feed_dict=feed_dict)\n",
    "        if i%100 ==0:\n",
    "            acc_training_set = session.run(model_accuracy,feed_dict=feed_dict)\n",
    "            print('Iteration:{0:>6},Accuracy Over the training set:{1:>6.1%}'.\\\n",
    "                  format(i + 1,acc_training_set))\n",
    "    total_iterations += num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_errors(cls_predicted,correct):\n",
    "    incorrect = (correct==False)\n",
    "    images = mnist.test.images[incorrect]\n",
    "    cls_pred = cls_predicted[incorrect]\n",
    "    cls_true = mnist.test.cls_integer[incorrect]\n",
    "    plot_imgs(imgs=imgs[0:9],\n",
    "             cls_actual = cls_actual[0:9],\n",
    "             cls_predicted = cls_predicted[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusionMatrix(cls_predicted):\n",
    "    cls_actual = mnist.test.cls_integer\n",
    "    conf_matrix = confusion_matrix(y_true=cls_actual,\n",
    "                                  y_pred=cls_predicted)\n",
    "    print(conf_matrix)\n",
    "    plt.matshow(conf_matrix)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks,range(num_classes))\n",
    "    plt.yticks(tick_marks,range(num_classes))\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.ylabel('True class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_accuracy(show_errors = False,show_confusionMatrix=False):\n",
    "    number_test = len(mnist.test.images)\n",
    "    cls_predicted = np.zeros(shape=number_test,dtype=np.int)\n",
    "    i = 0\n",
    "    while i < number_test:\n",
    "        j = min(i + test_batch_size,number_test)\n",
    "        input_images = mnist.test.images[i:j,:]\n",
    "        actual_labels = mnist.test.labels[i:j,:]\n",
    "        feed_dict = {input_values:input_images,\n",
    "                    y_actual:actual_labels}\n",
    "        cls_predicted[i:j] = session.run(y_predicted_cls_integer,feed_dict=feed_dict)\n",
    "        i = j\n",
    "    cls_actual = mnist.test.cls_integer\n",
    "    correct = (cls_actual ==cls_predicted)\n",
    "    correct_number_images = correct.sum()\n",
    "    testset_accuracy = float(correct_number_images)/number_test\n",
    "    print('Accuracy on Test_Set:{0:1%} ({1}/{2})'.format(testset_accuracy,correct_number_images,number_test))\n",
    "    if show_errors:\n",
    "        print('Example errors:')\n",
    "        plot_errors(cls_predicted=cls_predicted,correct=correct)\n",
    "    if show_confusionMatrix:\n",
    "        print('Confusion Matrix:')\n",
    "        plot_confusionMatrix(cls_predicted=cls_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test_Set:10.180000% (1018/10000)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:     1,Accuracy Over the training set:  6.2%\n",
      "Iteration:   101,Accuracy Over the training set: 54.7%\n",
      "Iteration:   201,Accuracy Over the training set: 85.9%\n",
      "Iteration:   301,Accuracy Over the training set: 87.5%\n",
      "Iteration:   401,Accuracy Over the training set: 82.8%\n",
      "Iteration:   501,Accuracy Over the training set: 82.8%\n",
      "Iteration:   601,Accuracy Over the training set: 92.2%\n",
      "Iteration:   701,Accuracy Over the training set: 90.6%\n",
      "Iteration:   801,Accuracy Over the training set: 90.6%\n",
      "Iteration:   901,Accuracy Over the training set: 90.6%\n",
      "Iteration:  1001,Accuracy Over the training set: 89.1%\n",
      "Iteration:  1101,Accuracy Over the training set: 92.2%\n",
      "Iteration:  1201,Accuracy Over the training set: 95.3%\n",
      "Iteration:  1301,Accuracy Over the training set: 96.9%\n",
      "Iteration:  1401,Accuracy Over the training set: 93.8%\n",
      "Iteration:  1501,Accuracy Over the training set: 93.8%\n",
      "Iteration:  1601,Accuracy Over the training set: 89.1%\n",
      "Iteration:  1701,Accuracy Over the training set: 93.8%\n",
      "Iteration:  1801,Accuracy Over the training set: 98.4%\n",
      "Iteration:  1901,Accuracy Over the training set: 98.4%\n",
      "Iteration:  2001,Accuracy Over the training set: 95.3%\n",
      "Iteration:  2101,Accuracy Over the training set: 98.4%\n",
      "Iteration:  2201,Accuracy Over the training set: 92.2%\n",
      "Iteration:  2301,Accuracy Over the training set: 96.9%\n",
      "Iteration:  2401,Accuracy Over the training set: 96.9%\n",
      "Iteration:  2501,Accuracy Over the training set: 95.3%\n",
      "Iteration:  2601,Accuracy Over the training set: 96.9%\n",
      "Iteration:  2701,Accuracy Over the training set: 96.9%\n",
      "Iteration:  2801,Accuracy Over the training set: 93.8%\n",
      "Iteration:  2901,Accuracy Over the training set: 96.9%\n",
      "Iteration:  3001,Accuracy Over the training set: 96.9%\n",
      "Iteration:  3101,Accuracy Over the training set: 98.4%\n",
      "Iteration:  3201,Accuracy Over the training set:100.0%\n",
      "Iteration:  3301,Accuracy Over the training set:100.0%\n",
      "Iteration:  3401,Accuracy Over the training set: 96.9%\n",
      "Iteration:  3501,Accuracy Over the training set:100.0%\n",
      "Iteration:  3601,Accuracy Over the training set: 95.3%\n",
      "Iteration:  3701,Accuracy Over the training set: 95.3%\n",
      "Iteration:  3801,Accuracy Over the training set: 98.4%\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_accuracy(show_errors=True,show_confusionMatrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
