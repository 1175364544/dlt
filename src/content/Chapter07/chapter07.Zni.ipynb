{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第07章 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据科学领域，卷积神经网络（Convolutional Neural Network）是一种特别的深度学习架构，它使用卷积操作来从输入的图片中提取解释性特征。卷积神经网络是前向反馈的神经网络，尤其是当它在模仿人类识别物品时进行的卷积操作。人类的脑皮层会对特定接收域的刺激进行反应。在特殊情况下，生物医学成像问题时常是具有挑战性的问题，但是在这一章节，我们将会看到怎么使用卷积神经网络来识别图片中的图案。\n",
    "\n",
    "在本章节中将包含以下几个主题：\n",
    "- 卷积操作\n",
    "- 诱因\n",
    "- 卷积神经网络的不同层\n",
    "- 基本的卷积神经网络案例：MNIST数字分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络在计算机视觉领域有广泛的使用，而且它们表现的比我们一直使用的传统的计算机视觉技术要好。卷积神经网络结合了著名的卷积操作和神经网络，因此就成就了卷积神经网络。所以，在进入卷积神经网络的神经网络层之前，我们将会先介绍下卷积操作以及它是怎么发挥作用的。\n",
    "\n",
    "卷积操作的目的是为了从图片中提取信息或者说是特征，任何图片都被认为是一些特殊值矩阵或者是一组特殊的值，而在矩阵中会形成一些特征。卷积操作就是了扫描这个矩阵，然后试图从里面提取与图片相关或者是解释性的特征。例如说，对了下面这个5 \\* 5的图片，其图片中对应的强度和像素值显示为0和1：\n",
    "\n",
    "<img src='./images/2018/10/9.1.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "然后是一个3 \\* 3的矩阵：\n",
    "\n",
    "<img src='./images/2018/10/9.2.png' style='float:center; width:150px;height:150px'/>\n",
    "\n",
    "我们用一个 3 \\* 3 的矩阵来卷积 5 \\* 5的图片：\n",
    "\n",
    "<img src='./images/2018/10/9.3.1.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.2.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.3.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.4.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.5.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.6.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.7.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.8.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "<img src='./images/2018/10/9.3.9.png' style='float:center; width:190px;height:150px'/>\n",
    "\n",
    "\n",
    "上图可以归纳如下。为了用一个3\\*3的卷积核形对原始的5\\*5的图片进行卷积，我们需要按照下面的步骤进行：\n",
    "- 用橙色的矩阵对原始的绿色图片内容进行扫描，然后每次移动一个像素\n",
    "- 在橙色的矩阵和原始的绿色矩阵中对对应位置的元素进行相乘（点乘）\n",
    "- 对每次对应位置相乘（点乘）的结果进行相加，然后得到一个数字，随着橙色矩阵的每次移动，就会生成一个相对应的数字，最后也就形成了上面粉红色的矩阵\n",
    "\n",
    "<img src='./images/2018/10/0001.gif' style='float:center; width:350px;height:300px'/>\n",
    "\n",
    "*正如你从上图看到的，橙色的矩阵每移动一个像素就只会操作绿色图片上的一部分，或者说它只能看到一部分。*\n",
    "\n",
    "所以，我们就可以在卷积神经网络的背景之下,来看下先前的解释：\n",
    "\n",
    "- 橙色的3\\*3的矩阵称为内核、特征检测器、滤镜\n",
    "- 橙色矩阵与绿色矩阵的某些部分点乘并对点乘结果进行求和产生粉红色矩阵中的一个元素，继而随着移动而产生的粉红色矩阵被称为特征映射\n",
    "\n",
    "因为特征映射是通过滤镜与原始图片中关联的像素进行点乘并加和得到的，并且每次改变滤镜时候，就会得到不同的特征映射。\n",
    "\n",
    "所以，在卷积神经网络的训练期间，我们需要搞清楚特征探测器（滤镜）的值，但是这个问题我们不做讨论。卷积神经网络会在学习过程中来探究这些值。所以，如果我们用越多的滤镜，那就意味着我们能从图片上提取越多的特征。\n",
    "\n",
    "在进入下一个小节之前，我们先来介绍一些在卷积神经网络背景下使用的术语：\n",
    "- 步长（Stride）：早些时候我们有提到过，在通常情况下，步长指的是我们用滤镜在原始输入的矩阵中移动的像素数。例如，步长是1就是指在进行卷积操作时每次将滤镜移动一个像素，而步长是2是指进行卷积操作时每次将滤镜移动两个像素。步长越长，那么我们生成的特征映射就越小\n",
    "- 零填充（Zero-padding）：如果我们要包含原始输入图片边界上的元素，那么我们就需要把滤镜的一部分放到输入图片的边界外，而零填充就是在输入图片的边界外填充零，防止在进行运算时图片与滤镜相应位置没有值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 诱因"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在物体检测和分割上，传统的计算机视觉技术被用来执行大多数的计算机视觉任务，这些技术也一直表现得很好，但是却没有被实时使用，例如是在自动驾驶汽车方面。在2012年，Alex Krizhevsky介绍了在ImageNet比赛中将识别物品以及分类错误从26%降到了15%的卷积神经网络。卷积神经网络现在已经被广泛使用，并且也已经有不同的变化。卷积神经网络也在ImageNet比赛中表现得比人类的分类错误还要低，下图是不同识别方法的错误率：\n",
    "\n",
    "<img src='./images/2018/10/9.4.png' style='float:center; width:400px;height:250px'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积神经网络的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自从卷积神经网络在计算机视觉、甚至是自然语言识别等不同的领域取得重大突破之后，更多的公司开始在他们计算机视觉回声系统中使用深度学习。例如谷歌公司就在图片搜索引擎中使用了这种架构，以及脸书公司也用这种结构来自动添加标签以及其他方面的使用。\n",
    "\n",
    "<img src='./images/2018/10/9.5.png' style='float:center; width:700px;height:270px'/>\n",
    "\n",
    "卷积神经网络能够实现这种突破性进展，是因为这种结构能用卷积操作从图片中提取特征。在接下来的内容中，你会发现这种方式跟人类大脑的工作方式非常相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络的不同层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就像上面图片所展示的那样，卷积神经网络是包含不同的层，而每层都是执行着不同的任务。在这一节，我们将会详细的了解卷积神经网络，也可以体会它以特殊方式将所有这些连接在计算机视觉中并取得突破的好处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对任何卷积神经网络来说，输入层都是作为第一层出现的。后续的所有的卷积层和池化层都对输入有特殊的格式要求。输入的变量是一维张量，类似于下面的结构\n",
    "\n",
    "```python\n",
    "[batch_size,image_width,image_height,channels]\n",
    "```\n",
    "\n",
    "在这里：\n",
    "- batch_size是从原始训练集中获取的随机样本，之后会对其进行随机梯度下降处理\n",
    "- image_width是输入图片的宽度\n",
    "- image_height是输入图片的长度\n",
    "- channels是输入图片的颜色通道数，对于RGB来说是3，对于二进制图像来说是1\n",
    "\n",
    "例如，著名的MNIST就是此类。我们利用这个数据集并借助用卷积神经网络来进行数字识别。\n",
    "\n",
    "就像MNIST那样，如果数据集是由28\\*28像素的图片组成，那么就需要特殊的输入结构，就像下面那样：\n",
    "\n",
    "```python\n",
    "[batch_size,28,28,1]\n",
    "```\n",
    "\n",
    "为了改变输入要素的形状，我们可以做如下的变换：\n",
    "\n",
    "```python\n",
    "input_layer = tf.reshape(features['x'],[-1,28,28,1])\n",
    "```\n",
    "\n",
    "*把batch_size定义为-1，那也就意味着这个数字由输入的样本数量动态决定。通过这样做，我们能够通过控制batch_size来微调卷积神经网络*\n",
    "\n",
    "作为进行变化形状的例子，我们把输入的样本分成5个批次，而'x'将包含3920个跟输入的图片相应像素相关联的的值。对于这个MNIST，我们的输入层将是如下这种形状：\n",
    "\n",
    "```python\n",
    "[5,28,28,1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就像之前提到的，卷积步骤就是从卷积操作得来的名字。卷积步骤的主要目的就是从输入的图片中提取特征，然后将他们提供给线性分类器。\n",
    "\n",
    "在自然的图片中，特征可能在任何位置。例如说，边际可能在图片的中间，也可能在角落，所以在卷积步骤中，堆叠一堆的目的就是为了能够从图片的任何地方去探测特征。\n",
    "\n",
    "在TensorFlow中，是很容易去定义一个卷积步骤的。例如说，如果我们将20个5\\*5的滤镜应用到输入层，而且还想用ReLU激活函数来处理的话，那么我们就需要用下面的代码：\n",
    "\n",
    "```python\n",
    "conv_layer1 = tf.layers.conv2d(inputs=input_layer,filters=20,kernel_size=[5,5],padding='same',activation=tf.nn.relu)\n",
    "```\n",
    "\n",
    "这个conv2d里面第一个参数是我们之前提到的输入层，第二个参数是指要有多少个滤镜将被用来处理图片，越多的滤镜，那么就有越多的特征元素被提取。第三个参数代表着滤镜或者说特征探测器的尺寸。至于我们在这里使用的填充参数'same'是给图片的边缘像素以0来进行填充。而最后一个参数就是在卷积操作最后输出时使用的激活函数。\n",
    "\n",
    "所以，在MNIST中，输入的张量是下面的这种格式：\n",
    "\n",
    "```python\n",
    "[batch_size,28,28,1]\n",
    "```\n",
    "\n",
    "然后，卷积操作之后输出的张量就是下面这种格式：\n",
    "\n",
    "```python\n",
    "[batch_size,28,28,20]\n",
    "```\n",
    "\n",
    "输出的张量跟输入的图片有相同的维度，但是因为我们用了20个滤镜来处理输入的图片，所以我们现在有了20个经过处理的图像。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入非线性的激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在卷积步骤中，我们之前讨论到将卷积步骤的输出提供给ReLU激活函数，所以我们接下来介绍非线性的激活函数。\n",
    "\n",
    "<img src='./images/2018/10/9.6.png' style='float:center; width:600px;height:220px'/>\n",
    "\n",
    "ReLU激活函数将会把像素值是负数的像素直接转换成0，将卷积输出结果提供给这个激活函数的目的就是在输出的图片中应用非线性激活函数，而这个非线性激活函数的所处理的数据对训练过程都是有好处的。为了能够清晰的显示ReLU激活函数的好处，我们可以看下面的图片，右侧的图片就是在左侧的基础上在行上进行卷积操作修复之后的版本：\n",
    "\n",
    "<img src='./images/2018/10/9.7.png' style='float:center; width:700px;height:300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 池化步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于深度学习的过程来说，池化步骤是最重要的步骤之一，而池化步骤有时也被称为缩减像素采样步骤。这一步骤主要就是用来减小卷积操作之后的特征图像的维度的。池化步骤的优点就是在保留原始图像重要信息的前提下对输出的特征图像降低尺寸。\n",
    "在下面的图片中就是使用一个尺寸为2\\*2的滤镜并应用最大操作来筛选出来四个值中最大的那个，然后再移动两个像素。跟这个类似的池化操作叫做最大化池化：\n",
    "\n",
    "<img src='./images/2018/10/9.8.png' style='float:center; width:350px;height:350px'/>\n",
    "\n",
    "我们可以用下面这一行代码来将卷积操作和池化层进行连接：\n",
    "\n",
    "```python\n",
    "pool_layer1 = tf.layers.max_pooling2d(inputs=conv_layer1,pool_size=[2,2],strides=2)\n",
    "```\n",
    "\n",
    "这个池化层会以下面这种格式来接受卷积操作的结果：\n",
    "\n",
    "```python\n",
    "[batch_size ,image_width,image_height,channels]\n",
    "```\n",
    "\n",
    "例如说，在我们的数字识别任务中，池化层的输入将会是下面这种格式：\n",
    "\n",
    "```python\n",
    "[batch_size,28,28,20]\n",
    "```\n",
    "\n",
    "池化层输出的结果将会有下面这种结构：\n",
    "\n",
    "```python\n",
    "[batch_size,14,14,20]\n",
    "```\n",
    "\n",
    "在这个例子中，卷积操作输出结果的尺寸将被减少到原来的一半。这个步骤是非常重要的，因为它在减少模型复杂度的同时还保留了重要的信息，所以也避免了过度优化问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全连接的神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一系列的卷积和池化步骤之后，接下来的是一个完全连接的神经网络，我们从输入的图片中提取高标准的特征，然后将结果提供给完全连接的神经网络，然后在这个特征基础上做一些实际分类：\n",
    "\n",
    "<img src='./images/2018/10/9.9.png' style='float:center; width:500px;height:200px'/>\n",
    "\n",
    "例如，数字识别分类任务中，我们可以把完全连接的神经网络放在卷积、池化步骤之后，而完全连接的神经网络包含了1024个神经元以及ReLU激活函数来执行实际分类。这个神经网络接受的输入需要具有下面这种格式：\n",
    "\n",
    "```python\n",
    "[batch_size,features]\n",
    "```\n",
    "\n",
    "所以，我们需要重塑（展平）从池化层获取的特征图像来符合我们所需要的格式。我们可以使用下面的这行代码来重新修改池化层的结果：\n",
    "\n",
    "```python\n",
    "pool1_flat = tf.reshape(pool_layer1,[-1,14,14,20])\n",
    "```\n",
    "\n",
    "在这个重塑函数中，我们用-1来显示每一批次的样本数量将会动态决定，而且从池化层输出的每个样本都是14\\*14\\*20的尺寸。\n",
    "\n",
    "所以最后重塑之后的格式将会是下面这种\n",
    "\n",
    "```python\n",
    "[batch_size,3136]\n",
    "```\n",
    "\n",
    "最后，我们可以使用TensorFlow中的Dense函数定义我们的完全连接的神经网络，其中Dense的具有所需数量的神经元（单元）以及最后的激活函数：\n",
    "\n",
    "```python\n",
    "dense_layer = tf.layers.dense(inputs=pool1_flat,units=1024,activation = tf.nn.relu)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logits图层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后我们需要Logits层，在这一层我们将使用完全连接层输出的结果来产生一个原始预测值。例如，为了数字识别分类，这个输出将会是长度为10的一维张量，其中每个值代表一个从0-9类的数。所以，我们为这个数字识别分类任务定义Logits层，在这个层我们只需要10个结果，同时在Dense函数中使用TensorFlow默认的线性激活函数：\n",
    "\n",
    "```python\n",
    "logits_layer = tf.layers.dense(inputs = dense_layer,units=10)\n",
    "```\n",
    "\n",
    "<img src='./images/2018/10/9.10.png' style='float:center; width:600px;height:200px'/>\n",
    "\n",
    "Logits层最后输出的结构将会是一个具有下面结构的张量矩阵：\n",
    "\n",
    "```python\n",
    "[batch_size,10]\n",
    "```\n",
    "\n",
    "在之前提到的，模型中的Logits层将会返回一个原始的预测值。但是我们需要将这些值转换成可解释的格式：\n",
    "\n",
    "- 输入样本0-9的预测类\n",
    "- 每个可能类的分数或概率。例如，样本为0的概率是1，以此类推\n",
    "\n",
    "<img src='./images/2018/10/9.11.png' style='float:center; width:700px;height:350px'/>\n",
    "\n",
    "所以，我们预测的类将会是10个结果中具有最高概率值的那个类。我们可以使用argmax函数来得到这个具体的值：\n",
    "\n",
    "```python\n",
    "tf.argmax(input=logits_layer,axis=1)\n",
    "```\n",
    "\n",
    "logits_layer层具有下面这种结构：\n",
    "\n",
    "```python\n",
    "[batch_size,10]\n",
    "```\n",
    "\n",
    "所以，我们需要在预测的结果中找到最大值，而这是索引为1的维度。\n",
    "\n",
    "最后我们可以得到下一个值，它代表着目标类的最大概率，通过将sotfmax激活函数应用到logits_layer层得到的结果，这将把每一个值压缩在0或者1：\n",
    "\n",
    "```python\n",
    "tf.nn.softmax(logits_layer,name=\"softmax_tensor\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络的基本例子--MNIST数字识别分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一节，我们借助MNIST数据集并使用卷积神经网络来做一个完整的数字分类识别。我们将会创建一个具有两层卷积层和完全连接的神经网络层的模型。\n",
    "\n",
    "我们先导入在这个实例中使用到的库：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将会使用TensorFlow辅助函数来下载MNIST数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-105345faee70>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Program\\Anaconda\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Program\\Anaconda\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Program\\Anaconda\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Program\\Anaconda\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Program\\Anaconda\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/MNIST/',one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个数据集将会被分成三个互不相关的数据集：训练集，验证集，测试集。所以，我们打印下各个数据集中图片的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of images in the training set:\t\t55000\n",
      "- Number of images in the test set:\t\t10000\n",
      "- Number of images in the validation set:\t5000\n"
     ]
    }
   ],
   "source": [
    "print('- Number of images in the training set:\\t\\t{}'.format(len(mnist.train.labels)))\n",
    "print('- Number of images in the test set:\\t\\t{}'.format(len(mnist.test.labels)))\n",
    "print('- Number of images in the validation set:\\t{}'.format(len(mnist.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集中图片的真是标签都是被存储为one-hot格式的，所以我们有一个含有10个值的数组，而其中类的索引就是对应图片上的数字。为了之后的使用，我们需要将数据集中的类转换成整型数字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist.test.cls_integer = np.argmax(mnist.test.labels,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再定义一些等下在实例中使用的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST数据集中图片的默认尺寸\n",
    "image_size = 28\n",
    "\n",
    "# 每个图片都被存为跟这个尺寸一样的向量\n",
    "image_size_flat = image_size*image_size\n",
    "\n",
    "# 每个图片的形状\n",
    "image_shape = (image_size,image_size)\n",
    "\n",
    "# 在MNIST数据集中的所有图片的色度都是1，也就是只有黑白两种颜色\n",
    "num_channels = 1\n",
    "\n",
    "# 在MNIST数据集中的数据类是从0到9的10个数据类\n",
    "num_classes = 10\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的滤镜尺寸\n",
    "filter_size_1 = 5\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的滤镜数量\n",
    "filters_1 = 16\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的滤镜尺寸\n",
    "filter_size_2 = 5\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的滤镜数量\n",
    "filters_2 = 36\n",
    "\n",
    "# 进行卷积操作时，第一次卷积步骤时的输出神经元个数\n",
    "fc_num_neurons = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要定义一个辅助函数来显示MNIST数据集中的图片。这个辅助函数将会把图片绘画在有9个子图的网格中：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_imgs(imgs,cls_actual,cls_predicted = None):\n",
    "    assert len(imgs) == len(cls_actual) == 9\n",
    "    \n",
    "    # 创建有9个子图的图像来绘画图片\n",
    "    fig,axes = plt.subplots(3,3)\n",
    "    fig.subplots_adjust(hspace = 0.3,wspace = 0.3)\n",
    "\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        \n",
    "        # 在第i个位置绘画图片\n",
    "        ax.imshow(imgs[i].reshape(image_shape),cmap = 'binary')\n",
    "        \n",
    "        # 用图片的真实值和预测的类来对图片进行贴标签\n",
    "        if cls_predicted is None:\n",
    "            xlabel = 'True:{0}'.format(cls_actual[i])\n",
    "        else:\n",
    "            xlabel = 'True:{0},Pred:{1}'.format(cls_actual[i],cls_predicted[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        # 移除图像上的刻度\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        # 将类显示为x轴的标签\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们从测试集中取出图片来进行绘画，然后看一下它是什么样子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKn2wxAEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc8eeca4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 从测试集中取出9个图片进行可视化\n",
    "imgs = mnist.test.images[0:9]\n",
    "\n",
    "# 得到测试集中的9个图片所对应的真实类\n",
    "cls_actual = mnist.test.cls_integer[0:9]\n",
    "\n",
    "# 绘画\n",
    "plot_imgs(imgs = imgs,cls_actual = cls_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "结果正如上面所显示的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在是时候来建立模型的核心部分了，这个计算图包含了所有在这一章提到的层。我们将以定义函数为开始，而这些函数将会被用于定义特定形状的变量，并且会随机初始化它们：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev = 0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05,shape = [length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们将会定义一个函数，这个函数将会基于输入的层、图像通道、滤镜大小、滤镜的数量、是否使用池化参数等来创建卷积层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input是之前层的输出\n",
    "def conv_layer(inputs,input_channels,filter_size,filters,use_pooling=True):\n",
    "    # 在这里使用了2*2的最大池化\n",
    "\n",
    "    #准备输入张量能接受的结构\n",
    "    shape = [filter_size,filter_size,input_channels,filters]\n",
    "\n",
    "    # 创建权重，而这就意味着滤镜要具有给定的结构\n",
    "    filter_weights = new_weights(shape = shape)\n",
    "\n",
    "    # 为每一个滤镜都创建偏差值\n",
    "    filters_biases = new_biases(length = filters)\n",
    "\n",
    "    # 正如我们上面所解释的那牙膏，在这里我们调用conv2d函数\n",
    "    # 同时里面的步长（strides）参数中有四个值，\n",
    "    # 第一个是指图片的数量，最后一个是指的图像的通道数，中间两个代表着滤镜移动的像素数\n",
    "    conv_layer = tf.nn.conv2d(input = inputs,\n",
    "                              filter = filter_weights,\n",
    "                              strides = [1,1,1,1],\n",
    "                              padding = 'SAME')\n",
    "\n",
    "    # 对conv_layer的输出结果增加偏差\n",
    "    conv_layer += filters_biases\n",
    "\n",
    "    # 用池化操作来降低图片的分辨率\n",
    "    if use_pooling:\n",
    "        # 用最大池化层来减小特征地图的输出结果\n",
    "        pool_layer = tf.nn.max_pool(value = conv_layer,\n",
    "                                    ksize = [1,2,2,1],\n",
    "                                    strides = [1,2,2,1],\n",
    "                                    padding = 'SAME')\n",
    "\n",
    "    # 将输出的结果提供给ReLU激活函数\n",
    "    relu_layer = tf.nn.relu(pool_layer)\n",
    "\n",
    "    # 在应用过relu和滤镜权重后，返回最终结果\n",
    "    return relu_layer,filter_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如我们先前提到的，池化层会生成一个四维的张量。我们需要把这个四维张量压平层一个两维的，然后将结果提供给完全连接的神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layers(layer):\n",
    "    # 获取图层的形状\n",
    "    shape = layer.get_shape()\n",
    "\n",
    "    # 我们需要将具有跟[num_images,image_height,image_width,num_channels]\n",
    "    #具有相同形状的图层进行压平处理，然后我们就会有跟[batch_size,num_features]相同尺寸的数据，\n",
    "    # 而其中的num_features的尺寸是image_height*image_width*num_channels\n",
    "    num_features = shape[1:4].num_elements()\n",
    "\n",
    "    # 重塑图片，然后将其提供给完全连接的神经网络\n",
    "    flatten_layer = tf.reshape(layer,[-1,num_features])\n",
    "\n",
    "    # 将压平的图层和要素数量返回\n",
    "    return flatten_layer,num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来的函数创建了一个完全连接神经网络，同时也假设输入的数据是一个两维的张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input 压平之后的输出结果\n",
    "# num_inputs 来自上一层的输入数量\n",
    "# num_outputs 输出的数量\n",
    "# use_relu 在结果中使用ReLU激活函数来移除其中的负值\n",
    "def fc_layer(inputs,num_inputs,num_outputs,use_relu = True):\n",
    "    # 为这一层的神经元创建权重\n",
    "    fc_weights = new_weights(shape = [num_inputs,num_outputs])\n",
    "    fc_biases = new_biases(length = num_outputs)\n",
    "\n",
    "    # 通过对输入的值和权重进行矩阵相乘然后再加上偏差，来计算这一层的值\n",
    "    fc_layer = tf.matmul(inputs,fc_weights) + fc_biases\n",
    "\n",
    "    # 如果使用ReLU激活函数的话\n",
    "    if use_relu:\n",
    "        relu_layer = tf.nn.relu(fc_layer)\n",
    "        return relu_layer\n",
    "    return fc_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在建立模型前，先为输入的图像定义一个占位符，其中shape的第一个参数是None，也就意味着可能是任意数量的图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_values = tf.placeholder(tf.float32,shape = [None,image_size_flat],\n",
    "                              name='input_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如我们之前提到的，我们需要输入到卷积步骤中的图片是需要一个四维的张量，所以我们需要把输入的图片重塑为下列的结构：\n",
    "\n",
    "[num_images,image_height,image_width,num_channels]\n",
    "\n",
    "所以，我们把输入的值进行重塑以满足下面的格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = tf.reshape(input_values,[-1,image_size,image_size,num_channels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要另外再定义一个占位符来存储事实类，而这个类值是一个one-hot编码格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_actual = tf.placeholder(tf.float32,shape = [None,num_classes],name = 'y_actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时，我们也需要定义一个变量来存储真实类的真实值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_actual_cls_integer = tf.argmax(y_actual,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "那么，接下来就是开始建立第一个卷积层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer_1,conv1_weights = conv_layer(inputs = input_image,\n",
    "                            input_channels = num_channels,\n",
    "                            filter_size = filter_size_1,\n",
    "                            filters = filters_1,\n",
    "                            use_pooling = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来检查下第一个卷积层输出结果的具体形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将创建第二个卷积网络，然后将第一个结果提交给它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer_2,conv2_weights = conv_layer(inputs = conv_layer_1,\n",
    "                            input_channels = filters_1,\n",
    "                            filter_size = filter_size_2,\n",
    "                            filters = filters_2,\n",
    "                            use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们需要第二次检查第二个的卷积层的输出结果，而其输出加过应该是(?,7,7,36),问号所代表的可以是任何数量的图像。\n",
    "\n",
    "接下来，我们需要把卷积层结果的四维张量处理成二维的，以便将结果提供给完全连接的神经网络：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten_layer,number_features = flatten_layers(conv_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要再次检查一下平坦层输出结果的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将创建一个完全连接层，并且将平坦层的结果提供给它。同时，我们也将完全连接层的结果用ReLU激活函数来处理，然后再提交给随后的完全连接层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_layer_1 = fc_layer(inputs = flatten_layer,\n",
    "                      num_inputs = number_features,\n",
    "                      num_outputs = fc_num_neurons,\n",
    "                      use_relu = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还需要再次检查第一个完全连接层的输出结果的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(fc_layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要添加另一个完全连接层，这个完全连接层将会把第一个完全连接层的结果当作输入，而且为每个图像生成一个大小为10的数组，表示每个目标类的分数是正确的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_layer_2 = fc_layer(inputs = fc_layer_1,\n",
    "                      num_inputs = fc_num_neurons,\n",
    "                      num_outputs = num_classes,\n",
    "                      use_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_3:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(fc_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将从第二个完全连接的层中对这些分数进行归一化，并将其提供给softmax激活函数，该函数将校准值压缩到介于0和1之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = tf.nn.softmax(fc_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们需要用TensorFlow的argmax函数，来提取概率最大的那个目标类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_cls_integer = tf.argmax(y_predicted,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要定义绩效指标，也就是交叉熵。如果预测是正确的话，那么交叉熵的值则为0："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-95a4299d59ab>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = fc_layer_2,\n",
    "                                                        labels = y_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们需要平均从上一步得到的所有交叉熵值，以便能够在测试集上获得单一的性能指标："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们有了一个需要被优化（最小化）的损失函数，所以我们将会用AdamOptimizer函数，这个函数是跟梯度下降类似，但是更加先进："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_optimizer = tf.train.AdamOptimizer(learning_rate = 1e-4).minimize(model_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了展示输出的结果，我们会定义一个变量来检查预测的类和真实类是否相等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_correct_prediction = tf.equal(y_predicted_cls_integer,y_actual_cls_integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过转换布尔值来计算模型精度，然后对它们求平均值以对正确分类的值求和："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_accuracy = tf.reduce_mean(tf.cast(model_correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过创建session变量来开始训练过程，而这个变量也将负责执行我们之前定义的计算图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时，我们也需要初始化我们之前定义的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们会批次提供图片数量来避免内存溢出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们开始训练过程前，我们将会先定义一个辅助函数，通过迭代训练批来执行优化过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 迭代优化的次数\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    \n",
    "\t# 将迭代次数变量进行全局更新\n",
    "\tglobal total_iterations\n",
    "\tfor i in range(total_iterations,total_iterations + num_iterations):\n",
    "\t\t\n",
    "\t\t# 为训练过程随机生成批次\n",
    "\t\t# input_batch包含从训练集中获取的图片，而y_actual_batch是所对应的图片的事实标签\n",
    "\t\tinput_batch,y_actual_batch = mnist.train.next_batch(train_batch_size)\n",
    "        \n",
    "\t\t# 将先前的值放在TensorFlow的dict格式中\n",
    "        # 以自动将它们分配给我们在上面定义的输入占位符。\n",
    "\t\tfeed_dict = {input_values:input_batch,y_actual:y_actual_batch}\n",
    "        \n",
    "\t\t# 接下来，我们将会在这个批次的图片上进行模型优化：\n",
    "\t\tsession.run(model_optimizer,feed_dict = feed_dict)\n",
    "        \n",
    "\t\t# 每进行100次迭代之后，打印训练状态：\n",
    "\t\tif i%100 == 0:\n",
    "            \n",
    "\t\t\t# 测量训练集的准确度\n",
    "\t\t\tacc_training_set = session.run(model_accuracy,feed_dict = feed_dict)\n",
    "\t\t\t# 打印训练集的准确度\n",
    "\t\t\tprint('Iteration:',\\\n",
    "                  '{0:> 6},Accuracy Over the training set:{1:>6.1%}'.format(i + 1,\\\n",
    "                                                                    acc_training_set))\n",
    "\t\t# 更新到目前执行迭代的次数\n",
    "\t\ttotal_iterations += num_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们将定义一些辅助函数来帮助我们进行模型结果的可视化，然后来看下哪些图片被模型错误的分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_errors(cls_predicted, correct):\n",
    "\t# cls_predicted是测试集中每个图像的预测类号的数组。\n",
    "    \n",
    "\t# 提取错误的图片\n",
    "\tincorrect = (correct == False)\n",
    "    \n",
    "\t# 从测试集中得到被模型错误分类的图片\n",
    "\timages = mnist.test.images[incorrect]\n",
    "    \n",
    "\t# 获取那些不正确图像的预测类\n",
    "\tcls_pred = cls_predicted[incorrect]\n",
    "    \n",
    "\t# 获取那些不正确图像的真实类\n",
    "\tcls_true = mnist.test.cls_integer[incorrect]\n",
    "    \n",
    "\t# 绘画9个图片\n",
    "\tplot_imgs(imgs = images[0:9],cls_actual = cls_true[0:9],\n",
    "              cls_predicted = cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以绘制预测结果与实际真实类别的混淆矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusionMatrix(cls_predicted):\n",
    "    \n",
    "\t# cls_predicted是测试集中每个图像的预测类号的数组。\n",
    "\t# 从测试集中获取真实类\n",
    "\tcls_actual = mnist.test.cls_integer\n",
    "    \n",
    "\t# 用sklearn来生成混淆矩阵\n",
    "\tconf_matrix = confusion_matrix(y_true = cls_actual,y_pred = cls_predicted)\n",
    "    \n",
    "\t# 打印矩阵\n",
    "\tprint(conf_matrix)\n",
    "    \n",
    "\t# 可视化混淆矩阵\n",
    "\tplt.matshow(conf_matrix)\n",
    "\tplt.colorbar()\n",
    "\ttick_marks = np.arange(num_classes)\n",
    "\tplt.xticks(tick_marks,range(num_classes))\n",
    "\tplt.yticks(tick_marks,range(num_classes))\n",
    "\tplt.xlabel('Predicted class')\n",
    "\tplt.ylabel('True class')\n",
    "    \n",
    "\t# 展示绘画\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们将会定义一个辅助函数来帮助我们测量训练模型在测试集上的准确性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "def test_accuracy(show_errors = False,show_confusionMatrix = False):\n",
    "    \n",
    "\t# 图片的数量\n",
    "\tnumber_test = len(mnist.test.images)\n",
    "    \n",
    "\t#为测试集的预测类定义一个零数组，将以小批量数据来测量并存储它\n",
    "\tcls_predicted = np.zeros(shape = number_test,dtype = np.int)\n",
    "    \n",
    "\t# 用测试集中的批次来测量预测类，以索引0的批次为开始\n",
    "\ti = 0\n",
    "\twhile i < number_test:\n",
    "        \n",
    "\t\t#要处理的下一批的结束索引是j\n",
    "\t\tj = min(i + test_batch_size,number_test)\n",
    "        \n",
    "\t\t#从开始和结束索引之间获取测试集中的所有图像\n",
    "\t\tinput_images = mnist.test.images[i:j,:]\n",
    "        \n",
    "\t\t# 得到这些图片的真实标签值\n",
    "\t\tactual_labels = mnist.test.labels[i:j,:]\n",
    "        \n",
    "\t\t#使用输入占位符值的相应值创建feed-dict\n",
    "\t\tfeed_dict = {input_values:input_images,y_actual:actual_labels}\n",
    "\t\tcls_predicted[i:j] = session.run(y_predicted_cls_integer,feed_dict = feed_dict)\n",
    "        \n",
    "\t\t# 将下一批的开始设置为我们刚刚处理的j的结束\n",
    "\t\ti = j\n",
    "        \n",
    "\t#获取测试图像的实际类号\n",
    "\tcls_actual = mnist.test.cls_integer\n",
    "    \n",
    "\t# 检查模型的预测是否正确\n",
    "\tcorrect = (cls_actual == cls_predicted)\n",
    "    \n",
    "\t# 对正确样例进行求和\n",
    "\tcorrect_number_images = correct.sum()\n",
    "    \n",
    "\t#通过将正确的分类与测试集中的图像总数相除来测量精度\n",
    "\ttestset_accuracy = float(correct_number_images)/number_test\n",
    "    \n",
    "\t# 展示准确性\n",
    "\tprint('Accuracy on Test-Set:{0:.1%} ({1}/{2})'.format(testset_accuracy,\n",
    "                                              correct_number_images,number_test))\n",
    "    \n",
    "\t# 显示一些不正确的例子\n",
    "\tif show_errors:\n",
    "\t\tprint('Example errors:')\n",
    "\t\tplot_errors(cls_predicted = cls_predicted,correct = correct)\n",
    "        \n",
    "\t#显示测试集预测的混淆矩阵\n",
    "\tif show_confusionMatrix:\n",
    "\t\tprint('Confusion Matrix:')\n",
    "\t\tplot_confusionMatrix(cls_predicted = cls_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在测试集上打印创建的模型的准确性，而不进行任何优化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set:9.2% (917/10000)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们通过运行一次迭代的优化过程，了解优化过程实际上增强了模型功能，以将图像分类到正确的类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,Accuracy Over the training set:  9.4%\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们迭代10000次的来进行优化过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    101,Accuracy Over the training set: 71.9%\n",
      "Iteration:    201,Accuracy Over the training set: 82.8%\n",
      "Iteration:    301,Accuracy Over the training set: 82.8%\n",
      "Iteration:    401,Accuracy Over the training set: 89.1%\n",
      "Iteration:    501,Accuracy Over the training set: 90.6%\n",
      "Iteration:    601,Accuracy Over the training set: 82.8%\n",
      "Iteration:    701,Accuracy Over the training set: 90.6%\n",
      "Iteration:    801,Accuracy Over the training set: 95.3%\n",
      "Iteration:    901,Accuracy Over the training set: 93.8%\n",
      "Iteration:   1001,Accuracy Over the training set: 95.3%\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations = 1001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们来检测模型将如何概括测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set:93.5% (9353/10000)\n",
      "Example errors:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XnclXP+x/HXR0mRlIrsd4owGEtDtqIfGktjmWw/+1gG\npWiYGD+yPIg0so01WbKUEWEGKSJEZGtDY2koWZphLIPI9/fHuT7nus59n3Mv3ec653T3fj4e9+O+\nzjnXub7f+/7e9/d8ru9qIQRERFZ0K5U7AyIilUCVoYgIqgxFRABVhiIigCpDERFAlaGICKDKUEQE\nUGUoIgKoMhQRAaB5Q07u0KFDqKqqSikrlWf+/PksXrzYyp2PUlIZN30q4/waVBlWVVUxY8aMZc/V\ncqZ79+7lzkLJqYybPpVxfrpNFhFBlaGICKDKUEQEUGUoIgKoMhQRAVQZiogAqgxFRIAGjjNMy5df\nfglAmzZtAFhpJdXRUthPP/2UPfbxcq+//nrO43feeQeAbt26ATBgwIDse7bddtuS5FOWL6p1RESo\nkMjwkEMOAWC11VYD4MQTTwRg//33TyW9zz77DIA111wTgObNK+LXIAX8+OOPALzyyisAjBgxIvva\nQw89VOt7X3jhBQBee+217HMeRYokKTIUEaFCIsPtttsOgOHDhwPQq1evVNO7+uqrgTjiuPLKK1NN\nT5aNt/sNGjQIgIkTJ9b5ng4dOgCw1VZb5Tx//fXXFzl3Usj48eMBmDdvXs7zkyZNyh5PmTIFgJ12\n2gmAvn375px73HHHZY/XWWedNLJZgyJDEREqJDLcYIMNSpKOfzJdddVVAPzwww+AIsNKkOwhPv/8\n8wH4y1/+AsDXX3+dc+4aa6yRPT711FMBOOKIIwBYa621AOjUqVN6mV2Bvf3220BuJPf555/nnPP9\n998D8Z1XPmaZFbWmT5+e8921bt06e3z66ac3Isf1p8hQRIQKiQxvuOGGkqTj7RQeEXpbpZTfueee\nmz1O9hYn9enTp8brW265ZboZkxwHH3wwAO+//36q6dx6663Z4379+gHptx0qMhQRQZWhiAhQ5tvk\n2bNnA/Dxxx+XJL3JkyfnPB46dGhJ0pWavMPkvPPOA/LfGq+88spAPJXu0ksvBaBVq1alyKLk8c03\n35QknTlz5mSPd955ZwBOOukkAI466igANtxww6KmqchQRIQyR4YvvvgiAP/5z39ynvdpecXiHSbe\n1e+RRc+ePYuajtSfR4Q+0D5po402AuLI/fjjjy9dxqRWXbp0AWDhwoU1XvPOrFGjRgHw1VdfAXDy\nyScD0LVr1+y5u+22GxB3ijkfpnPaaadln/vwww+BeMiVD8U7+uijG/Oj1KDIUESEMkSGyTaHP//5\nzzmvHXTQQUD8SVIsDz/8MABvvPFGzvXbtm1b1HSkMG8j9CE01dsIW7RokT0eO3YsAD169ChR7qS+\n7r33XiBux4M4cgshAHEE2K5dOwCefPJJII4q81m8eDEAf/rTnwD46KOPsq/5AOzdd98dgL322qtx\nP0QBigxFRChDZHjmmWdmj30ivkurd3f06NGpXFfq76677gIKD6hO9vQrIqxcPvA5+X88cuRIIO4B\n9jZeL+tkW2F1X3zxBQCHHnooAM8++2yNc7bYYgsgvsNLiyJDERFKGBk+8sgjAPz1r3+t8VpVVRUQ\nL9FeLN5L/emnnxb1ulJ/zz//PACDBw/Oed7HEN54440A7LrrrqXNmDTKwIEDs8c+rdUXaX700UcB\nePrppwG44447gHgqX5I/N3Xq1Jznk22S3o6YNkWGIiKUIDL0sUaXXHIJUHNMIcRLt7ds2bKoaX/w\nwQdA3IvsTjjhhKKmI7m8VxHiRVULjSX1MaD//e9/s6/5OFBtDLZ88Kje/898VIhvr3DkkUcC8QwS\niHuEX3rppZxr+R3DNddck32uVAuq6K9NRARVhiIiQAluk30nOt/PNsnD6er7VaStffv2JU1vRZO8\n5R03blzec3yv7P79++d8h3hlYx+gXao9MKRx1l57bQCmTZsGxAO0fdqcr1wOcfOJr3i9/fbbA3DO\nOecA5VlrVJGhiAgpRoa+k1n1bvFNNtkke+yfFM2aNQPihvdvv/224HW9gbX6/greIO+fNPl4JLrx\nxhvX/QPIMvMJ9cvquuuuA+KB2L5CuUcesnzYb7/9gDjKe/XVV7OvJTvZACZMmADAuuuuW6Lc1aTI\nUESEFCNDnzrz2muv5TzvQykgXqzTLV26FICbbrqp4HW33XZbIO62d/fccw+Qu2uXTxB3vjBDbdGj\nNF5yf1y3+uqrA3DbbbflfY8P0IW4/N966y0gnsp39tlnFzWfki7fxdD3Rq5eF0Bl/S8qMhQRIcXI\ncPz48Xmf9+V+ILd3qb58CTBf8rtNmzZAPLCze/fu2XOr7+fqe+xK6R133HFAPGWrumQ7bvU7Ax88\nL8uXRYsWAXDnnXfWee4VV1wB5A62LjVFhiIipBgZeo+ijxlzvqQ7xL2D1Zf57927NwC/+tWvalx3\nhx12AOKxbB06dADiid7eEwnx2MZtttkGgE033XRZfhQpgrq2cqjefizLv1mzZgHx3Vxyj2ufEnvf\nffcBMGbMGADOOOMMADp37lyyfDpFhiIiqDIUEQFSvE0+5ZRTANhxxx1znk9OrVpzzTUBWHXVVRt8\nfd9fwfkqGPlWw/Wufe/ql/LzQfNDhgwB4pWLkvxvxc+R5cP8+fOBeBqeT5Tw6ZUAhx9+OBCvTDRo\n0CAAlixZUqps1qDIUESEFCPD5s0zl87XCZKm5D4qvk+DJvqX1t577509nj17NhBP2vf1677//vuc\nx/kMGzYMyO10k8p3ww03APGOd94p4tFgUiXtT6TIUESEMuyOl7aOHTvmPZbSufzyy7PHzzzzDBBP\nxUoOuk/q1KlT9tgjwmOOOSalHEqa3n333ZzHPhUzOaDad8GbO3cuEO+JrIUaRETKrMlFhlJ+3nsI\n8aiCW265BYgHwvuyTv49ueyXT7WUpsH3P0ryJbx8oQZf4NmjyHJQZCgigiJDSZnviJbcGU3E+ciD\nSpiOqchQRARFhiJSZH369AFqzgbz5wF69uwJwODBgwFo0aJFiXJXmCJDERFUGYqIALpNFpEi+/3v\nf5/zfXmhyFBEBFWGIiKAKkMREQCs+s72tZ5s9jnwz/SyU3E2CiGsUKs9qIybPpVxfg2qDEVEmird\nJouIoMpQRASoozI0s/Zm9kb09YmZLUw8Lvr8GTNbw8wWmdnVBV6/28w+iNJ/1cx2zHdeA9JbYGZt\n8zxvZna5mc0zs7fMrH9j0qlkpSxjM6sys8lmNjf62iDPOaUq42Q6b5jZVo1Jp5KVuIyvMrM50f/N\nSPM1unLPKVUZT0v8nIvM7IHarlProOsQwr+AbaILXwh8E0IYUS1BI9P2+HNDf4g8LgOm1HHOmSGE\nCWa2L3AjsF21/DQPIfzUyHycCKwFdAshBDNbq5HXq1glLuMxwNAQwtNm1hpYWuC8UpRxNp0iXKei\nlaqMzawn0B3YikygNQ3YBXg+z+mpl3EIYefE9R4GHqzt/GW6TTazrtEn+z3AHGADM/sy8frhZjYq\nOl7bzB40sxlm9rKZ9ShwzR2AtsDT9czGVKBr9N7no0+hGcCAQmmaWUczmxR9ct0M1PjUipwKXByi\n3qUQwmf1zFOTUewyNrOtgaUhhKcBQgjfhBC+qyMbaZbxCi+F/+MAtARaAKuQCbbq+t9JvYyjqLEn\nUHMf4YTGtBluBowMIWwBLKzlvGuB4SGE7sChgP9ydzSzm6LjZsAI4OwGpN8XmJV43CyE0D2EcHWh\nNIGLgCkhhF8AjwHZDRfMbGIiAuwMHBUVwmNm1qUB+WpKilbGwKbAV2Y2wcxeN7MrzKyuv780yxhg\nuJnNNLMRxb5dXI4UrYxDCM+RiQY/AT4GHg0hzKsj/bTLGOBgYGII4dvaMtKYucnvhRBm1OO8PYFu\niaaDdmbWKoQwHZgePXc6MCGE8LHVbGKobmQU6n8GJFcMHVdXmmQ+HfYFCCE8bGZf+wkhhD6J97ck\ncyvR3cy8EPaox8/a1BSzjJsDuwHbkvmnewA4Grgzz/VKUcZ/BBaRiWJuA84i00yzoilaGZtZN6AL\nsB7QDJhsZhNDCNPyXK8UZeyOAK6v6wdsTGWYrGV/JjdUbZk4NmCHEMKSWq7VA9jZzAYCrYEWZvZt\nCOG8POcWaudJ5idvmvWoaN1CYHx0PB64ub5vbGKKWcYLgNdCCPMBzGwCmXaifJVh6mUcQvg4OvzB\nzO4ABtTrjU1PMcv4YGCaR2Bm9gSZ/+18lWEp/o8xs7XJfAA/Xte5RRlaEzW6fmFmm0S3PgclXp4M\nZHtjzWybPO8/PISwYQihCjgHGO0VoZkNN7O+DcxSoTSnAv8bPdcXKLT7zATiSHAP4O0Gpt/kNLaM\ngZeAjmbWPnrcG5gbnV/yMjazdaLvBhwAzG5g+k1OEcr4Q6CXmTU3s5WBXsBb0fnl+D8GOAR4uI5K\nHCjuOMMhwEQynwILEs/3B3aJ2mbmEoXE1dqTarM1mTaIhsibJjAU2NPMZgP7k2nXIMpPsq3hMuAI\nM5sFXAyc3MD0m6plLuOoZ/BsYEr0e10CjI7eX44yHmtmM8m0V7UBhjUw/aaqMf/HY4GPgJnAm8DL\nIQSPyMpRxgCHA/fVJ7GKno4XfWo/HkL4dbnzIulQGTd9y0sZV3RlKCJSKpqOJyKCKkMREUCVoYgI\noMpQRARo4KDrDh06hKqqqpSyUnnmz5/P4sWLV6i5rSrjpk9lnF+DKsOqqipmzKjPzJ2moXv37uXO\nQsmpjJs+lXF+uk0WEUGVoYgIoMpQRARQZSgiAjRuCS8RkRpmzcqs1dq7d28AFi9eDMArr7ySPacS\nO64UGYqIoMhQSuyMM84A4Jprril4zpAhQwA44IADANhpp53Sz5g02gknnADAmDFjAPjpp8x+Tptu\nuikAnTp1Kk/G6kmRoYgIFRIZfvxxZm3GG2+8EYB7770XgPfff7/GuccffzwQt0ccdthhAKy88sqp\n51Mab+edM7s3erQ3e3ZmgekHHoi3tL3iiisAGDlyJAAnnZRZ03PYsMz6q6uvXtvCxlIuEydOBGpG\nhE888QQA66+/fnkyVk+KDEVEKENk+PPP8R7VHgFeeumlALz9dt1bjdx+++053/29Tz31FADrrrtu\n/jdKRWjdujUQR4QXXHABAJdcckn2nEGDBgFw3XXXAXDDDTcAsPvuuwPQr1+/kuRV6ue0004D4NNP\nPwWgW7duADz+eGbF/+VlHrQiQxERyhAZjho1Knv8+9//Pue1Nm3aAHDMMccA0LVr1xrv/8c//gHA\nzTdndu/0aHLw4MEA3HPPPdlzmzVrVqxsSyP98MMPAJx3Xmb31zfffBOANdZYA8j9W3jkkUdy3rvK\nKqsA0KNHj9TzKQ3317/+FYClS5cCcP/99wPLT0ToFBmKiFDCyHDs2LFA3EOYVL2NoXPnznVer1ev\nXkDcvjRu3DgAhg8fnj1nww03bESOpZg8uttggw2AODL0nuEnn3wye+78+fOBeLPwffbZB6j83sgV\nyejRo7PHX375JRCP7Nh8883zvsdHjQA8/fTTOa/56JBytvkrMhQRQZWhiAhQwtvkqVOnArnDZ3x6\nzmOPPQbU7/bYHXLIIQBcdNFFACxatKgo+ZR0bbHFFgD87W9/A+KB9jNnziz4nj/+8Y/pZ0wa5Kuv\nvsoee8fJjjvuCEDz5plqxZu9fBB9chLFggULcq7nTSCrrbYaAB06dMi+NnDgQCBe3KEh9URDKDIU\nEaHM0/GOPvpoADbeeONyZkNKaPvtt895/MILLxQ816MF72CTyvGXv/ylxnPegeJRv9+9+bCq2lSP\nFN95553ssf+NVL+rKPbQHUWGIiKUOTIsxpI+Bx98MABz5swBYPz48dnXzjzzzEZfX4pru+22A6BF\nixYALFmypOC5zzzzDADt2rVLPV9SP3feeScQD39KGjFiBAAPPfQQEEeEu+66KwBnnXVW9tz11luv\n1nR8qBzE03bnzp0LxNM0//znPzc4/7VRZCgiQpkjQ59S51PploVP+Hf+6SGVqUuXLgDsu+++AEyY\nMKHGOb68lwbNVx5fjMF7kJOqT6hYe+21AbjjjjuAhvUNJNuW99tvPwD22GMPAK6//nognp7pbZON\npchQRIQyR4Y+PcfHIPbs2bPB15g3b15R8yTpevbZZ4G4RzCfVq1aAfF4NVm+rLXWWkA8Bbexo0U2\n2WQTII40PTp96aWXAEWGIiJFVbKP3t/97ndA3NME8MknnwAwYMCAnO/Vx5V98MEH2ePkEl0A//zn\nP3Me+zUh7qn0nkspPy//H3/8seA5Pol/xowZQGVuKyk1dezYEYBTTjkFiBdTaSxfvMEjTW87vO22\n24Di9SorMhQRQZWhiAhQwttkv9U5/fTTs8/5qsezZs0Caq58vSySDfP//ve/gcrfr3VF8MUXXwBw\nyy23APFahc7XOQT48MMPgXivEy/TLbfcMvV8yrKrfhtbbPlWvi8mRYYiIpRhaM0f/vCH7PE222wD\nxLufvfvuu0D8CfDyyy/XeP8OO+wAxHvpelR5/vnnp5RjKQaP7r7//vuc5/OtdO1Ldj366KNAPEB7\nypQpQDxwWyrLZpttlur1Fy9enOr1FRmKiFCGyND3woD4E9+/+7AYb+PzSDGpervBd999VzAtX0hW\nbYblV+hT3RdhSA6nuvXWWwHo06cPEO+Xcs011wBw7bXXppZPqTw+DOuyyy7Lef63v/1tUdNRZCgi\nQpmn41VXPYJrbO+RL9qw++67N+o6kp58y3P5dK79998fiCNDjxh9q4dC75f0+E6FQ4cOzT7nS3X5\nhIgTTjgBKF7Z+P+x78/s7czJ/odiUGQoIkIJI8PPPvsMiBd6BDjggAMA6N+/P1D8Zbx94VepXH37\n9i34mi/Y63zJJo8MpPS22morILe9zhdf9VEAo0aNAuLptT49rz4Lb/z0009Abn+BbyfgfPypbwNQ\nLIoMRURQZSgiApTwNrl9+/ZA3LgKcM455wDw9ddf5zwu9u2yLF98xeQnnngCgJVXXhmIm1O0zmH5\nJTsvfGql7z/ka4z6fsfTp08HcvdCrq53794A3H///UDu6lRed1x99dVAetP9FBmKiFDCyLBZs2YA\nnHjiidnnbr/9diDeC8VXQfbFHHwdswMPPLDgdV999dWcx5tvvnn2eNVVV21stiVlvl/usccem33u\nvvvuA+LG9JNPPhmIG86l/Lbddtvs8ZgxY4C4A2X48OFA/iivEB9Q75LD7C688EIg/jtIiyJDERHK\nMOja7/8hnpy/9957A/H0OW8b8rai1q1bF7yetze65E57bdq0KUKOpRh++ctfAnG7kU/P853TkkII\nAJxxxhlAbjuzVC4fduOR4rnnngvAsGHDgNojxPXXXx+Io7/k0J3k3V6aFBmKiFDm6Xi+L+6kSZMA\nuOCCC4A4WvAJ2r4waG184U+1K1Um7y30fa49AnjkkUeA3KmXN910EwC77LILkLu4hyw/fFC0R4r+\nvVIpMhQRoUIWavAl30ePHg3ES8PffffdQO7ueN4D7Xux+qfPxRdfDEDbtm1LkGNZVr4Iw4QJE8qc\nE5FcigxFRKiQyND5SHbvRT7++ONrnOMRoIhIMSkyFBFBlaGICKDKUEQEUGUoIgKoMhQRAVQZiogA\nYD4pvl4nm30O/DO97FScjUIIHcudiVJSGTd9KuP8GlQZiog0VbpNFhFBlaGICKDKUEQEqKMyNLP2\nZvZG9PWJmS1MPG5RzIyY2Qgzmx195V2U0MzuNrMPovRfNbMdG5nmAjOrscyNme1tZq9H6TxnZhs3\nJp1KVuIyvsrM5pjZW2Y20nwyeu45pSrjQWb2npmFfK83JSUu4yozm2xmc6OvDfKcU6oy7mJmL5vZ\nu2Z2r5mtXOuFQgj1+gIuBM7K87wBK9X3OgWufQDwBNAMaA28CrTOc97dwIHR8b7Aa3nOad6AdBcA\nbfM8/z6wSXQ8EBjVmJ9veflKuYx7AlPJfAA3B14Gdi1jGW8LbFTo9ab6lWYZR9d5DugdHbcGWpWx\njB8E+kXHo4CTarvOMt0mm1nXqNa/B5gDbGBmXyZeP9zMRkXHa5vZg2Y2I6qle+S55BbAsyGEpSGE\nb4DZwN51ZGMq0DVK4/ko0pgBDCiUppl1NLNJUXRyM5k/gHwC4BuorAF8XJ/fS1OSQhkHoCXQAliF\nTIX4WR3ZSK2MQwivhxBWpOElNRS7jM1sa2BpCOFpgBDCNyGE7+rIRiplbGbNyHwAPxQ9dSdQeJtN\nGtdmuBkwMoSwBbCwlvOuBYaHELoDh5KpoTGzHc3spuicN4F9zKyVmXUEegE1wutq+gKzEo+bhRC6\nhxCuLpQmcBEwJYTwC+AxYF1/s5lNNLO1oocnAE+a2QLgMGB4HXlpqopWxiGE54BpwCdkPlweDSHM\nqyP9NMtYMor5f7wp8JWZTbBMM9MVZlZXHZNWGXcEFocQlkYvLQDWqy0jjVnP8L0Qwox6nLcn0C3R\nPNTOzFqFEKYD0wFCCI+ZWXfgRTLRwovA0nwXA0aa2YXReSclnh9XV5pkPin2jdJ82MyyW+uFEPok\n3n8m0CeEMMPMzgVGAKfU42dtaopWxmbWDehC5g+yGTDZzCaGEKbluV4pylgyilbGZOqT3cg0QSwE\nHgCOJhOVVZdqGZtZJxqoMZXht4njn8kNVVsmjg3YIYSwpLaLhRAuBi4GMLP7gUJRw5khhHxrxifz\nkzdNq9leX4OZrQNslvgDGQesqGvUF7OMDwamhRC+BTCzJ4AeZKLF6lItY8lRzDJeQKb9bz6AmU0A\ntiN/ZZh2GX8OdDCzZlF0uD61R77FGVoTQvgZ+MLMNonC4oMSL08G+vsDM9um+vvNrLmZrRkdbwts\nDjwVPR5uZn0bmKVCaU4F/jd6ri+wep73/ovML9G3a9sLeKuB6Tc5jS1j4EOgV1TWK5NpCnkrOr/U\nZSx5FKGMXwI6mplvjt4bmBudX9IyjirA5xI/w7HAw7UlVsxxhkOAiWQ+6Rcknu8P7GJmM81sLlFI\nXK2tYRXg+ej1G4AjE/f6W5NpZ2qIvGkCQ4E9zWw2sD+JjhFva4g+hU4GJpjZm8Dh0c8mjSvjscBH\nwEwybcQvhxAej14raRlHx4OjNuFOgDfESyPKOITwE3A2MMXMZgFLgNHR+0texlFehpjZu2R6tu+o\nLbGKnptsmXj48RDCr8udF0mHyrjpW17KuKIrQxGRUtF0PBERVBmKiACqDEVEgAaOM+zQoUOoqqpK\nKSuVZ/78+SxevHiFGrimMm76VMb5NagyrKqqYsaM+gxWbxq6d+9e7iyUnMq46VMZ56fbZBERVBmK\niACqDEVEAFWGIiKAKkMREUCVoYgIoMpQRARo3OKuIjmWLMmswfnUU09ln7v33nsB+Ne//gXAxx9n\nVlvaaqutAOjcuTMAF198ccnyKQ33ww8/AHDllVcCcTkCfPjhhwD8/e9/r/f12rVrB8B5550HwBln\nnAFAs2bNGp/ZZaTIUESECosMPVqYPXs2AHvssQcATz/9dNnyJIXNnz8fgJEjRwIwZswYAL78MrvB\nmm/ZyFprZdbb/PrrzHYV//nPfwC45557gLjsAQ455JAUcy3LYsCAAQDcdtttBc/x5fh79uwJZGa6\nALz44osA/OMf/8ie638jZ599NgCPPfYYAHfddRcA661X695NqVBkKCJChUSG3l4wZ86cnOd32223\ncmRH6uCf8B4BLF2a2aHBo78ddtghe+5vf/tbAH7zm98A8P333+dcy9sMvU1KKsvpp58OxFH/mWee\nCcCBB8ZbEG+//fY572nRogUAzZtnqhdvS/7pp5+y53zxxRcAHHnkkQBMnToVgD333BOAJ598Mnvu\nBhvUtWtwcSgyFBGhzJHhoEGDALj++uuBuH1pr732AuCCCy4o+N5bb70VgD/84Q8Fz/G2p9raOaTh\nnn32WQAOOiiz8ZhHfb/+df23uHjmmWdyHjfkvVI63ra35pprAjBkSGZvNL8LqA+PFP07wKqrrgrE\nfwfbbbcdAG+88QYA++yzT/bciRMnAum3IyoyFBGhDJHhW2/FWxDffffdAPz8889A3PvkkUa+MUc3\n35zZ0XHgwIFA3B7hvAca4NBDDy1SriXpxBNPXOb3LlyY2cfbo0rXoUOHRuVJ0uG9vccddxwAbdu2\nTSUd703u1asXAHPnzs2+9rvf/Q6IxzF6W2SxKTIUEUGVoYgIUIbb5GSX/L///W8gHl7hYfDmm2+e\n856bbrope+xd+357fMsttwCw//77A7DGGmtkz/VGWik/b4g/7LDDAPjuu+8AuP/++8uWJ6nb1ltv\nXZJ0OnXqBMBFF10EwPHHH599bdKkSUA8/KZ3796p5EGRoYgIJYwM582bB8Bnn31W4zVvkK8eEbpk\n9OCDdr0h95e//CUA66yzTvEyK0XjEaF3eE2bNg2Abt26AdCvX7/yZEwq0uGHHw7E0zQhvmP0AdqL\nFi1KJW1FhiIilDAyvPrqq4HcSfwHHHAAAGeddVbe94waNQqAl156qcZrV111FZA79Usqw1dffZU9\n9rZcjwhXWWUVIB40L5JP8v/aI0NfBu65554Dij9dV5GhiAgliAzfe+89IB5gnbT66qsD8TSdKVOm\nAPDqq68CcOGFFwJxzyPA+uuvD8Auu+ySToZlmfmyXD5oHuCFF14A4uWdvLf/9ddfB+IJ+z7gHuCb\nb74B4jbktAb6Srp+/PFHIJ5mm48PoF5ppdy4zEcdAAwdOhSIF3rwpeMUGYqIpCD1yPDRRx8F4kU9\nk3xqlk/S93FEyUiwugULFgCw3377AfEYxP/5n/8pUo5lWX300UdA3KaTj48m8EU6XDJ68CiydevW\nAOy6665APNUyOXLAF+PwtkgpPb8jGDduHADTp08H4MEHH8x5PR//P/aFH/yxlznEdwbJ/oY0KDIU\nEaHMS3h5G+GyePfddwHo378/EC8Qe8oppzQ+Y7JMttxySwAmT56cfc43DvKeQF8C3tuJZ82aBeRG\nex4B+LkWNUGaAAAJC0lEQVSPP/54zveko48+GoDLLrsMgHPPPbcYP4rUwe/iAE466SQgd1n/+qq+\nidTtt98OxOOHk1q2bAnAvvvu2+B06kORoYgIqgxFRIAK2QPFV7n1hRXefPNNIO50Se6c5msc+oq4\n77zzDhDvu5tcJ2/ttddOM9tSQG0T6at3nPjeJ8kOEB9C4cNyHnjgAQBmzJgB5Dake/n78Iv27dsD\ncPLJJy/7DyAF+YB639sG4jL06XLVJ0LsvvvuQLxuKcTNIt7p4v/rl19+ORDXAUmrrbYaEJdxsSky\nFBGhBJGhR2o+gDbZuO47YXk3utf8v/rVr4A4Erjmmmuy7/EocsKECUC8pJdP3k5O8/q///u/Yv4o\nkoJ8Q2J8IK6veuzf3bfffps99kH4Pnxj2LBhgCLDtPj+yd4hBvHQON9BryF89z3nd4HJQdfVd1RM\niyJDERFKEBlutNFGOd/79OlT53tqa+vz6VzHHnssAH/729+AuF0puRCsIsOmye8gAJ566ikgvgPx\noTw+LGennXYqce6atrSWz3I++DrfPic+wD4tigxFRKiQ3uTqvF2i+oDMfHwxSI8Mk20ZTz75JAB7\n7713sbMoFcKn9/kWEq1atQKga9euZcuTNNx///tfAE477TQgXqwDoGPHjkDujnlpUGQoIkKFRobV\n1TZBe5tttgHiSf3JT5T3338/3YxJnXwxjvXWW69o1/z888+zx8k2YojHqXk0IenzpbqWLl0K5N/v\nvBD/395+++0B+OCDD4DcsYTeL7DFFls0PrO1UGQoIoIqQxERoEJvk331E28EP/XUU7OvzZ49G4Dz\nzz8fgC5dugDxfirJXbWkPJ544ons8c033wzAQw89tMzX8+l548ePB+IVaiBe9cYH72rVonQdddRR\nQO6alT686ZJLLgHiFepr4/sa+aroixcvznn90ksvzR77JIy0KTIUEaFCI0OfYuURYXKNuuuvvx6I\nVz326Xk+WVzKxxvDk4Nj1113XSAut/oMuvdhUh4t+NRLb1xPrortw7BGjBjRqLxL/fhkh+SeRh4Z\nejTnw50OPPBAAJYsWQLAww8/nH2Pl7FPo/TVzUePHg3Eiz6UkiJDEREqNDJ0gwcPBmDSpEnZ57w9\nynfG6tGjB5B/b2UpLY/YfKgFwLx58wAYOHBgvd4LcZRQXZs2bQA44ogjss+NHDkSyD99S9Jz5ZVX\nZo//9Kc/AfH/pg93qj7sqTZ33nknELdJloMiQxERKjwydKNGjcoeDx8+HIBrr70WUERYSdq1awfk\ntifNnDkTiJdjS/Y0JyV3Q+vcuXPOaz6d0tsbNaC6/HyyA8DYsWOBeMSAt/Em2wirO+ecc4B4Ou0v\nfvGLVPLZEIoMRURYTiLD5FSuIUOGAPES4t5L6ZLL/pdqfJLk6tevX95jaZq8Ldd7mv378kaRoYgI\ny0lkmOTj1q677rqc7yIijaHIUEQEVYYiIoAqQxERQJWhiAigylBEBFBlKCICgCUnyNd5stnnwD/T\ny07F2SiEsELN/VIZN30q4/waVBmKiDRVuk0WEUGVoYgIUEdlaGbtzeyN6OsTM1uYeNyimBkxs6vM\nbI6ZvWVmIy3PCp9mdreZfRCl/6qZ7djINBeYWdtaXr/BzApv2twElKqMzayzmb0WXXe2mZ1U4LyS\nlHG1dN4ws60ak04lK2EZb29mL0XlO9PM8q7SUcIyvtPM3jSzWWZ2v5mtVuuFQgj1+gIuBM7K87wB\nK9X3OgWu3ROYSqZybg68DOya57y7gQOj432B1/Kc07wB6S4A2hZ4bUdgDPBlY3625ekr5TJeBVgl\nOm4DfAisVa4yTqazIn2lXMbdgC7R8frAJ8DqZSzjNonja/P93MmvZbpNNrOuZjbXzO4B5gAbJCMo\nMzvczEZFx2ub2YNmNsPMXjazHnkuGYCWQAsy/zTNgc/qyMZUoGuUxvNRNDkDGFAoTTPraGaTogj0\nZjJ/APl+vubAFcA59f+tNC3FLuMQwg8hBN+1axUyv/v86/vHUitjSaWM3wkhvBcdLwD+BXSoIxup\nlXEI4avo/JXI1C+19hY3ps1wM2BkCGELYGEt510LDA8hdAcOBfyXu6OZ3RRl+jlgGplPko+BR0MI\n8+pIvy8wK/G4WQihewjh6kJpAhcBU0IIvwAeA9b1N5vZRDNbK3o4CBgPfFpHHpq6opVx9LjKzGaS\nGdZxaQihrt9vmmUMMDy6nRtRzNvF5UxRy9iZ2c7R4fw60k+1jM3sLjL1ysbADbVlpDFLeL0XQphR\nj/P2BLpZ3ATYzsxahRCmA9MBzKwb0AVYD2gGTDaziSGEaXmuN9LMLiQTOSbbncbVlSaZ2/F9AUII\nD5vZ135CCKFPlJf1gQOB3VFUUbQyBgghzAe2NrP1gIfM7IEQwuIaV0u5jCN/BBaRuRu5DTgLuIwV\nT1HLGCAq3zuAI0N0j5pHKcqYEMIxZtaMTEXYj0zTV16NqQy/TRz/TG7F0TJxbMAOIYQltVzrYGBa\nCOFbADN7AuhBJlqs7swQwoQ68pM3TSuw61o12wGbAO9Fj9uY2TshhG71eXMTU8wyzgohLDSzt4Fd\ngXxlmXYZE0L4ODr8wczuAAbU641NT1HL2MzWAP4ODAkhvFLLqamXsQshLDWzccBAaqkMizK0JoTw\nM/CFmW0S3Z8flHh5MtDfH5jZNtXfT6YxvZeZNTezlYFewFvR+cPNrG8Ds1QozanA/0bP9QVWz/Oz\nPBJC6BRCqCLTlvHVCloR5mhsGZvZ+mbWMjpuD+wMzIsel7SMo9fWib4bcAAwu4HpNzlFKONVgIeB\nUSGEh6q9VtIyNrOVzGzj6NiA3wBv15ZYMccZDgEmkonmFiSe7w/sErXNzCUKiau1NYwFPgJmAm8C\nL4cQHo9e25rMPX9D5E0TGArsaWazgf3JtE8S5ad6e5LU1Jgy3hJ4xczeBKYAw0IIc6PXylHGY6P2\ny1lkereHNTD9pqoxZXwEmQ+5E63mkKVSl3Ez4G4zm0WmXlkTuLS2xCp6Ol5Uoz8eQvh1ufMi6VAZ\nN33LSxlXdGUoIlIqmo4nIoIqQxERQJWhiAigylBEBFBlKCICqDIUEQFUGYqIAPD/Xp+lBQDCIyIA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc8e48a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 959    0    2    1    0    6    9    3    0    0]\n",
      " [   0 1119    2    3    0    2    4    0    5    0]\n",
      " [  12    3  925   22   18    3    9   20   18    2]\n",
      " [   1    2    7  947    0   26    0   14    6    7]\n",
      " [   0    2    3    0  929    0   12    3    2   31]\n",
      " [   5    1    2   16    6  845    8    2    5    2]\n",
      " [   9    5    2    0   12   17  911    1    1    0]\n",
      " [   0   10   17    6    4    1    0  966    0   24]\n",
      " [   7    5    5   24   15   36   14   20  829   19]\n",
      " [   7    6    3   12   29    9    0   19    1  923]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD3CAYAAAA+C7CYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc8e86e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_accuracy(show_errors = True,show_confusionMatrix = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有趣的是，在使用基本卷积网络时，我们实际上在测试中获得了近93％的准确率。这个实现和结果向您展示了一个简单的卷积网络可以做什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一章中，我们已经涵盖了TensorFlow中CNN直觉和技术细节。我们还看了一下如何在TensorFlow中实现CNN的基本架构。\n",
    "在下一章节，我们将会演示更高级的架构，可用于检测数据科学家广泛使用的图像数据集中的对象。我们还将看到CNN的美丽以及它们如果像人类那样在首次认识到物体的基本特征，然后在这之上构建更高级的语义特征来对它们进行分类。尽管，这些步骤在我们大脑中进行的很快，而这的确是我们在辨认物体时所发生的。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
