{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 建模、构建与训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此示例显示如何创建CNN以在CIFAR-10数据集中对图像进行分类。 我们将使用一个简单的卷积神经网络实现几个卷积和完全连接的层。\n",
    "即使网络架构非常简单，您也会看到它的执行情况。所以，让我们开始这个实现。\n",
    "\n",
    "我们导入此实现所需的所有包:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorFlow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline线导向魔法函数，绘制命令的输出将在前端显示，该命令激活为 IPython 提供支持的“内联（inline）后端”\n",
    "#IPython “内联后端” 也可以使用 IPython的 %config 命令进行微调。\n",
    "#对于 Mac OS X 用户 %config InlineBackend.figure_format='retina' 是另一个有用的选项，它能提升 Matplotlib 图形在 Retina 屏上的质量\n",
    "#urlretrieve()方法直接将远程数据下载到本地\n",
    "#os.path.isfile()函数判断某一路径是否为文件\n",
    "#os.path.isdir()函数判断某一路径是否为目录\n",
    "#Tqdm 是一个快速，可扩展的Python进度条，可以在 Python 长循环中添加一个进度提示信息\n",
    "#tarfile解压缩一个tar包\n",
    "#Numpy支持大量的维度数组和矩阵运算，对数组运算提供了大量的数学函数库\n",
    "#random() 方法返回随机生成的一个实数，它在[0,1)范围内\n",
    "#matplotlib.pyplot绘图库\n",
    "#LabelBinarizer标签二值化\n",
    "#OneHotEncoder one-hot编码可以使分类更加准确\n",
    "#pickle用于python特有的类型和python的数据类型间进行转换\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载CIFAR-10数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此实施中，我们将使用CIFAR - 10，这是使用最广泛的数据集之一用于对象检测。因此，让我们首先定义一个辅助类来下载和提取 CIFAR - 10数据集(如果尚未下载) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_batches_dir_path = 'cifar-10-batches-py/'\n",
    "tar_gz_filename = './data/cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_filename):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Python Images Batches') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_filename,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_batches_dir_path):\n",
    "    with tarfile.open(tar_gz_filename) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载并提取CIFAR - 10数据集后，您会发现它已经存在分成五批。CIFAR - 10包含10个类别/类别的图像:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.airplane\n",
    "2.automobile\n",
    "3.bird\n",
    "4.cat\n",
    "5.deer\n",
    "6.dog\n",
    "7.frog\n",
    "8.horse\n",
    "9.ship\n",
    "10.truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们深入研究构建网络核心之前，让我们做一些数据分析预处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分析和预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要分析数据集并做一些基本的预处理。那么，让我们从定义一些辅助函数，使我们能够从这五个批次中加载特定的批次进行处理，并打印关于该批次及其样本的一些分析:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a helper function for loading a batch of images\n",
    "#定义用于加载一批图像的辅助函数\n",
    "def load_batch(cifar10_dataset_dir_path, batch_num):\n",
    "    with open(cifar10_dataset_dir_path + 'data_batch_' + str(batch_num), mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    input_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    target_labels = batch['labels']\n",
    "\n",
    "    return input_features, target_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们定义了一个函数，它可以帮助我们显示来自特定批次:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to show the stats for batch ans specific sample\n",
    "#定义一个函数来显示批次和特定样本的统计数据\n",
    "def batch_image_stats(cifar10_dataset_dir_path, batch_num, sample_num):\n",
    "    batch_nums = list(range(1, 6))\n",
    "\n",
    "    # checking if the batch_num is a valid batch number\n",
    "    #检查batch_num是否是有效的批号\n",
    "    if batch_num not in batch_nums:\n",
    "        print('Batch Num is out of Range. You can choose from these Batch nums: {}'.format(batch_nums))\n",
    "        return None\n",
    "\n",
    "    input_features, target_labels = load_batch(cifar10_dataset_dir_path, batch_num)\n",
    "\n",
    "    # checking if the sample_num is a valid sample number\n",
    "    #检查sample_num是否是有效的样本号\n",
    "    if not (0 <= sample_num < len(input_features)):\n",
    "        print('{} samples in batch {}.  {} is not a valid sample number.'.format(len(input_features), batch_num,\n",
    "                                                                                 sample_num))\n",
    "        return None\n",
    "\n",
    "    print('\\nStatistics of batch number {}:'.format(batch_num))\n",
    "    print('Number of samples in this batch: {}'.format(len(input_features)))\n",
    "    print('Per class counts of each Label: {}'.format(dict(zip(*np.unique(target_labels, return_counts=True)))))\n",
    "\n",
    "    image = input_features[sample_num]\n",
    "    label = target_labels[sample_num]\n",
    "    cifar10_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    print('\\nSample Image Number {}:'.format(sample_num))\n",
    "    print('Sample image - Minimum pixel value: {} Maximum pixel value: {}'.format(image.min(), image.max()))\n",
    "    print('Samplei mage - Shape: {}'.format(image.shape))\n",
    "    print('Sample Label - Label Id: {} Name: {}'.format(label, cifar10_class_names[label]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们可以使用这个函数来处理我们的数据集并可视化特定的图像:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of batch number 3:\n",
      "Number of samples in this batch: 10000\n",
      "Per class counts of each Label: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "\n",
      "Sample Image Number 6:\n",
      "Sample image - Minimum pixel value: 30 Maximum pixel value: 242\n",
      "Samplei mage - Shape: (32, 32, 3)\n",
      "Sample Label - Label Id: 8 Name: ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore a specific batch and sample from the dataset\n",
    "#从数据集中探索特定批次和样本\n",
    "batch_num = 3\n",
    "sample_num = 6\n",
    "batch_image_stats(cifar10_batches_dir_path, batch_num, sample_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在继续将数据集输入模型之前，我们需要将其标准化为0到1的范围。\n",
    "批量标准化优化了网络训练。 它已被证明有几个好处："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更快的训练：由于在网络的前向传递期间的额外计算以及在网络的向后传播过程中训练的额外超参数，每个训练步骤将更慢。 但是，它应该更快地收敛，因此整体训练应该更快。\n",
    "\n",
    "更高的学习率：梯度下降算法通常需要较小的学习率才能使网络收敛到损失函数的最小值。 随着神经网络越来越深，它们的梯度值在反向传播过程中变得越来越小，因此它们通常需要更多的迭代。 使用批量标准化的想法允许我们使用更高的学习率，这进一步提高了网络训练的速度。\n",
    "\n",
    "容易初始化权重：权重初始化可能很困难，如果我们使用深度神经网络则会更加困难。 批量标准化似乎让我们在选择初始起始重量时要小心谨慎。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，让我们继续定义一个函数，该函数将负责规范输入图像，使这些图像的所有像素值介于0和1之间:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize CIFAR-10 images to be in the range of [0,1]\n",
    "#将CIFAR-10图像标准化为[0,1]范围\n",
    "def normalize_images(images):\n",
    "    # initial zero ndarray\n",
    "    normalized_images = np.zeros_like(images.astype(float))\n",
    "\n",
    "    # The first images index is number of images where the other indices indicates\n",
    "    #第一图像索引是其他索引指示的图像的数量\n",
    "    # hieight, width and depth of the image\n",
    "    #图像的高度，宽度和深度\n",
    "    num_images = images.shape[0]\n",
    "\n",
    "    # Computing the minimum and maximum value of the input image to do the normalization based on them\n",
    "    #计算输入图像的最小值和最大值，以便根据它们进行标准化\n",
    "    maximum_value, minimum_value = images.max(), images.min()\n",
    "\n",
    "    # Normalize all the pixel values of the images to be from 0 to 1\n",
    "    #将图像的所有像素值标准化为0到1\n",
    "    for img in range(num_images):\n",
    "        normalized_images[img, ...] = (images[img, ...] - float(minimum_value)) / float(maximum_value - minimum_value)\n",
    "\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要实现另一个辅助函数来对输入图像的标签进行编码。在这个函数中，我们将使用sklearn的one-hot编码，其中每个图像标签都由一个0向量表示，除了这个向量表示的图像的类索引之外。\n",
    "输出向量的大小将取决于我们在数据集中拥有的类的数量，在CIFAR-10数据中是10个类:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the input images. Each image will be represented by a vector of zeros except for the class index of the image\n",
    "#编码输入图像。 除了图像的类索引之外，每个图像将由零向量表示\n",
    "# that this vector represents. The length of this vector depends on number of classes that we have\n",
    "#这个向量代表。这个向量的长度取决于我们拥有的类的数量\n",
    "# the dataset which is 10 in CIFAR-10\n",
    "#CIFAR-10中的数据集为10\n",
    "\n",
    "def one_hot_encode(images):\n",
    "    num_classes = 10\n",
    "\n",
    "    # use sklearn helper function of OneHotEncoder() to do that\n",
    "    #使用OneHotEncoder（）的sklearn辅助函数来做到这一点\n",
    "    encoder = OneHotEncoder(num_classes)\n",
    "\n",
    "    # resize the input images to be 2D\n",
    "    #将输入图像的大小调整为2D\n",
    "    input_images_resized_to_2d = np.array(images).reshape(-1, 1)\n",
    "    one_hot_encoded_targets = encoder.fit_transform(input_images_resized_to_2d)\n",
    "\n",
    "    return one_hot_encoded_targets.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，是时候调用前面的辅助函数来进行预处理和持久化数据集，以便我们以后可以使用它了:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_persist_data(cifar10_batches_dir_path, normalize_images, one_hot_encode):\n",
    "    num_batches = 5\n",
    "    valid_input_features = []\n",
    "    valid_target_labels = []\n",
    "\n",
    "    for batch_ind in range(1, num_batches + 1):\n",
    "        # Loading batch\n",
    "        #加载批次\n",
    "        input_features, target_labels = load_batch(cifar10_batches_dir_path, batch_ind)\n",
    "        num_validation_images = int(len(input_features) * 0.1)\n",
    "\n",
    "        # Preprocess the current batch and perisist it for future use\n",
    "        #预处理当前批次并对其进行保存以备将来使用\n",
    "        input_features = normalize_images(input_features[:-num_validation_images])\n",
    "        target_labels = one_hot_encode(target_labels[:-num_validation_images])\n",
    "\n",
    "        # Persisting the preprocessed batch\n",
    "        #保留预处理的批处理\n",
    "        pickle.dump((input_features, target_labels), open('./preprocess/preprocess_train_batch_' + str(batch_ind) + '.p', 'wb'))\n",
    "\n",
    "        # Define a subset of the training images to be used for validating our model\n",
    "        #定义用于验证模型的训练图像的子集\n",
    "        valid_input_features.extend(input_features[-num_validation_images:])\n",
    "        valid_target_labels.extend(target_labels[-num_validation_images:])\n",
    "\n",
    "    # Preprocessing and persisting the validationi subset\n",
    "    #预处理并持久化validationi子集\n",
    "    input_features = normalize_images(np.array(valid_input_features))\n",
    "    target_labels = one_hot_encode(np.array(valid_target_labels))\n",
    "\n",
    "    pickle.dump((input_features, target_labels), open('./preprocess/preprocess_valid.p', 'wb'))\n",
    "\n",
    "    # Now it's time to preporcess and persist the test batche\n",
    "    #现在是时候预处理并持久化测试批次了\n",
    "    with open(cifar10_batches_dir_path + '/test_batch', mode='rb') as file:\n",
    "        test_batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    test_input_features = test_batch['data'].reshape((len(test_batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_input_labels = test_batch['labels']\n",
    "\n",
    "    # Normalizing and encoding the test batch\n",
    "    #对测试批处理进行规范化和编码\n",
    "    input_features = normalize_images(np.array(test_input_features))\n",
    "    target_labels = one_hot_encode(np.array(test_input_labels))\n",
    "\n",
    "    pickle.dump((input_features, target_labels), open('./preprocess/preprocess_test.p', 'wb'))\n",
    "\n",
    "# Calling the helper function above to preprocess and persist the training, validation, and testing set\n",
    "#调用上面的辅助函数来预处理并持久化训练，验证和测试集\n",
    "preprocess_persist_data(cifar10_batches_dir_path, normalize_images, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将预处理后的数据保存到磁盘。\n",
    "我们还需要在训练过程的不同时期加载用于在其上运行训练模型的验证集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Preprocessed Validation data\n",
    "#加载预处理的验证数据\n",
    "valid_input_features, valid_input_labels = pickle.load(open('./preprocess/preprocess_valid.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在是时候构建我们的分类应用程序的核心，这是该CNN架构的计算图，但是为了最大化这种实现的好处，我们不会使用TensorFlow层API。 相反，我们将使用它的TensorFlow神经网络版本。\n",
    "\n",
    "因此，让我们首先定义模型输入占位符，它将输入图像，目标类和丢失层的保持概率参数（这有助于我们通过删除一些连接来降低架构的复杂性，从而减少机会的可能性过拟合）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model inputs\n",
    "#定义模型输入\n",
    "def images_input(img_shape):\n",
    "    return tf.placeholder(tf.float32, (None,) + img_shape, name=\"input_images\")\n",
    "\n",
    "\n",
    "def target_input(num_classes):\n",
    "    target_input = tf.placeholder(tf.int32, (None, num_classes), name=\"input_images_target\")\n",
    "    return target_input\n",
    "\n",
    "\n",
    "# define a function for the dropout layer keep probability\n",
    "#为dropout层定义一个保持概率的函数\n",
    "def keep_prob_input():\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要使用TensorFlow神经网络实现版本来构建具有最大池的卷积层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying a convolution operation to the input tensor followed by max pooling\n",
    "#将卷积运算应用于输入张量，然后进行最大池化\n",
    "def conv2d_layer(input_tensor, conv_layer_num_outputs, conv_kernel_size, conv_layer_strides, pool_kernel_size,\n",
    "                 pool_layer_strides):\n",
    "    input_depth = input_tensor.get_shape()[3].value\n",
    "    weight_shape = conv_kernel_size + (input_depth, conv_layer_num_outputs,)\n",
    "\n",
    "    # Defining layer weights and biases\n",
    "    #定义图层权重和偏差\n",
    "    weights = tf.Variable(tf.random_normal(weight_shape))\n",
    "    biases = tf.Variable(tf.random_normal((conv_layer_num_outputs,)))\n",
    "\n",
    "    # Considering the biase variable\n",
    "    #考虑偏差变量\n",
    "    conv_strides = (1,) + conv_layer_strides + (1,)\n",
    "\n",
    "    conv_layer = tf.nn.conv2d(input_tensor, weights, strides=conv_strides, padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, biases)\n",
    "\n",
    "    conv_kernel_size = (1,) + conv_kernel_size + (1,)\n",
    "\n",
    "    pool_strides = (1,) + pool_layer_strides + (1,)\n",
    "\n",
    "    pool_layer = tf.nn.max_pool(conv_layer, ksize=conv_kernel_size, strides=pool_strides, padding='SAME')\n",
    "\n",
    "    return pool_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如您在上一章中可能看到的，最大池操作的输出是一个4D张量，它与完全连接层所需的输入格式不兼容。因此，我们需要实现一个平化层，将最大池化层的输出从4D转换为2D张量:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the output of max pooling layer to be fing to the fully connected layer which only accepts the output\n",
    "# to be in 2D\n",
    "#将最大池层的输出展平为仅接受输出的完全连接层\n",
    "#在2D中\n",
    "def flatten_layer(input_tensor):\n",
    "\n",
    "    return tf.contrib.layers.flatten(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要定义一个辅助函数，使我们能够在我们的架构中添加一个完全连接的层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the fully connected layer that will use the flattened output of the stacked convolution layers\n",
    "#to do the actuall classification\n",
    "#定义将使用堆叠卷积层的展平输出的完全连接层。\n",
    "#进行实际分类\n",
    "def fully_connected_layer(input_tensor, num_outputs):\n",
    "    return tf.layers.dense(input_tensor, num_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，在使用这些辅助函数创建整个体系结构之前，我们需要创建另一个函数来获取完全连接层的输出，并生成与我们在数据集中具有的类数相对应的10个实值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the output function\n",
    "#定义输出函数\n",
    "def output_layer(input_tensor, num_outputs):\n",
    "    return  tf.layers.dense(input_tensor, num_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，让我们继续并定义将所有这些碎片组合在一起并创建具有三个卷积层的CNN的功能。 其中每一个都遵循最大池操作。 我们还将有两个完全连接的层，其中每个层后面都有一个压差层，以降低模型复杂性并防止过度拟合。 最后，我们将使输出层生成10个实值向量，其中每个值表示每个类的得分是正确的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_convolution_net(image_data, keep_prob):\n",
    "    # Applying 3 convolution layers followed by max pooling layers\n",
    "    #应用3个卷积层，然后应用最大池化层\n",
    "    conv_layer_1 = conv2d_layer(image_data, 32, (3, 3), (1, 1), (3, 3), (3, 3))\n",
    "    conv_layer_2 = conv2d_layer(conv_layer_1, 64, (3, 3), (1, 1), (3, 3), (3, 3))\n",
    "    conv_layer_3 = conv2d_layer(conv_layer_2, 128, (3, 3), (1, 1), (3, 3), (3, 3))\n",
    "\n",
    "    # Flatten the output from 4D to 2D to be fed to the fully connected layer\n",
    "    #将输出从4D展平为2D以馈送到完全连接的层\n",
    "    flatten_output = flatten_layer(conv_layer_3)\n",
    "\n",
    "    # Applying 2 fully connected layers with drop out\n",
    "    #应用2个完全连接的层并退出\n",
    "    fully_connected_layer_1 = fully_connected_layer(flatten_output, 64)\n",
    "    fully_connected_layer_1 = tf.nn.dropout(fully_connected_layer_1, keep_prob)\n",
    "    fully_connected_layer_2 = fully_connected_layer(fully_connected_layer_1, 32)\n",
    "    fully_connected_layer_2 = tf.nn.dropout(fully_connected_layer_2, keep_prob)\n",
    "\n",
    "    # Applying the output layer while the output size will be the number of categories that we have\n",
    "    # in CIFAR-10 dataset\n",
    "    #应用输出层，而输出大小将是我们拥有的类别数。 在CIFAR-10数据集中\n",
    "    output_logits = output_layer(fully_connected_layer_2, 10)\n",
    "\n",
    "    # returning output\n",
    "    #返回输出\n",
    "    return output_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们调用前面的辅助函数来构建网络并定义其丢失和优化标准："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-690534c94a53>:23: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the helper function above to build the network\n",
    "#使用上面的辅助函数来构建网络\n",
    "#First off, let's remove all the previous inputs, weights, biases form the previous runs\n",
    "#首先，让我们删除之前运行的所有先前的输入，权重和偏差\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Defining the input placeholders to the convolution neural network\n",
    "#将输入占位符定义到卷积神经网络\n",
    "input_images = images_input((32, 32, 3))\n",
    "input_images_target = target_input(10)\n",
    "keep_prob = keep_prob_input()\n",
    "\n",
    "# Building the models\n",
    "#建立模型\n",
    "logits_values = build_convolution_net(input_images, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "#名称logits Tensor，因此可以在训练后从磁盘加载\n",
    "logits_values = tf.identity(logits_values, name='logits')\n",
    "\n",
    "# defining the model loss\n",
    "#定义模型损失\n",
    "model_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_values, labels=input_images_target))\n",
    "\n",
    "# Defining the model optimizer\n",
    "#定义模型优化器\n",
    "model_optimizer = tf.train.AdamOptimizer().minimize(model_cost)\n",
    "\n",
    "# Calculating and averaging the model accuracy\n",
    "#计算和平均模型精度\n",
    "correct_prediction = tf.equal(tf.argmax(logits_values, 1), tf.argmax(input_images_target, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='model_accuracy')\n",
    "#tests.test_conv_net(build_convolution_net)这行代码书上有代码里面没有"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经建立了这个网络的计算架构，现在是时候开始培训过程并看到一些结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，让我们定义一个辅助函数，使我们能够启动训练过程。该函数将获取输入图像、目标类的one-hot编码，并保留概率值作为输入。然后，它将把这些值提供给计算图，并调用模型优化器:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a helper function for kicking off the training process\n",
    "#定义辅助函数以启动培训过程\n",
    "def train(session, model_optimizer, keep_probability, in_feature_batch, target_batch):\n",
    "\n",
    "    session.run(model_optimizer, feed_dict={input_images: in_feature_batch, input_images_target: target_batch, keep_prob: keep_probability})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要在训练过程的不同时间步骤中验证我们的模型，因此我们将定义一个辅助函数，该函数将在验证集上打印出模型的准确性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a helper funcitno for print information about the model accuracy and it's validation accuracy as well\n",
    "#定义辅助函数以获取有关模型精度的打印信息以及它的验证准确性\n",
    "def print_model_stats(session, input_feature_batch, target_label_batch, model_cost, model_accuracy):\n",
    "    validation_loss = session.run(model_cost,\n",
    "                                  feed_dict={input_images: input_feature_batch, input_images_target: target_label_batch,\n",
    "                                             keep_prob: 1.0})\n",
    "    validation_accuracy = session.run(model_accuracy, feed_dict={input_images: input_feature_batch,\n",
    "                                                                 input_images_target: target_label_batch,\n",
    "                                                                 keep_prob: 1.0})\n",
    "\n",
    "    print(\"Valid Loss: %f\" % (validation_loss))\n",
    "    print(\"Valid accuracy: %f\" % (validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还定义模型超参数，我们可以使用它来调整模型以获得更好的性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "#模型超参数\n",
    "# 原始数据num_epochs是100，batch_size是128\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们开始训练过程，但仅针对一批CIFAR-10数据集，并查看基于此批次的模型准确性。\n",
    "\n",
    "然而，在此之前，我们将定义一个辅助函数，它将加载批处理训练并将输入图像与目标类分开："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset features and labels to batches\n",
    "#将数据集特征和标签拆分为批次\n",
    "def batch_split_features_labels(input_features, target_labels, train_batch_size):\n",
    "    for start in range(0, len(input_features), train_batch_size):\n",
    "        end = min(start + train_batch_size, len(input_features))\n",
    "        yield input_features[start:end], target_labels[start:end]\n",
    "\n",
    "#Loading the persisted preprocessed training batches\n",
    "#加载持久的预处理培训批次\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    filename = './preprocess/preprocess_train_batch_' + str(batch_id) + '.p'\n",
    "    input_features, target_labels = pickle.load(open(filename, mode='rb'))\n",
    "    train_batch_size = batch_size\n",
    "\n",
    "    # Returning the training images in batches according to the batch size defined above\n",
    "    #根据上面定义的批量大小分批返回训练图像\n",
    "    return batch_split_features_labels(input_features, target_labels, train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们开始一批的训练过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on only a Single Batch from the CIFAR-10 Dataset...\n",
      "Epoch number  1, CIFAR-10 Batch Number 1:  Valid Loss: 293.963135\n",
      "Valid accuracy: 0.200000\n",
      "Epoch number  2, CIFAR-10 Batch Number 1:  Valid Loss: 153.959122\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number  3, CIFAR-10 Batch Number 1:  Valid Loss: 117.611549\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number  4, CIFAR-10 Batch Number 1:  Valid Loss: 96.232826\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number  5, CIFAR-10 Batch Number 1:  Valid Loss: 64.179176\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number  6, CIFAR-10 Batch Number 1:  Valid Loss: 47.152710\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number  7, CIFAR-10 Batch Number 1:  Valid Loss: 38.405567\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number  8, CIFAR-10 Batch Number 1:  Valid Loss: 31.021799\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number  9, CIFAR-10 Batch Number 1:  Valid Loss: 25.224461\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 10, CIFAR-10 Batch Number 1:  Valid Loss: 21.938726\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 11, CIFAR-10 Batch Number 1:  Valid Loss: 15.838600\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 12, CIFAR-10 Batch Number 1:  Valid Loss: 13.927182\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 13, CIFAR-10 Batch Number 1:  Valid Loss: 11.603777\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 14, CIFAR-10 Batch Number 1:  Valid Loss: 9.308886\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 15, CIFAR-10 Batch Number 1:  Valid Loss: 8.293280\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 16, CIFAR-10 Batch Number 1:  Valid Loss: 6.881075\n",
      "Valid accuracy: 0.350000\n",
      "Epoch number 17, CIFAR-10 Batch Number 1:  Valid Loss: 5.721671\n",
      "Valid accuracy: 0.275000\n",
      "Epoch number 18, CIFAR-10 Batch Number 1:  Valid Loss: 5.028631\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number 19, CIFAR-10 Batch Number 1:  Valid Loss: 4.308107\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 20, CIFAR-10 Batch Number 1:  Valid Loss: 3.735994\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 21, CIFAR-10 Batch Number 1:  Valid Loss: 3.189520\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 22, CIFAR-10 Batch Number 1:  Valid Loss: 2.745335\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number 23, CIFAR-10 Batch Number 1:  Valid Loss: 2.267317\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 24, CIFAR-10 Batch Number 1:  Valid Loss: 1.869930\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 25, CIFAR-10 Batch Number 1:  Valid Loss: 1.703285\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 26, CIFAR-10 Batch Number 1:  Valid Loss: 1.685980\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 27, CIFAR-10 Batch Number 1:  Valid Loss: 1.634872\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 28, CIFAR-10 Batch Number 1:  Valid Loss: 1.642162\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 29, CIFAR-10 Batch Number 1:  Valid Loss: 1.621118\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 30, CIFAR-10 Batch Number 1:  Valid Loss: 1.643961\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 31, CIFAR-10 Batch Number 1:  Valid Loss: 1.683671\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number 32, CIFAR-10 Batch Number 1:  Valid Loss: 1.590501\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number 33, CIFAR-10 Batch Number 1:  Valid Loss: 1.627982\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 34, CIFAR-10 Batch Number 1:  Valid Loss: 1.678017\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 35, CIFAR-10 Batch Number 1:  Valid Loss: 1.569320\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 36, CIFAR-10 Batch Number 1:  Valid Loss: 1.633281\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 37, CIFAR-10 Batch Number 1:  Valid Loss: 1.683215\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 38, CIFAR-10 Batch Number 1:  Valid Loss: 1.581867\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 39, CIFAR-10 Batch Number 1:  Valid Loss: 1.664400\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 40, CIFAR-10 Batch Number 1:  Valid Loss: 1.620128\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 41, CIFAR-10 Batch Number 1:  Valid Loss: 1.647842\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 42, CIFAR-10 Batch Number 1:  Valid Loss: 1.656982\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number 43, CIFAR-10 Batch Number 1:  Valid Loss: 1.624977\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number 44, CIFAR-10 Batch Number 1:  Valid Loss: 1.564966\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number 45, CIFAR-10 Batch Number 1:  Valid Loss: 1.579529\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 46, CIFAR-10 Batch Number 1:  Valid Loss: 1.572911\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 47, CIFAR-10 Batch Number 1:  Valid Loss: 1.564638\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 48, CIFAR-10 Batch Number 1:  Valid Loss: 1.610420\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 49, CIFAR-10 Batch Number 1:  Valid Loss: 1.659990\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 50, CIFAR-10 Batch Number 1:  Valid Loss: 1.566424\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 51, CIFAR-10 Batch Number 1:  Valid Loss: 1.691176\n",
      "Valid accuracy: 0.350000\n",
      "Epoch number 52, CIFAR-10 Batch Number 1:  Valid Loss: 1.664817\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 53, CIFAR-10 Batch Number 1:  Valid Loss: 1.603754\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 54, CIFAR-10 Batch Number 1:  Valid Loss: 1.588923\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 55, CIFAR-10 Batch Number 1:  Valid Loss: 1.516420\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 56, CIFAR-10 Batch Number 1:  Valid Loss: 1.541147\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 57, CIFAR-10 Batch Number 1:  Valid Loss: 1.509699\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 58, CIFAR-10 Batch Number 1:  Valid Loss: 1.476985\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 59, CIFAR-10 Batch Number 1:  Valid Loss: 1.533420\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 60, CIFAR-10 Batch Number 1:  Valid Loss: 1.511405\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 61, CIFAR-10 Batch Number 1:  Valid Loss: 1.574154\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 62, CIFAR-10 Batch Number 1:  Valid Loss: 1.501852\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 63, CIFAR-10 Batch Number 1:  Valid Loss: 1.476640\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 64, CIFAR-10 Batch Number 1:  Valid Loss: 1.502470\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number 65, CIFAR-10 Batch Number 1:  Valid Loss: 1.496759\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 66, CIFAR-10 Batch Number 1:  Valid Loss: 1.472177\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 67, CIFAR-10 Batch Number 1:  Valid Loss: 1.491909\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 68, CIFAR-10 Batch Number 1:  Valid Loss: 1.475400\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 69, CIFAR-10 Batch Number 1:  Valid Loss: 1.601580\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 70, CIFAR-10 Batch Number 1:  Valid Loss: 1.498318\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 71, CIFAR-10 Batch Number 1:  Valid Loss: 1.508536\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number 72, CIFAR-10 Batch Number 1:  Valid Loss: 1.533771\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 73, CIFAR-10 Batch Number 1:  Valid Loss: 1.429514\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 74, CIFAR-10 Batch Number 1:  Valid Loss: 1.438678\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 75, CIFAR-10 Batch Number 1:  Valid Loss: 1.459931\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 76, CIFAR-10 Batch Number 1:  Valid Loss: 1.407053\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 77, CIFAR-10 Batch Number 1:  Valid Loss: 1.469333\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 78, CIFAR-10 Batch Number 1:  Valid Loss: 1.402550\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number 79, CIFAR-10 Batch Number 1:  Valid Loss: 1.503048\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 80, CIFAR-10 Batch Number 1:  Valid Loss: 1.433402\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 81, CIFAR-10 Batch Number 1:  Valid Loss: 1.392699\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 82, CIFAR-10 Batch Number 1:  Valid Loss: 1.396071\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 83, CIFAR-10 Batch Number 1:  Valid Loss: 1.392434\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number 84, CIFAR-10 Batch Number 1:  Valid Loss: 1.436687\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 85, CIFAR-10 Batch Number 1:  Valid Loss: 1.442868\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 86, CIFAR-10 Batch Number 1:  Valid Loss: 1.362015\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 87, CIFAR-10 Batch Number 1:  Valid Loss: 1.357624\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 88, CIFAR-10 Batch Number 1:  Valid Loss: 1.313854\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number 89, CIFAR-10 Batch Number 1:  Valid Loss: 1.438564\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 90, CIFAR-10 Batch Number 1:  Valid Loss: 1.389294\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 91, CIFAR-10 Batch Number 1:  Valid Loss: 1.410175\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 92, CIFAR-10 Batch Number 1:  Valid Loss: 1.332405\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number 93, CIFAR-10 Batch Number 1:  Valid Loss: 1.307268\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 94, CIFAR-10 Batch Number 1:  Valid Loss: 1.356404\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 95, CIFAR-10 Batch Number 1:  Valid Loss: 1.326406\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 96, CIFAR-10 Batch Number 1:  Valid Loss: 1.358722\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number 97, CIFAR-10 Batch Number 1:  Valid Loss: 1.366259\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 98, CIFAR-10 Batch Number 1:  Valid Loss: 1.274579\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number 99, CIFAR-10 Batch Number 1:  Valid Loss: 1.327188\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 100, CIFAR-10 Batch Number 1:  Valid Loss: 1.234392\n",
      "Valid accuracy: 0.550000\n"
     ]
    }
   ],
   "source": [
    "print('Training on only a Single Batch from the CIFAR-10 Dataset...')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    # 初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    # 训练周期\n",
    "    for epoch in range(num_epochs):\n",
    "        batch_ind = 1\n",
    "\n",
    "        for batch_features, batch_labels in load_preprocess_training_batch(batch_ind, batch_size):\n",
    "            train(sess, model_optimizer, keep_probability, batch_features, batch_labels)\n",
    "\n",
    "        print('Epoch number {:>2}, CIFAR-10 Batch Number {}:  '.format(epoch + 1, batch_ind), end='')\n",
    "        print_model_stats(sess, batch_features, batch_labels, model_cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如您所见，仅在单个批次上进行培训时，验证准确性并不高。 让我们看看验证准确性如何仅根据模型的完整培训流程进行更改："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full training for the network...\n",
      "Epoch number 1, CIFAR-10 Batch Number 1:  Valid Loss: 409.357758\n",
      "Valid accuracy: 0.225000\n",
      "Epoch number 1, CIFAR-10 Batch Number 2:  Valid Loss: 271.498352\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number 1, CIFAR-10 Batch Number 3:  Valid Loss: 121.103394\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 1, CIFAR-10 Batch Number 4:  Valid Loss: 101.355110\n",
      "Valid accuracy: 0.350000\n",
      "Epoch number 1, CIFAR-10 Batch Number 5:  Valid Loss: 81.377403\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number 2, CIFAR-10 Batch Number 1:  Valid Loss: 81.818733\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number 2, CIFAR-10 Batch Number 2:  Valid Loss: 64.170433\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 2, CIFAR-10 Batch Number 3:  Valid Loss: 27.400745\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 2, CIFAR-10 Batch Number 4:  Valid Loss: 29.049261\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 2, CIFAR-10 Batch Number 5:  Valid Loss: 25.695215\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 3, CIFAR-10 Batch Number 1:  Valid Loss: 24.224697\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 3, CIFAR-10 Batch Number 2:  Valid Loss: 21.026337\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 3, CIFAR-10 Batch Number 3:  Valid Loss: 9.791779\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 3, CIFAR-10 Batch Number 4:  Valid Loss: 9.825465\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number 3, CIFAR-10 Batch Number 5:  Valid Loss: 8.286464\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 4, CIFAR-10 Batch Number 1:  Valid Loss: 8.211388\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 4, CIFAR-10 Batch Number 2:  Valid Loss: 7.452418\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number 4, CIFAR-10 Batch Number 3:  Valid Loss: 2.668766\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number 4, CIFAR-10 Batch Number 4:  Valid Loss: 2.848174\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 4, CIFAR-10 Batch Number 5:  Valid Loss: 2.109991\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 5, CIFAR-10 Batch Number 1:  Valid Loss: 2.351979\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number 5, CIFAR-10 Batch Number 2:  Valid Loss: 2.261059\n",
      "Valid accuracy: 0.275000\n",
      "Epoch number 5, CIFAR-10 Batch Number 3:  Valid Loss: 1.498792\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 5, CIFAR-10 Batch Number 4:  Valid Loss: 1.693558\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 5, CIFAR-10 Batch Number 5:  Valid Loss: 1.721384\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number 6, CIFAR-10 Batch Number 1:  Valid Loss: 1.753878\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number 6, CIFAR-10 Batch Number 2:  Valid Loss: 1.798246\n",
      "Valid accuracy: 0.350000\n",
      "Epoch number 6, CIFAR-10 Batch Number 3:  Valid Loss: 1.678262\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 6, CIFAR-10 Batch Number 4:  Valid Loss: 1.755621\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number 6, CIFAR-10 Batch Number 5:  Valid Loss: 1.717646\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number 7, CIFAR-10 Batch Number 1:  Valid Loss: 1.781550\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number 7, CIFAR-10 Batch Number 2:  Valid Loss: 1.809139\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number 7, CIFAR-10 Batch Number 3:  Valid Loss: 1.571715\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 7, CIFAR-10 Batch Number 4:  Valid Loss: 1.749777\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 7, CIFAR-10 Batch Number 5:  Valid Loss: 1.723316\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number 8, CIFAR-10 Batch Number 1:  Valid Loss: 1.697542\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 8, CIFAR-10 Batch Number 2:  Valid Loss: 1.736573\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 8, CIFAR-10 Batch Number 3:  Valid Loss: 1.573046\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number 8, CIFAR-10 Batch Number 4:  Valid Loss: 1.682797\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number 8, CIFAR-10 Batch Number 5:  Valid Loss: 1.721381\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 9, CIFAR-10 Batch Number 1:  Valid Loss: 1.739458\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number 9, CIFAR-10 Batch Number 2:  Valid Loss: 1.728277\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number 9, CIFAR-10 Batch Number 3:  Valid Loss: 1.544062\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number 9, CIFAR-10 Batch Number 4:  Valid Loss: 1.674332\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number 9, CIFAR-10 Batch Number 5:  Valid Loss: 1.743536\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number10, CIFAR-10 Batch Number 1:  Valid Loss: 1.732479\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number10, CIFAR-10 Batch Number 2:  Valid Loss: 1.801403\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number10, CIFAR-10 Batch Number 3:  Valid Loss: 1.498095\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number10, CIFAR-10 Batch Number 4:  Valid Loss: 1.690109\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number10, CIFAR-10 Batch Number 5:  Valid Loss: 1.686468\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number11, CIFAR-10 Batch Number 1:  Valid Loss: 1.720509\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number11, CIFAR-10 Batch Number 2:  Valid Loss: 1.728362\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number11, CIFAR-10 Batch Number 3:  Valid Loss: 1.467077\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number11, CIFAR-10 Batch Number 4:  Valid Loss: 1.623495\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number11, CIFAR-10 Batch Number 5:  Valid Loss: 1.723196\n",
      "Valid accuracy: 0.350000\n",
      "Epoch number12, CIFAR-10 Batch Number 1:  Valid Loss: 1.703071\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number12, CIFAR-10 Batch Number 2:  Valid Loss: 1.796813\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number12, CIFAR-10 Batch Number 3:  Valid Loss: 1.502796\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number12, CIFAR-10 Batch Number 4:  Valid Loss: 1.727509\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number12, CIFAR-10 Batch Number 5:  Valid Loss: 1.778687\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number13, CIFAR-10 Batch Number 1:  Valid Loss: 1.676800\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number13, CIFAR-10 Batch Number 2:  Valid Loss: 1.725782\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number13, CIFAR-10 Batch Number 3:  Valid Loss: 1.507322\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number13, CIFAR-10 Batch Number 4:  Valid Loss: 1.666105\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number13, CIFAR-10 Batch Number 5:  Valid Loss: 1.722360\n",
      "Valid accuracy: 0.325000\n",
      "Epoch number14, CIFAR-10 Batch Number 1:  Valid Loss: 1.704163\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number14, CIFAR-10 Batch Number 2:  Valid Loss: 1.780728\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number14, CIFAR-10 Batch Number 3:  Valid Loss: 1.404613\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number14, CIFAR-10 Batch Number 4:  Valid Loss: 1.543607\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number14, CIFAR-10 Batch Number 5:  Valid Loss: 1.706409\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number15, CIFAR-10 Batch Number 1:  Valid Loss: 1.744962\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number15, CIFAR-10 Batch Number 2:  Valid Loss: 1.787815\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number15, CIFAR-10 Batch Number 3:  Valid Loss: 1.437744\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number15, CIFAR-10 Batch Number 4:  Valid Loss: 1.659431\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number15, CIFAR-10 Batch Number 5:  Valid Loss: 1.673167\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number16, CIFAR-10 Batch Number 1:  Valid Loss: 1.726825\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number16, CIFAR-10 Batch Number 2:  Valid Loss: 1.747001\n",
      "Valid accuracy: 0.350000\n",
      "Epoch number16, CIFAR-10 Batch Number 3:  Valid Loss: 1.458149\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number16, CIFAR-10 Batch Number 4:  Valid Loss: 1.551127\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number16, CIFAR-10 Batch Number 5:  Valid Loss: 1.659631\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number17, CIFAR-10 Batch Number 1:  Valid Loss: 1.635448\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number17, CIFAR-10 Batch Number 2:  Valid Loss: 1.729602\n",
      "Valid accuracy: 0.300000\n",
      "Epoch number17, CIFAR-10 Batch Number 3:  Valid Loss: 1.470585\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number17, CIFAR-10 Batch Number 4:  Valid Loss: 1.526881\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number17, CIFAR-10 Batch Number 5:  Valid Loss: 1.641187\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number18, CIFAR-10 Batch Number 1:  Valid Loss: 1.701472\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number18, CIFAR-10 Batch Number 2:  Valid Loss: 1.756624\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number18, CIFAR-10 Batch Number 3:  Valid Loss: 1.439366\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number18, CIFAR-10 Batch Number 4:  Valid Loss: 1.551325\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number18, CIFAR-10 Batch Number 5:  Valid Loss: 1.598213\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number19, CIFAR-10 Batch Number 1:  Valid Loss: 1.575009\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number19, CIFAR-10 Batch Number 2:  Valid Loss: 1.673545\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number19, CIFAR-10 Batch Number 3:  Valid Loss: 1.360596\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number19, CIFAR-10 Batch Number 4:  Valid Loss: 1.525635\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number19, CIFAR-10 Batch Number 5:  Valid Loss: 1.648590\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number20, CIFAR-10 Batch Number 1:  Valid Loss: 1.662945\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number20, CIFAR-10 Batch Number 2:  Valid Loss: 1.615687\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number20, CIFAR-10 Batch Number 3:  Valid Loss: 1.345132\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number20, CIFAR-10 Batch Number 4:  Valid Loss: 1.548739\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number20, CIFAR-10 Batch Number 5:  Valid Loss: 1.570839\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number21, CIFAR-10 Batch Number 1:  Valid Loss: 1.643520\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number21, CIFAR-10 Batch Number 2:  Valid Loss: 1.589296\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number21, CIFAR-10 Batch Number 3:  Valid Loss: 1.250484\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number21, CIFAR-10 Batch Number 4:  Valid Loss: 1.477887\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number21, CIFAR-10 Batch Number 5:  Valid Loss: 1.570659\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number22, CIFAR-10 Batch Number 1:  Valid Loss: 1.592672\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number22, CIFAR-10 Batch Number 2:  Valid Loss: 1.695196\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number22, CIFAR-10 Batch Number 3:  Valid Loss: 1.289409\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number22, CIFAR-10 Batch Number 4:  Valid Loss: 1.420925\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number22, CIFAR-10 Batch Number 5:  Valid Loss: 1.583024\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number23, CIFAR-10 Batch Number 1:  Valid Loss: 1.528205\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number23, CIFAR-10 Batch Number 2:  Valid Loss: 1.629443\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number23, CIFAR-10 Batch Number 3:  Valid Loss: 1.303574\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number23, CIFAR-10 Batch Number 4:  Valid Loss: 1.378338\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number23, CIFAR-10 Batch Number 5:  Valid Loss: 1.549078\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number24, CIFAR-10 Batch Number 1:  Valid Loss: 1.499421\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number24, CIFAR-10 Batch Number 2:  Valid Loss: 1.570659\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number24, CIFAR-10 Batch Number 3:  Valid Loss: 1.250033\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number24, CIFAR-10 Batch Number 4:  Valid Loss: 1.516116\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number24, CIFAR-10 Batch Number 5:  Valid Loss: 1.497730\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number25, CIFAR-10 Batch Number 1:  Valid Loss: 1.493873\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number25, CIFAR-10 Batch Number 2:  Valid Loss: 1.587152\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number25, CIFAR-10 Batch Number 3:  Valid Loss: 1.238065\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number25, CIFAR-10 Batch Number 4:  Valid Loss: 1.444057\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number25, CIFAR-10 Batch Number 5:  Valid Loss: 1.486626\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number26, CIFAR-10 Batch Number 1:  Valid Loss: 1.456175\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number26, CIFAR-10 Batch Number 2:  Valid Loss: 1.550445\n",
      "Valid accuracy: 0.375000\n",
      "Epoch number26, CIFAR-10 Batch Number 3:  Valid Loss: 1.189675\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number26, CIFAR-10 Batch Number 4:  Valid Loss: 1.406832\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number26, CIFAR-10 Batch Number 5:  Valid Loss: 1.487066\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number27, CIFAR-10 Batch Number 1:  Valid Loss: 1.479992\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number27, CIFAR-10 Batch Number 2:  Valid Loss: 1.561991\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number27, CIFAR-10 Batch Number 3:  Valid Loss: 1.218859\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number27, CIFAR-10 Batch Number 4:  Valid Loss: 1.345825\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number27, CIFAR-10 Batch Number 5:  Valid Loss: 1.463443\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number28, CIFAR-10 Batch Number 1:  Valid Loss: 1.458813\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number28, CIFAR-10 Batch Number 2:  Valid Loss: 1.548436\n",
      "Valid accuracy: 0.400000\n",
      "Epoch number28, CIFAR-10 Batch Number 3:  Valid Loss: 1.114097\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number28, CIFAR-10 Batch Number 4:  Valid Loss: 1.325707\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number28, CIFAR-10 Batch Number 5:  Valid Loss: 1.438877\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number29, CIFAR-10 Batch Number 1:  Valid Loss: 1.416119\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number29, CIFAR-10 Batch Number 2:  Valid Loss: 1.512378\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number29, CIFAR-10 Batch Number 3:  Valid Loss: 1.088105\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number29, CIFAR-10 Batch Number 4:  Valid Loss: 1.327550\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number29, CIFAR-10 Batch Number 5:  Valid Loss: 1.422262\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number30, CIFAR-10 Batch Number 1:  Valid Loss: 1.370865\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number30, CIFAR-10 Batch Number 2:  Valid Loss: 1.438269\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number30, CIFAR-10 Batch Number 3:  Valid Loss: 1.125662\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number30, CIFAR-10 Batch Number 4:  Valid Loss: 1.286249\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number30, CIFAR-10 Batch Number 5:  Valid Loss: 1.346226\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number31, CIFAR-10 Batch Number 1:  Valid Loss: 1.316091\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number31, CIFAR-10 Batch Number 2:  Valid Loss: 1.467800\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number31, CIFAR-10 Batch Number 3:  Valid Loss: 1.081103\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number31, CIFAR-10 Batch Number 4:  Valid Loss: 1.210867\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number31, CIFAR-10 Batch Number 5:  Valid Loss: 1.316915\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number32, CIFAR-10 Batch Number 1:  Valid Loss: 1.283693\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number32, CIFAR-10 Batch Number 2:  Valid Loss: 1.348685\n",
      "Valid accuracy: 0.500000\n",
      "Epoch number32, CIFAR-10 Batch Number 3:  Valid Loss: 1.068520\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number32, CIFAR-10 Batch Number 4:  Valid Loss: 1.268858\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number32, CIFAR-10 Batch Number 5:  Valid Loss: 1.283997\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number33, CIFAR-10 Batch Number 1:  Valid Loss: 1.226452\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number33, CIFAR-10 Batch Number 2:  Valid Loss: 1.347492\n",
      "Valid accuracy: 0.425000\n",
      "Epoch number33, CIFAR-10 Batch Number 3:  Valid Loss: 1.040192\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number33, CIFAR-10 Batch Number 4:  Valid Loss: 1.242752\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number33, CIFAR-10 Batch Number 5:  Valid Loss: 1.251934\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number34, CIFAR-10 Batch Number 1:  Valid Loss: 1.221646\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number34, CIFAR-10 Batch Number 2:  Valid Loss: 1.374526\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number34, CIFAR-10 Batch Number 3:  Valid Loss: 1.041460\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number34, CIFAR-10 Batch Number 4:  Valid Loss: 1.215158\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number34, CIFAR-10 Batch Number 5:  Valid Loss: 1.242565\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number35, CIFAR-10 Batch Number 1:  Valid Loss: 1.168569\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number35, CIFAR-10 Batch Number 2:  Valid Loss: 1.313241\n",
      "Valid accuracy: 0.475000\n",
      "Epoch number35, CIFAR-10 Batch Number 3:  Valid Loss: 1.069963\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number35, CIFAR-10 Batch Number 4:  Valid Loss: 1.141080\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number35, CIFAR-10 Batch Number 5:  Valid Loss: 1.205782\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number36, CIFAR-10 Batch Number 1:  Valid Loss: 1.188742\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number36, CIFAR-10 Batch Number 2:  Valid Loss: 1.298874\n",
      "Valid accuracy: 0.450000\n",
      "Epoch number36, CIFAR-10 Batch Number 3:  Valid Loss: 0.966093\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number36, CIFAR-10 Batch Number 4:  Valid Loss: 1.153994\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number36, CIFAR-10 Batch Number 5:  Valid Loss: 1.197652\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number37, CIFAR-10 Batch Number 1:  Valid Loss: 1.126032\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number37, CIFAR-10 Batch Number 2:  Valid Loss: 1.290655\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number37, CIFAR-10 Batch Number 3:  Valid Loss: 0.985497\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number37, CIFAR-10 Batch Number 4:  Valid Loss: 1.138523\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number37, CIFAR-10 Batch Number 5:  Valid Loss: 1.184605\n",
      "Valid accuracy: 0.525000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number38, CIFAR-10 Batch Number 1:  Valid Loss: 1.086018\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number38, CIFAR-10 Batch Number 2:  Valid Loss: 1.248665\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number38, CIFAR-10 Batch Number 3:  Valid Loss: 0.979255\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number38, CIFAR-10 Batch Number 4:  Valid Loss: 1.051253\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number38, CIFAR-10 Batch Number 5:  Valid Loss: 1.163857\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number39, CIFAR-10 Batch Number 1:  Valid Loss: 1.111699\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number39, CIFAR-10 Batch Number 2:  Valid Loss: 1.211628\n",
      "Valid accuracy: 0.525000\n",
      "Epoch number39, CIFAR-10 Batch Number 3:  Valid Loss: 0.945881\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number39, CIFAR-10 Batch Number 4:  Valid Loss: 1.112708\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number39, CIFAR-10 Batch Number 5:  Valid Loss: 1.059367\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number40, CIFAR-10 Batch Number 1:  Valid Loss: 1.052228\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number40, CIFAR-10 Batch Number 2:  Valid Loss: 1.096763\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number40, CIFAR-10 Batch Number 3:  Valid Loss: 0.912301\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number40, CIFAR-10 Batch Number 4:  Valid Loss: 1.035464\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number40, CIFAR-10 Batch Number 5:  Valid Loss: 1.014528\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number41, CIFAR-10 Batch Number 1:  Valid Loss: 1.030164\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number41, CIFAR-10 Batch Number 2:  Valid Loss: 1.052020\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number41, CIFAR-10 Batch Number 3:  Valid Loss: 0.902056\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number41, CIFAR-10 Batch Number 4:  Valid Loss: 1.039864\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number41, CIFAR-10 Batch Number 5:  Valid Loss: 1.037368\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number42, CIFAR-10 Batch Number 1:  Valid Loss: 1.083448\n",
      "Valid accuracy: 0.600000\n",
      "Epoch number42, CIFAR-10 Batch Number 2:  Valid Loss: 1.092143\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number42, CIFAR-10 Batch Number 3:  Valid Loss: 0.839494\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number42, CIFAR-10 Batch Number 4:  Valid Loss: 1.078458\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number42, CIFAR-10 Batch Number 5:  Valid Loss: 0.993800\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number43, CIFAR-10 Batch Number 1:  Valid Loss: 0.983769\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number43, CIFAR-10 Batch Number 2:  Valid Loss: 1.009526\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number43, CIFAR-10 Batch Number 3:  Valid Loss: 0.802883\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number43, CIFAR-10 Batch Number 4:  Valid Loss: 0.984475\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number43, CIFAR-10 Batch Number 5:  Valid Loss: 0.956927\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number44, CIFAR-10 Batch Number 1:  Valid Loss: 0.958820\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number44, CIFAR-10 Batch Number 2:  Valid Loss: 0.973259\n",
      "Valid accuracy: 0.550000\n",
      "Epoch number44, CIFAR-10 Batch Number 3:  Valid Loss: 0.843996\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number44, CIFAR-10 Batch Number 4:  Valid Loss: 1.019488\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number44, CIFAR-10 Batch Number 5:  Valid Loss: 1.001382\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number45, CIFAR-10 Batch Number 1:  Valid Loss: 0.892534\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number45, CIFAR-10 Batch Number 2:  Valid Loss: 0.921239\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number45, CIFAR-10 Batch Number 3:  Valid Loss: 0.802450\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number45, CIFAR-10 Batch Number 4:  Valid Loss: 0.925227\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number45, CIFAR-10 Batch Number 5:  Valid Loss: 0.977740\n",
      "Valid accuracy: 0.575000\n",
      "Epoch number46, CIFAR-10 Batch Number 1:  Valid Loss: 0.868918\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number46, CIFAR-10 Batch Number 2:  Valid Loss: 0.888644\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number46, CIFAR-10 Batch Number 3:  Valid Loss: 0.775012\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number46, CIFAR-10 Batch Number 4:  Valid Loss: 0.899221\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number46, CIFAR-10 Batch Number 5:  Valid Loss: 0.943984\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number47, CIFAR-10 Batch Number 1:  Valid Loss: 0.828064\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number47, CIFAR-10 Batch Number 2:  Valid Loss: 0.827802\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number47, CIFAR-10 Batch Number 3:  Valid Loss: 0.688672\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number47, CIFAR-10 Batch Number 4:  Valid Loss: 0.928407\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number47, CIFAR-10 Batch Number 5:  Valid Loss: 0.840809\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number48, CIFAR-10 Batch Number 1:  Valid Loss: 0.869675\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number48, CIFAR-10 Batch Number 2:  Valid Loss: 0.805258\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number48, CIFAR-10 Batch Number 3:  Valid Loss: 0.649420\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number48, CIFAR-10 Batch Number 4:  Valid Loss: 0.908385\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number48, CIFAR-10 Batch Number 5:  Valid Loss: 0.872988\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number49, CIFAR-10 Batch Number 1:  Valid Loss: 0.740736\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number49, CIFAR-10 Batch Number 2:  Valid Loss: 0.760911\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number49, CIFAR-10 Batch Number 3:  Valid Loss: 0.660917\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number49, CIFAR-10 Batch Number 4:  Valid Loss: 0.892711\n",
      "Valid accuracy: 0.625000\n",
      "Epoch number49, CIFAR-10 Batch Number 5:  Valid Loss: 0.834105\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number50, CIFAR-10 Batch Number 1:  Valid Loss: 0.756759\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number50, CIFAR-10 Batch Number 2:  Valid Loss: 0.766090\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number50, CIFAR-10 Batch Number 3:  Valid Loss: 0.652967\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number50, CIFAR-10 Batch Number 4:  Valid Loss: 0.790441\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number50, CIFAR-10 Batch Number 5:  Valid Loss: 0.809868\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number51, CIFAR-10 Batch Number 1:  Valid Loss: 0.770577\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number51, CIFAR-10 Batch Number 2:  Valid Loss: 0.723057\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number51, CIFAR-10 Batch Number 3:  Valid Loss: 0.631530\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number51, CIFAR-10 Batch Number 4:  Valid Loss: 0.805793\n",
      "Valid accuracy: 0.650000\n",
      "Epoch number51, CIFAR-10 Batch Number 5:  Valid Loss: 0.770357\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number52, CIFAR-10 Batch Number 1:  Valid Loss: 0.739990\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number52, CIFAR-10 Batch Number 2:  Valid Loss: 0.753315\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number52, CIFAR-10 Batch Number 3:  Valid Loss: 0.607127\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number52, CIFAR-10 Batch Number 4:  Valid Loss: 0.817503\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number52, CIFAR-10 Batch Number 5:  Valid Loss: 0.844882\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number53, CIFAR-10 Batch Number 1:  Valid Loss: 0.716430\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number53, CIFAR-10 Batch Number 2:  Valid Loss: 0.688014\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number53, CIFAR-10 Batch Number 3:  Valid Loss: 0.580938\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number53, CIFAR-10 Batch Number 4:  Valid Loss: 0.821323\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number53, CIFAR-10 Batch Number 5:  Valid Loss: 0.761030\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number54, CIFAR-10 Batch Number 1:  Valid Loss: 0.658209\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number54, CIFAR-10 Batch Number 2:  Valid Loss: 0.719530\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number54, CIFAR-10 Batch Number 3:  Valid Loss: 0.629068\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number54, CIFAR-10 Batch Number 4:  Valid Loss: 0.716192\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number54, CIFAR-10 Batch Number 5:  Valid Loss: 0.759439\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number55, CIFAR-10 Batch Number 1:  Valid Loss: 0.684590\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number55, CIFAR-10 Batch Number 2:  Valid Loss: 0.695839\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number55, CIFAR-10 Batch Number 3:  Valid Loss: 0.583295\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number55, CIFAR-10 Batch Number 4:  Valid Loss: 0.693245\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number55, CIFAR-10 Batch Number 5:  Valid Loss: 0.711799\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number56, CIFAR-10 Batch Number 1:  Valid Loss: 0.613985\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number56, CIFAR-10 Batch Number 2:  Valid Loss: 0.686247\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number56, CIFAR-10 Batch Number 3:  Valid Loss: 0.584010\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number56, CIFAR-10 Batch Number 4:  Valid Loss: 0.702821\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number56, CIFAR-10 Batch Number 5:  Valid Loss: 0.653379\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number57, CIFAR-10 Batch Number 1:  Valid Loss: 0.630651\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number57, CIFAR-10 Batch Number 2:  Valid Loss: 0.611675\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number57, CIFAR-10 Batch Number 3:  Valid Loss: 0.563784\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number57, CIFAR-10 Batch Number 4:  Valid Loss: 0.718090\n",
      "Valid accuracy: 0.700000\n",
      "Epoch number57, CIFAR-10 Batch Number 5:  Valid Loss: 0.649557\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number58, CIFAR-10 Batch Number 1:  Valid Loss: 0.662435\n",
      "Valid accuracy: 0.725000\n",
      "Epoch number58, CIFAR-10 Batch Number 2:  Valid Loss: 0.582546\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number58, CIFAR-10 Batch Number 3:  Valid Loss: 0.543824\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number58, CIFAR-10 Batch Number 4:  Valid Loss: 0.649407\n",
      "Valid accuracy: 0.675000\n",
      "Epoch number58, CIFAR-10 Batch Number 5:  Valid Loss: 0.607154\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number59, CIFAR-10 Batch Number 1:  Valid Loss: 0.641378\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number59, CIFAR-10 Batch Number 2:  Valid Loss: 0.572776\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number59, CIFAR-10 Batch Number 3:  Valid Loss: 0.493343\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number59, CIFAR-10 Batch Number 4:  Valid Loss: 0.656615\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number59, CIFAR-10 Batch Number 5:  Valid Loss: 0.594571\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number60, CIFAR-10 Batch Number 1:  Valid Loss: 0.586156\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number60, CIFAR-10 Batch Number 2:  Valid Loss: 0.564351\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number60, CIFAR-10 Batch Number 3:  Valid Loss: 0.452745\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number60, CIFAR-10 Batch Number 4:  Valid Loss: 0.592224\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number60, CIFAR-10 Batch Number 5:  Valid Loss: 0.571778\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number61, CIFAR-10 Batch Number 1:  Valid Loss: 0.549919\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number61, CIFAR-10 Batch Number 2:  Valid Loss: 0.538840\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number61, CIFAR-10 Batch Number 3:  Valid Loss: 0.412032\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number61, CIFAR-10 Batch Number 4:  Valid Loss: 0.635142\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number61, CIFAR-10 Batch Number 5:  Valid Loss: 0.597037\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number62, CIFAR-10 Batch Number 1:  Valid Loss: 0.566868\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number62, CIFAR-10 Batch Number 2:  Valid Loss: 0.511894\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number62, CIFAR-10 Batch Number 3:  Valid Loss: 0.481811\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number62, CIFAR-10 Batch Number 4:  Valid Loss: 0.604325\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number62, CIFAR-10 Batch Number 5:  Valid Loss: 0.558071\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number63, CIFAR-10 Batch Number 1:  Valid Loss: 0.554166\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number63, CIFAR-10 Batch Number 2:  Valid Loss: 0.525268\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number63, CIFAR-10 Batch Number 3:  Valid Loss: 0.482739\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number63, CIFAR-10 Batch Number 4:  Valid Loss: 0.578764\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number63, CIFAR-10 Batch Number 5:  Valid Loss: 0.536710\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number64, CIFAR-10 Batch Number 1:  Valid Loss: 0.553735\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number64, CIFAR-10 Batch Number 2:  Valid Loss: 0.512818\n",
      "Valid accuracy: 0.750000\n",
      "Epoch number64, CIFAR-10 Batch Number 3:  Valid Loss: 0.447581\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number64, CIFAR-10 Batch Number 4:  Valid Loss: 0.571358\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number64, CIFAR-10 Batch Number 5:  Valid Loss: 0.493642\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number65, CIFAR-10 Batch Number 1:  Valid Loss: 0.495793\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number65, CIFAR-10 Batch Number 2:  Valid Loss: 0.500662\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number65, CIFAR-10 Batch Number 3:  Valid Loss: 0.439672\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number65, CIFAR-10 Batch Number 4:  Valid Loss: 0.564428\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number65, CIFAR-10 Batch Number 5:  Valid Loss: 0.486077\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number66, CIFAR-10 Batch Number 1:  Valid Loss: 0.512356\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number66, CIFAR-10 Batch Number 2:  Valid Loss: 0.465535\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number66, CIFAR-10 Batch Number 3:  Valid Loss: 0.404327\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number66, CIFAR-10 Batch Number 4:  Valid Loss: 0.566852\n",
      "Valid accuracy: 0.775000\n",
      "Epoch number66, CIFAR-10 Batch Number 5:  Valid Loss: 0.466571\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number67, CIFAR-10 Batch Number 1:  Valid Loss: 0.504252\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number67, CIFAR-10 Batch Number 2:  Valid Loss: 0.475696\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number67, CIFAR-10 Batch Number 3:  Valid Loss: 0.405437\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number67, CIFAR-10 Batch Number 4:  Valid Loss: 0.566119\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number67, CIFAR-10 Batch Number 5:  Valid Loss: 0.490946\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number68, CIFAR-10 Batch Number 1:  Valid Loss: 0.500283\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number68, CIFAR-10 Batch Number 2:  Valid Loss: 0.493397\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number68, CIFAR-10 Batch Number 3:  Valid Loss: 0.410252\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number68, CIFAR-10 Batch Number 4:  Valid Loss: 0.530864\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number68, CIFAR-10 Batch Number 5:  Valid Loss: 0.491411\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number69, CIFAR-10 Batch Number 1:  Valid Loss: 0.479608\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number69, CIFAR-10 Batch Number 2:  Valid Loss: 0.498933\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number69, CIFAR-10 Batch Number 3:  Valid Loss: 0.413462\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number69, CIFAR-10 Batch Number 4:  Valid Loss: 0.518386\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number69, CIFAR-10 Batch Number 5:  Valid Loss: 0.455029\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number70, CIFAR-10 Batch Number 1:  Valid Loss: 0.468822\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number70, CIFAR-10 Batch Number 2:  Valid Loss: 0.444393\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number70, CIFAR-10 Batch Number 3:  Valid Loss: 0.390788\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number70, CIFAR-10 Batch Number 4:  Valid Loss: 0.515909\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number70, CIFAR-10 Batch Number 5:  Valid Loss: 0.410253\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number71, CIFAR-10 Batch Number 1:  Valid Loss: 0.496741\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number71, CIFAR-10 Batch Number 2:  Valid Loss: 0.444694\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number71, CIFAR-10 Batch Number 3:  Valid Loss: 0.383986\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number71, CIFAR-10 Batch Number 4:  Valid Loss: 0.486288\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number71, CIFAR-10 Batch Number 5:  Valid Loss: 0.451908\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number72, CIFAR-10 Batch Number 1:  Valid Loss: 0.437655\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number72, CIFAR-10 Batch Number 2:  Valid Loss: 0.451180\n",
      "Valid accuracy: 0.800000\n",
      "Epoch number72, CIFAR-10 Batch Number 3:  Valid Loss: 0.360684\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number72, CIFAR-10 Batch Number 4:  Valid Loss: 0.467693\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number72, CIFAR-10 Batch Number 5:  Valid Loss: 0.425440\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number73, CIFAR-10 Batch Number 1:  Valid Loss: 0.449025\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number73, CIFAR-10 Batch Number 2:  Valid Loss: 0.430664\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number73, CIFAR-10 Batch Number 3:  Valid Loss: 0.389939\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number73, CIFAR-10 Batch Number 4:  Valid Loss: 0.439642\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number73, CIFAR-10 Batch Number 5:  Valid Loss: 0.398800\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number74, CIFAR-10 Batch Number 1:  Valid Loss: 0.439421\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number74, CIFAR-10 Batch Number 2:  Valid Loss: 0.437595\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number74, CIFAR-10 Batch Number 3:  Valid Loss: 0.346835\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number74, CIFAR-10 Batch Number 4:  Valid Loss: 0.445773\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number74, CIFAR-10 Batch Number 5:  Valid Loss: 0.382502\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number75, CIFAR-10 Batch Number 1:  Valid Loss: 0.444158\n",
      "Valid accuracy: 0.850000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number75, CIFAR-10 Batch Number 2:  Valid Loss: 0.401530\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number75, CIFAR-10 Batch Number 3:  Valid Loss: 0.353528\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number75, CIFAR-10 Batch Number 4:  Valid Loss: 0.485423\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number75, CIFAR-10 Batch Number 5:  Valid Loss: 0.399531\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number76, CIFAR-10 Batch Number 1:  Valid Loss: 0.421074\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number76, CIFAR-10 Batch Number 2:  Valid Loss: 0.447072\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number76, CIFAR-10 Batch Number 3:  Valid Loss: 0.363383\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number76, CIFAR-10 Batch Number 4:  Valid Loss: 0.470939\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number76, CIFAR-10 Batch Number 5:  Valid Loss: 0.409506\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number77, CIFAR-10 Batch Number 1:  Valid Loss: 0.395905\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number77, CIFAR-10 Batch Number 2:  Valid Loss: 0.422292\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number77, CIFAR-10 Batch Number 3:  Valid Loss: 0.337476\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number77, CIFAR-10 Batch Number 4:  Valid Loss: 0.421673\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number77, CIFAR-10 Batch Number 5:  Valid Loss: 0.368561\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number78, CIFAR-10 Batch Number 1:  Valid Loss: 0.396161\n",
      "Valid accuracy: 0.825000\n",
      "Epoch number78, CIFAR-10 Batch Number 2:  Valid Loss: 0.401064\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number78, CIFAR-10 Batch Number 3:  Valid Loss: 0.310413\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number78, CIFAR-10 Batch Number 4:  Valid Loss: 0.438184\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number78, CIFAR-10 Batch Number 5:  Valid Loss: 0.347920\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number79, CIFAR-10 Batch Number 1:  Valid Loss: 0.411237\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number79, CIFAR-10 Batch Number 2:  Valid Loss: 0.367874\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number79, CIFAR-10 Batch Number 3:  Valid Loss: 0.301776\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number79, CIFAR-10 Batch Number 4:  Valid Loss: 0.417859\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number79, CIFAR-10 Batch Number 5:  Valid Loss: 0.399733\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number80, CIFAR-10 Batch Number 1:  Valid Loss: 0.397991\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number80, CIFAR-10 Batch Number 2:  Valid Loss: 0.397579\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number80, CIFAR-10 Batch Number 3:  Valid Loss: 0.330038\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number80, CIFAR-10 Batch Number 4:  Valid Loss: 0.386152\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number80, CIFAR-10 Batch Number 5:  Valid Loss: 0.346028\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number81, CIFAR-10 Batch Number 1:  Valid Loss: 0.444786\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number81, CIFAR-10 Batch Number 2:  Valid Loss: 0.370622\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number81, CIFAR-10 Batch Number 3:  Valid Loss: 0.335846\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number81, CIFAR-10 Batch Number 4:  Valid Loss: 0.373282\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number81, CIFAR-10 Batch Number 5:  Valid Loss: 0.337163\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number82, CIFAR-10 Batch Number 1:  Valid Loss: 0.374520\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number82, CIFAR-10 Batch Number 2:  Valid Loss: 0.396648\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number82, CIFAR-10 Batch Number 3:  Valid Loss: 0.328506\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number82, CIFAR-10 Batch Number 4:  Valid Loss: 0.347752\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number82, CIFAR-10 Batch Number 5:  Valid Loss: 0.324170\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number83, CIFAR-10 Batch Number 1:  Valid Loss: 0.354464\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number83, CIFAR-10 Batch Number 2:  Valid Loss: 0.360627\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number83, CIFAR-10 Batch Number 3:  Valid Loss: 0.292083\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number83, CIFAR-10 Batch Number 4:  Valid Loss: 0.347759\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number83, CIFAR-10 Batch Number 5:  Valid Loss: 0.334551\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number84, CIFAR-10 Batch Number 1:  Valid Loss: 0.362116\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number84, CIFAR-10 Batch Number 2:  Valid Loss: 0.351294\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number84, CIFAR-10 Batch Number 3:  Valid Loss: 0.281403\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number84, CIFAR-10 Batch Number 4:  Valid Loss: 0.357493\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number84, CIFAR-10 Batch Number 5:  Valid Loss: 0.290194\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number85, CIFAR-10 Batch Number 1:  Valid Loss: 0.356044\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number85, CIFAR-10 Batch Number 2:  Valid Loss: 0.356335\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number85, CIFAR-10 Batch Number 3:  Valid Loss: 0.294043\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number85, CIFAR-10 Batch Number 4:  Valid Loss: 0.377587\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number85, CIFAR-10 Batch Number 5:  Valid Loss: 0.383265\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number86, CIFAR-10 Batch Number 1:  Valid Loss: 0.327655\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number86, CIFAR-10 Batch Number 2:  Valid Loss: 0.365242\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number86, CIFAR-10 Batch Number 3:  Valid Loss: 0.329025\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number86, CIFAR-10 Batch Number 4:  Valid Loss: 0.326512\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number86, CIFAR-10 Batch Number 5:  Valid Loss: 0.300918\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number87, CIFAR-10 Batch Number 1:  Valid Loss: 0.345766\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number87, CIFAR-10 Batch Number 2:  Valid Loss: 0.334919\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number87, CIFAR-10 Batch Number 3:  Valid Loss: 0.286109\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number87, CIFAR-10 Batch Number 4:  Valid Loss: 0.325842\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number87, CIFAR-10 Batch Number 5:  Valid Loss: 0.295704\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number88, CIFAR-10 Batch Number 1:  Valid Loss: 0.303547\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number88, CIFAR-10 Batch Number 2:  Valid Loss: 0.365599\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number88, CIFAR-10 Batch Number 3:  Valid Loss: 0.272619\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number88, CIFAR-10 Batch Number 4:  Valid Loss: 0.281574\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number88, CIFAR-10 Batch Number 5:  Valid Loss: 0.283096\n",
      "Valid accuracy: 0.975000\n",
      "Epoch number89, CIFAR-10 Batch Number 1:  Valid Loss: 0.403834\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number89, CIFAR-10 Batch Number 2:  Valid Loss: 0.364436\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number89, CIFAR-10 Batch Number 3:  Valid Loss: 0.269096\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number89, CIFAR-10 Batch Number 4:  Valid Loss: 0.311713\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number89, CIFAR-10 Batch Number 5:  Valid Loss: 0.277612\n",
      "Valid accuracy: 1.000000\n",
      "Epoch number90, CIFAR-10 Batch Number 1:  Valid Loss: 0.281425\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number90, CIFAR-10 Batch Number 2:  Valid Loss: 0.330442\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number90, CIFAR-10 Batch Number 3:  Valid Loss: 0.276172\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number90, CIFAR-10 Batch Number 4:  Valid Loss: 0.352412\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number90, CIFAR-10 Batch Number 5:  Valid Loss: 0.285986\n",
      "Valid accuracy: 1.000000\n",
      "Epoch number91, CIFAR-10 Batch Number 1:  Valid Loss: 0.323226\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number91, CIFAR-10 Batch Number 2:  Valid Loss: 0.344056\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number91, CIFAR-10 Batch Number 3:  Valid Loss: 0.273713\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number91, CIFAR-10 Batch Number 4:  Valid Loss: 0.310897\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number91, CIFAR-10 Batch Number 5:  Valid Loss: 0.283160\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number92, CIFAR-10 Batch Number 1:  Valid Loss: 0.329333\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number92, CIFAR-10 Batch Number 2:  Valid Loss: 0.314200\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number92, CIFAR-10 Batch Number 3:  Valid Loss: 0.234912\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number92, CIFAR-10 Batch Number 4:  Valid Loss: 0.316442\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number92, CIFAR-10 Batch Number 5:  Valid Loss: 0.293491\n",
      "Valid accuracy: 1.000000\n",
      "Epoch number93, CIFAR-10 Batch Number 1:  Valid Loss: 0.301471\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number93, CIFAR-10 Batch Number 2:  Valid Loss: 0.296645\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number93, CIFAR-10 Batch Number 3:  Valid Loss: 0.291733\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number93, CIFAR-10 Batch Number 4:  Valid Loss: 0.311010\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number93, CIFAR-10 Batch Number 5:  Valid Loss: 0.267827\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number94, CIFAR-10 Batch Number 1:  Valid Loss: 0.313246\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number94, CIFAR-10 Batch Number 2:  Valid Loss: 0.297267\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number94, CIFAR-10 Batch Number 3:  Valid Loss: 0.265071\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number94, CIFAR-10 Batch Number 4:  Valid Loss: 0.308381\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number94, CIFAR-10 Batch Number 5:  Valid Loss: 0.274654\n",
      "Valid accuracy: 0.975000\n",
      "Epoch number95, CIFAR-10 Batch Number 1:  Valid Loss: 0.290429\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number95, CIFAR-10 Batch Number 2:  Valid Loss: 0.334429\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number95, CIFAR-10 Batch Number 3:  Valid Loss: 0.239052\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number95, CIFAR-10 Batch Number 4:  Valid Loss: 0.333594\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number95, CIFAR-10 Batch Number 5:  Valid Loss: 0.257331\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number96, CIFAR-10 Batch Number 1:  Valid Loss: 0.299432\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number96, CIFAR-10 Batch Number 2:  Valid Loss: 0.310011\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number96, CIFAR-10 Batch Number 3:  Valid Loss: 0.276387\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number96, CIFAR-10 Batch Number 4:  Valid Loss: 0.282793\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number96, CIFAR-10 Batch Number 5:  Valid Loss: 0.277028\n",
      "Valid accuracy: 0.975000\n",
      "Epoch number97, CIFAR-10 Batch Number 1:  Valid Loss: 0.279635\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number97, CIFAR-10 Batch Number 2:  Valid Loss: 0.265130\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number97, CIFAR-10 Batch Number 3:  Valid Loss: 0.257276\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number97, CIFAR-10 Batch Number 4:  Valid Loss: 0.287178\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number97, CIFAR-10 Batch Number 5:  Valid Loss: 0.247864\n",
      "Valid accuracy: 0.975000\n",
      "Epoch number98, CIFAR-10 Batch Number 1:  Valid Loss: 0.290763\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number98, CIFAR-10 Batch Number 2:  Valid Loss: 0.299908\n",
      "Valid accuracy: 0.850000\n",
      "Epoch number98, CIFAR-10 Batch Number 3:  Valid Loss: 0.250594\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number98, CIFAR-10 Batch Number 4:  Valid Loss: 0.314393\n",
      "Valid accuracy: 0.925000\n",
      "Epoch number98, CIFAR-10 Batch Number 5:  Valid Loss: 0.250342\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number99, CIFAR-10 Batch Number 1:  Valid Loss: 0.274724\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number99, CIFAR-10 Batch Number 2:  Valid Loss: 0.319883\n",
      "Valid accuracy: 0.875000\n",
      "Epoch number99, CIFAR-10 Batch Number 3:  Valid Loss: 0.242232\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number99, CIFAR-10 Batch Number 4:  Valid Loss: 0.277071\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number99, CIFAR-10 Batch Number 5:  Valid Loss: 0.221080\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number100, CIFAR-10 Batch Number 1:  Valid Loss: 0.261396\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number100, CIFAR-10 Batch Number 2:  Valid Loss: 0.268680\n",
      "Valid accuracy: 0.900000\n",
      "Epoch number100, CIFAR-10 Batch Number 3:  Valid Loss: 0.224548\n",
      "Valid accuracy: 0.950000\n",
      "Epoch number100, CIFAR-10 Batch Number 4:  Valid Loss: 0.303349\n",
      "Valid accuracy: 0.975000\n",
      "Epoch number100, CIFAR-10 Batch Number 5:  Valid Loss: 0.203371\n",
      "Valid accuracy: 0.975000\n"
     ]
    }
   ],
   "source": [
    "print('Full training for the network...')  \n",
    "model_save_path = './classification/cifar-10_classification'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    # 初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    # 训练周期\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # iterate through the batches\n",
    "        # 遍历批次\n",
    "        num_batches = 5\n",
    "\n",
    "        for batch_ind in range(1, num_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_ind, batch_size):\n",
    "                train(sess, model_optimizer, keep_probability, batch_features, batch_labels)\n",
    "\n",
    "            print('Epoch number{:>2}, CIFAR-10 Batch Number {}:  '.format(epoch + 1, batch_ind), end='')\n",
    "            print_model_stats(sess, batch_features, batch_labels, model_cost, accuracy)\n",
    "\n",
    "    # Save the trained Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们根据CIFAR-10数据集的测试集部分测试训练的模型。 首先，我们将定义一个辅助函数，它将帮助我们可视化一些示例图像及其相应的真实标签的预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to visualize some samples and their corresponding predictions\n",
    "# 辅助函数可视化一些样本及其相应的预测\n",
    "def display_samples_predictions(input_features, target_labels, samples_predictions):\n",
    "    num_classes = 10\n",
    "\n",
    "    cifar10_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(num_classes))\n",
    "    label_inds = label_binarizer.inverse_transform(np.array(target_labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=2)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    num_predictions = 4\n",
    "    margin = 0.05\n",
    "    ind = np.arange(num_predictions)\n",
    "    width = (1. - 2. * margin) / num_predictions\n",
    "\n",
    "    for image_ind, (feature, label_ind, prediction_indicies, prediction_values) in enumerate(\n",
    "            zip(input_features, label_inds, samples_predictions.indices, samples_predictions.values)):\n",
    "        prediction_names = [cifar10_class_names[pred_i] for pred_i in prediction_indicies]\n",
    "        correct_name = cifar10_class_names[label_ind]\n",
    "\n",
    "        axies[image_ind][0].imshow(feature)\n",
    "        axies[image_ind][0].set_title(correct_name)\n",
    "        axies[image_ind][0].set_axis_off()\n",
    "\n",
    "        axies[image_ind][1].barh(ind + margin, prediction_values[::-1], width)\n",
    "        axies[image_ind][1].set_yticks(ind + margin)\n",
    "        axies[image_ind][1].set_yticklabels(prediction_names[::-1])\n",
    "        axies[image_ind][1].set_xticks([0, 0.5, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们恢复训练好的模型并根据测试集进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./classification/cifar-10_classification\n",
      "Test set accuracy: 0.6189291401273885\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_batch_size = 64\n",
    "\n",
    "save_model_path = './classification/cifar-10_classification'\n",
    "\n",
    "# Number of images to visualize\n",
    "# 要可视化的图像数量\n",
    "num_samples = 4\n",
    "\n",
    "# Number of top predictions\n",
    "# 最高预测数量\n",
    "top_n_predictions = 4\n",
    "\n",
    "# Defining a helper function for testing the trained model\n",
    "# 定义辅助函数以测试训练模型\n",
    "def test_classification_model():\n",
    "    input_test_features, target_test_labels = pickle.load(open('./preprocess/preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # loading the trained model\n",
    "        # 加载训练的模型\n",
    "        model = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        model.restore(sess, save_model_path)\n",
    "\n",
    "        # Getting some input and output Tensors from loaded model\n",
    "        # 从加载的模型中获取一些输入和输出张量\n",
    "        model_input_values = loaded_graph.get_tensor_by_name('input_images:0')\n",
    "        model_target = loaded_graph.get_tensor_by_name('input_images_target:0')\n",
    "        model_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        model_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        model_accuracy = loaded_graph.get_tensor_by_name('model_accuracy:0')\n",
    "\n",
    "        # Testing the trained model on the test set batches\n",
    "        # 在测试集批次上测试训练的模型\n",
    "        test_batch_accuracy_total = 0\n",
    "        test_batch_count = 0\n",
    "\n",
    "        for input_test_feature_batch, input_test_label_batch in batch_split_features_labels(input_test_features,\n",
    "                                                                                            target_test_labels,\n",
    "                                                                                            test_batch_size):\n",
    "            test_batch_accuracy_total += sess.run(\n",
    "                model_accuracy,\n",
    "                feed_dict={model_input_values: input_test_feature_batch, model_target: input_test_label_batch,\n",
    "                           model_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Test set accuracy: {}\\n'.format(test_batch_accuracy_total / test_batch_count))\n",
    "\n",
    "        # print some random images and their corresponding predictions from the test set results\n",
    "        #从测试集结果中打印一些随机图像及其相应的预测\n",
    "        random_input_test_features, random_test_target_labels = tuple(\n",
    "            zip(*random.sample(list(zip(input_test_features, target_test_labels)), num_samples)))\n",
    "\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(model_logits), top_n_predictions),\n",
    "            feed_dict={model_input_values: random_input_test_features, model_target: random_test_target_labels,\n",
    "                       model_keep_prob: 1.0})\n",
    "\n",
    "        display_samples_predictions(random_input_test_features, random_test_target_labels, random_test_predictions)\n",
    "\n",
    "# Calling the function\n",
    "# 调用函数\n",
    "test_classification_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们的测试精度大约为62％，对于像我们使用的CNN这样简单的CNN也不错。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章向我们展示了如何制作CNN来对CIFAR-10数据集中的图像进行分类。 测试集的分类准确度约为79％-80％。 还绘制了卷积层的输出，但很难看出神经网络如何识别和分类输入图像。 需要更好的可视化技术。\n",
    "\n",
    "接下来，我们将使用现代和令人兴奋的深度学习实践之一，即转移学习。 转移学习允许您使用数据贪婪的小型数据集深度学习架构。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
